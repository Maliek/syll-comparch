<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book lang="en">
<bookinfo>
<title>Computerarchitectuur</title>
<date>2014-11-16</date>
</bookinfo>
<preface id="_over_deze_cursus">
<title>Over deze cursus</title>
<simpara>Dit lesmateriaal werd opgesteld doorheen de jaren, met tal van auteurs. Dhr Sven Sanders en Dhr Johan Donne verdienen daarbij een speciale vermelding, omdat zij de fundamenten van deze informatiebron reeds jaren geleden gelegd hebben.</simpara>
<simpara>Er werd in deze cursus gepoogd om steeds correct om te gaan met materiaal van externe bronnen, inzake copyrights en bronvermelding. Mocht je toch een fragment of afbeelding vinden zonder correcte bronvermelding, geef dat dan zeker door.<?asciidoc-br?>
Stuur hiervoor zeker een <ulink url="mailto:roel.vansteenberghe@hubkaho.be">mailtje</ulink>. Er zal meteen het nodige gedaan worden om de situatie recht te zetten.</simpara>
<simpara>Door deze cursus aan te bieden op Github is er ook de hoop dat er ook door anderen (ja, ook jij :-) ) toevoegingen kunnen gebeuren.</simpara>
</preface>
<chapter id="_licentie">
<title>Licentie</title>
<simpara>Hergebruik van het materiaal is dan ook toegelaten, maar wel onder voorwaarden:</simpara>
<itemizedlist>
<listitem>
<simpara>het materiaal, of fragmenten ervan, mogen niet commercieel beschikbaar gesteld worden zonder uitdrukkelijke en schriftelijke toestemming van de auteur(s)</simpara>
</listitem>
<listitem>
<simpara>de inhoud aanpassen mag, maar dan op voorwaarde dat de aanpassingen ook publiek beschikbaar worden gesteld. Bij voorkeur gebeurt dit online (met een pull request op Github), zodat iedereen mee kan genieten van de verbeteringen.</simpara>
</listitem>
</itemizedlist>
<simpara>Concreet betekent dit dat al het materiaal onder de <ulink url="http://creativecommons.org/licenses/by-nc-sa/4.0/deed.nl">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</ulink> valt, tenzij anders gespecifieerd.</simpara>
</chapter>
<preface id="_voorwoord">
<title>Voorwoord</title>
<simpara>Als iemand van de buitenwereld je de komende jaren vraagt wat je precies gestudeerd hebt, of wat je doet als werk, dan zal je antwoord vaak ‘iets met computers’ zijn. Soms is dat nu eenmaal de makkelijkste manier om je er vanaf te maken.</simpara>
<simpara>Tegenwoordig zijn computers, tablets, smartphones en andere devices immers zo gewoon, dat ze bijna thuis horen in het rijtje van basisbehoeften als stromend water, elektriciteit en TV.</simpara>
<simpara>Toch blijft het belangrijk voor jullie als ICT&#8217;ers om te weten wat er onder de motorkap van je devices schuilt. Die achtergrondkennis is onontbeerlijk om later efficiënt problemen op te lossen of producten (in de breedste zin van het woord) van goeie kwaliteit af te leveren. Zelfs wie zich later zal toespitsen op het ontwikkelen van software, zal efficiënter kunnen werken als hij ook snapt wat achter de schermen gebeurt.</simpara>
<simpara>Deze cursus probeert je een overzicht te geven van de interne keuken van een moderne computer terwijl de cursus processorarchitectuur dan weer iets dieper ingaat op de werking van het kloppend hart ervan.</simpara>
<simpara>Uiteraard zijn twaalf lessen veel te weinig om alle onderdelen tot op het bot uit te benen. Daarom kan ik enkele standaardwerken aanbevelen, die zeker een bron van inspiratie vormden voor deze cursus. De boeken van William Stallings <xref linkend="STALLINGS"/> en Umakishore Ramachandran <xref linkend="RAMA"/> verdienen zeker je aandacht.</simpara>
<simpara>Een overzicht van de werkvormen die bij dit vak gebruikt worden, vind je terug in de ECTS fiche. Deze kan je vinden op <ulink url="http://onderwijsaanbod.hubkaho.be">onderwijsaanbod.kahosl.be</ulink></simpara>
<simpara>Veel succes met deze cursus!</simpara>
<simpara>Roel Van Steenberghe</simpara>
</preface>
<chapter id="_computervoeding">
<title>Computervoeding</title>
<section id="_principe_en_werking">
<title>Principe en werking</title>
<simpara>Een computer, of het nu een PC, laptop, server of smartphone is, kan enkel functioneren als de juiste elektrische spanningen aangebracht worden. Elektronische componenten vragen een relatief lage, maar erg stabiele gelijkspanning om te functioneren.
Deze wordt geleverd door een voeding, die de wisselspanning van het elektriciteitsnet omzet naar de nodige gelijkspanningsniveaus. De techniek die hierbij gebruikt wordt noemt men switched mode power supply of schakelende voeding.
Het schema van de omzetting wordt weergegeven in onderstaande afbeelding</simpara>
<figure>
<title>Principe schakelende voeding</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/principe_geschakelde_voeding.png" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>psu principe</phrase></textobject>
</mediaobject>
</figure>
<simpara>Een eerste stap &#9312; is de <emphasis role="strong">gelijkrichter</emphasis> aan de ingang, waarmee de wisselspanning wordt omgezet naar een gelijkspanning. Deze gelijkspanning wordt vervolgens gefilterd, zodat de variatie in het spanningsniveau beperkt wordt.
De tweede stap &#9313; is een stuk minder voor de hand liggend. Op basis van de gelijkgerichte en gefilterde ingangsspanning zal een invertor een blokgolf genereren. Deze wisselspanning wordt bekomen door het aan- en afschakelen van de ingangsspanning.
Eigenlijk is de combinatie van de eerste twee stappen samen te vatten als een frequentieomvormer. Het ingangssignaal wordt omgezet naar een hoger-frequent signaal (van 50Hz naar frequenties boven 20kHz).</simpara>
<simpara>Het voordeel van deze omzetting is dat de <emphasis role="strong">transformator</emphasis> in de volgende stap een stuk kleiner en efficiënter kan zijn. Deze gelijkrichter en transformator &#9314; brengt de spanning naar het gewenste niveau, waarna het met de uitgangs-gelijkrichter en filter &#9315; wordt omgezet naar een stabiele gelijkspanning.
Een bijkomend voordeel van de omzetting is dat het menselijk gehoor signalen boven 20kHz niet kan waarnemen, zo hebben we dus geen last van het geluid dat de voeding kan voortbrengen.</simpara>
<simpara>In de figuur is ook te zien dat de uitgangsspanning teruggekoppeld wordt &#9316; naar de invertor. Op die manier kan de uitgangsspanning nog geregeld worden. De invertor-stap heeft immers ook invloed op de amplitude van zijn uitgang. Deze <emphasis role="strong">terugkoppeling</emphasis> gebeurt meestal met optocouplers om een galvanische scheiding te bekomen.</simpara>
<note>
<simpara>Om het verbruik van een CPU uit te drukken, wordt vaak gesproken over <emphasis role="strong">TDP</emphasis> (Thermal Design Power). Dat is een waarde die aanduidt hoeveel energie de CPU maximaal dissipeert onder een zware, maar realistische belasting gedurende een bepaalde tijd. Echter dient opgemerkt te worden dat 'AMD' en 'Intel' hiervoor verschillende berekeningsmethodes gebruiken.  De TDP geeft dus een indicatie over het maximale verbruik, maar gedetailleerde benchmarks blijven nodig om exacte waarden te kennen. <footnote><simpara>meer uitleg over de berekening van TDP bij Intel vind je in <ulink url="http://www.intel.com/content/www/us/en/benchmarks/resources-xeon-measuring-processor-power-paper.html">deze whitepaper</ulink></simpara></footnote></simpara>
</note>
</section>
<section id="_eigenschappen">
<title>Eigenschappen</title>
<section id="_vormfactor_en_connectoren">
<title>Vormfactor en connectoren</title>
<simpara>De eerste (IBM) PC beschikte over een moederbord met AT vormfactor, de bijhorende voeding was dan ook een AT voeding. In 1995 kwam er een opvolger, met name de ATX vormfactor. Ondertussen is deze specificatie ook geëvolueerd (ondertussen ATX 2.3).</simpara>
<simpara>De belangrijkste verschillen situeren zich op het vlak van de spanningen die de voeding kan afgeven en de connectoren die voorzien zijn op de voeding.
In het bijzonder is er natuurlijk een verschil tussen de verschillende connectoren die op het moederbord worden aangesloten. Een AT voeding bood een connector van tweemaal zes aansluitingen, een ATX voeding biedt daarentegen een connector met 24 aansluitingen. (in de oorspronkelijke versie was dit 20, tegenwoordig is er ook steeds een vierpolige connector die twee keer twaalf Volt levert aan de processor.)</simpara>
<figure>
<title>ATX 2.0 moederbord connector (CC Wikimedia commons)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/1000px-ATX_PS_signals.svg.png" contentwidth="300" width="40%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>ATX 2.0</phrase></textobject>
</mediaobject>
</figure>
<simpara>Een belangrijk verschil tussen beiden is de aanwezigheid bij ATX van een 3.3V spanning, een +5V standby en power on signaal.
Deze laatste twee maken het mogelijk dat de mechanische schakelaar van de AT voeding (die rechtstreeks de voeding aanstuurde), vervangen kon worden door een elektronisch signaal van het moederbord naar de voeding. In eerste instantie kan het moederbord dit signaal sturen als het zelf een input krijgt van een drukknop. Er zijn echter ook alternatieven mogelijk, zoals wake-on-lan, speciale toetsen op een toetsenbord,&#8230;&#8203;</simpara>
<simpara>Hieruit kan je afleiden dat bij een computer die uitgeschakeld is, een deel van het moederbord nog steeds onder spanning staat.
Deze spanning kan je alleen wegnemen door de voeding uit te schakelen (schakelaar op voeding, stekker uittrekken).</simpara>
<simpara>Naast de verschillen in connectoren die op het moederbord worden aangesloten, is er ook onderscheid op het vlak van de andere connectoren. Afhankelijk van de andere apparaten (en hun voedingsaansluiting), moet je erop letten om een voeding te kiezen die de nodige connectoren aanbiedt.</simpara>
<simpara>Enkele belangrijke connectoren zijn:</simpara>
<itemizedlist>
<listitem>
<simpara>ATX power connector (ook wel moederbord connector genoemd)</simpara>
</listitem>
<listitem>
<simpara>4-pin connector (molex): o.a. voor (ATA) schijven, optische drives</simpara>
</listitem>
<listitem>
<simpara>SATA voedingsconnector</simpara>
</listitem>
<listitem>
<simpara>Auxiliary connectors: verschillende varianten van extra voedingsconnector en om extra vermogen te leveren</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_vermogen">
<title>Vermogen</title>
<simpara>Een erg belangrijke eigenschap voor een voeding is het vermogen dat ze kan leveren.
Uiteraard moet dit te leveren vermogen voldoende zijn om alle componenten in het systeem te voorzien van stroom. Het vergelijken van voedingen op dit vlak is iets complexer dan kijken naar de waarden die de fabrikant op zijn verpakking adverteert.</simpara>
<simpara>Belangrijker dan het getal is de betekenis ervan. Aangezien er geen voorschriften zijn voor de bepaling van die vermogenswaarde, kan 500W bij de ene fabrikant betekenen dat de voeding 500W piekvermogen kan leveren bij 10°C en bij een andere een continu vermogen van 500W bij 40°C.
Als het systeem continu 450W nodig heeft, zou de eerste voeding kunnen falen.</simpara>
<simpara>Een tweede belangrijke opmerking is dat niet alleen het totale vermogen belangrijk is, maar ook het vermogen dat op elke voedingsspanning apart geleverd kan worden. Het is duidelijk dat een computervoeding meerdere eindtrappen moet bevatten voor de verschillende spanningen. Op elk van deze rails is er een maximale stroom die geleverd kan worden.</simpara>
<simpara>Als de maximale stroom op de 12V rail 5A is, kan je met een 500W voeding niet voorzien in de behoeften van een computer die een vermogen van 200W nodig heeft, maar wel 6A op de 12V rail. Dit kan een belangrijke reden voor prijsverschillen in voedingen zijn. Goedkopere voedingen kunnen typisch meer stroom leveren bij de lagere spanningen en minder bij 12V. Er moet nog worden opgemerkt dat sommige voedingen verschillende rails hebben voor eenzelfde voedingsspanning. Op elk van deze rails is dan een maximale stroom vastgelegd. Het zal wel duidelijk zijn dat je dan best de verbruikers op een zo evenwichtig mogelijke manier over deze rails moet verdelen.</simpara>
<simpara>Een laatste opmerking is dat het vermogen van de voeding zo goed mogelijk op het systeem moet worden afgestemd. Uiteraard betekent dit dat je voldoende piekvermogen nodig hebt, maar zomaar een voeding van 1kW aanschaffen voor een systeem dat 200W nodig heeft is niet meteen een goede keuze.</simpara>
</section>
<section id="_rendement">
<title>Rendement</title>
<simpara>Het ‘groene’ aspect bij computers komt steeds meer naar voor. Het rendement van de voeding is daarbij een belangrijke factor. Je wil natuurlijk voor elke 100 Watt die je uit het stroomnet haalt, ook 100W prestaties zien. Helaas is dit niet mogelijk: voedingen hebben een rendement dat een stuk lager ligt dan de ideale 100%. Dat verlies uit zich voornamelijk in warmte, die dan weer moet afgevoerd worden. Het spreekt voor zich dan een hoger rendement meestal ook een iets hoger prijskaartje met zich zal meebrengen. Toch is dit het overwegen waard als je een kleine rekenoefening maakt.</simpara>
</section>
<section id="_geluid">
<title>Geluid</title>
<simpara>De geluidsproductie van een computer is in verschillende gebruiksomgevingen liefst zo klein mogelijk. Een belangrijke bron van lawaai wordt gevormd door de verschillende koelingen en in het bijzonder de ventilatoren die hierbij worden gebruikt. Hier blijkt alvast het belang van het rendement van een voeding. Hoe hoger het rendement, des te minder verlies er is. Dit verlies manifesteert zich steeds onder de vorm van warmte.</simpara>
<simpara>Naast het rendement is ook de grootte van de ventilator belangrijk. Een grotere ventilator zal bij lagere toerentallen voldoende kunnen koelen en daarbij minder lawaai produceren. Er bestaan ook voedingen die volledig passief (zonder ventilatoren) gekoeld worden. Deze produceren uiteraard geen lawaai, maar zijn typisch iets duurder.</simpara>
<example>
<title>rekenvoorbeeld stroomverbruik</title>
<simpara>Een computer (inclusief scherm) die niet erg zwaar belast wordt, verbruikt ongeveer 200 Watt. Als je deze pc elke werkdag 10 uur gebruikt, dan komt het verbruik op</simpara>
<simpara>0,150 kW x 10 uur per dag x 250 werkdagen= 375 kWh per jaar</simpara>
<simpara>Als je daar de prijs tegenover zet die een gemiddeld gezin (bron: VREG, oktober 2012) betaalt per kWh, dan kost deze pc je 375 * 0,2€ = € 75. Een voeding met een rendement dat 20% beter is zal je dus op jaarbasis makkelijk 15 Euro opleveren.</simpara>
<simpara>Het loont dus de moeite om bij de aankoop de voeding zorgvuldig te kiezen. De meerprijs voor een duurdere PSU (Power Supply Unit) kan dus zeker renderen. In een bedrijf met honderden desktops begrijp je dat dit een verkoopsargument kan zijn.</simpara>
</example>
<simpara><emphasis role="strong">Het 80-plus certificatieprogramma</emphasis> probeert voor de consument duidelijkheid te scheppen door voedingen een label te geven naargelang de efficiëntie. De certificatie is echter geen verplichting voor fabrikanten.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>80 plus certificatie (bron: <ulink url="http://en.wikipedia.org/wiki/80_Plus">Wikipedia</ulink> )</title>
<tgroup cols="7">
<colspec colname="col_1" colwidth="14*"/>
<colspec colname="col_2" colwidth="14*"/>
<colspec colname="col_3" colwidth="14*"/>
<colspec colname="col_4" colwidth="14*"/>
<colspec colname="col_5" colwidth="14*"/>
<colspec colname="col_6" colwidth="14*"/>
<colspec colname="col_7" colwidth="14*"/>
<thead>
<row>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top">standaard</entry>
<entry align="left" valign="top">brons</entry>
<entry align="left" valign="top">zilver</entry>
<entry align="left" valign="top">goud</entry>
<entry align="left" valign="top">platinum</entry>
<entry align="left" valign="top">titanium <footnote><simpara>bij titanium worden ook nog extra eisen gesteld</simpara></footnote></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>20% belast</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=80%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=82%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=85%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=87%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=90%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=94%</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>50% belast</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=80%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=85%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=88%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=90%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=92%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=96%</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>100% belast</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=80%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=82%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=85%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=87%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=89%</simpara></entry>
<entry align="left" valign="top"><simpara>&gt;=94%</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Laptops hebben een verbruik dat typisch een flink stuk lager zit. Hoewel ze een voeding hebben die meestal een behoorlijk hoog wattage aankan om de accu snel op te laden, is het gemiddeld verbruik meestal slechts rond de 30Watt.
Nieuwere toestellen die een hoge autonomie tot hun belangrijkste verkoopargumenten rekenen, zoals chromebooks, kunnen zelfs onder maximale belasting onder de grens van 15 Watt blijven. <xref linkend="ANAND"/></simpara>
<simpara>Het matige rendement van PSU’s is voor een deel eigen aan de opbouw ervan. Omdat veel verschillende eindtrappen nodig zijn voor de verschillende spanningen, is het totale rendementsverlies een accumulatie van de kleinere verliezen bij de deeltrappen.</simpara>
<simpara>Ondertussen verlaten sommige grote spelers om die reden de ATX standaard om met eigen oplossingen hogere rendementen te behalen. Google ontwikkelt bijvoorbeeld z’n eigen servervoedingen die door hun eenvoud een veel hoger rendement halen. De eenvoud bestaat erin dat ze slechts 1 spanning aanbieden aan het moederbord: 12V. Als componenten een andere voedingsspanning vereisen,  worden die waar nodig getransformeerd op het moederbord, wat veel efficiënter kan. Google research publiceerde een paper <xref linkend="GOOGLE"/> die schat dat de energiebesparing die je hiermee kan behalen op een populatie van 100 miljoen computers 13 miljard kWh betreft op jaarbasis. Dat komt, om je een idee te geven, ongeveer overeen met de opbrengst van de helft van een kerncentrale zoals die in Doel (jaarproductie 22 miljard kWh).</simpara>
</section>
<section id="_problemen_met_voedingen">
<title>Problemen met voedingen</title>
<simpara>Problemen met voedingen hebben altijd gevolgen voor het volledige systeem, aangezien ze dit volledige systeem van stroom moeten voorzien. Een belangrijke oorzaak van problemen is een te klein vermogen voor het systeem of onvoldoende koeling. Dit probleem uit zich meestal niet in het niet opstarten van het systeem, maar eerder in het onverwacht afsluiten (of eventueel herstarten) ervan. Dit is dan nog het meest aangename gevolg van het probleem. Het is belangrijk om bij dergelijke problemen de voeding en de koeling ervan te controleren.</simpara>
<simpara>Minder aangename gevolgen kunnen zijn dat de voeding beschadigd raakt en in het meer dramatische geval dat er rook uit de computerkast komt. Deze kan dan afkomstig zijn van de voeding zelf, maar ook van andere componenten(moederbord, RAM, CPU). Een situatie die de meesten liever vermijden.</simpara>
<simpara>Een voeding kan ook slijtage vertonen. In het bijzonder op het vlak van de elektrolytische condensatoren kan er veel verschil zijn tussen voedingen. Minder kwalitatieve condensatoren kunnen uitdrogen (elektrolyt dat verdampt), waardoor ze hun functie minder tot niet meer vervullen en de voeding uiteindelijk rook in plaats van gelijkspanning produceert. Dit gebeurt uiteraard pas na verloop van tijd (afhankelijk van de belasting van de computer).</simpara>
<simpara>Sommige voedingen hebben een controlesysteem dat je door middel van geluidssignalen preventief waarschuwt als er problemen dreigen, zoals overbelasting of een gebrekkige koeling.</simpara>
</section>
</section>
<section id="_accu_s">
<title>Accu’s</title>
<simpara>Tegenwoordig kunnen we het niet meer hebben over computervoedingen zonder even uit te wijden over accu’s. In de trend naar mobiliteit (laptops, tablets, smartphones), vormen die een onmisbare schakel.</simpara>
<section id="_eigenschappen_2">
<title>Eigenschappen</title>
<section id="_capaciteit">
<title>Capaciteit</title>
<simpara>De capaciteit van batterijen wordt meestal uitgedrukt in Ah (ampère/uur) of mAh (milliampère/uur). Met die eenheid kan je makkelijk accu-packs vergelijken. Een batterij van 6Ah zal theoretisch bijvoorbeeld in staat zijn om gedurende 6 uur een stroom af te leveren van 1 Ampère, of gedurende bijvoorbeeld 2 uur een stroom van 3 Ampère. Uiteraard zijn er in realiteit door de fabrikant maxima gedefinieerd zodat de levensduur van de accu niet bedreigd wordt.</simpara>
<simpara>Sommige fabrikanten verkiezen echter om hun capaciteiten uit te drukken in Wh, wat vergelijken lastiger kan maken. Toch kan je eenvoudig omrekenen bij gelijkstroom:
Je weet immers dat</simpara>
<simpara>P=U*I (Vermogen = Spanning x Stroom)</simpara>
<simpara>Willen we dus de stroom I(A) kennen, dan moeten we het vermogen delen door de spanning.
Nemen we onderstaand voorbeeld:</simpara>
<figure>
<title>accu</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/Battery_Capacity_Conversion.JPG" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>accus</phrase></textobject>
</mediaobject>
</figure>
<simpara>We kunnen hier dus de capaciteit in Ah bepalen door</simpara>
<simpara>I_h = P_h/U = 2,4Wh/3,6V = 0,666Ah (of 666mAh)</simpara>
</section>
<section id="_aantal_cellen">
<title>Aantal cellen</title>
<simpara>Een accu wordt opgebouwd uit verschillende cellen. Bijvoorbeeld bij Li-ion accu’s kunnen die elk ongeveer 3V leveren. Het spreekt voor zich dat een toename van het aantal cellen zal betekenen dat de totale capaciteit ook toeneemt.</simpara>
<example>
<title>Oefening</title>
<simpara>Wat is de capaciteit van je eigen laptopaccu?</simpara>
<simpara>Stel dat je deze accu gebruikt om een lamp (bijvoorbeeld een powerLED) te doen branden die 5 Watt verbruikt. Hoe lang zal de lamp branden?</simpara>
<simpara>Uit hoeveel cellen bestaat je accu-pack?</simpara>
</example>
</section>
<section id="_laadcurve">
<title>Laadcurve</title>
<simpara>Om de optimale kwaliteit van de accu te garanderen over langere termijn is het nodig om de juiste laadcurve te respecteren. Een batterij zal uiteraard stroom nodig hebben om zich op te laden, maar het is niet noodzakelijk zo dat een hogere stroom zal betekenen dat de batterij sneller oplaadt. Het gebruik van de juiste en kwalitatieve adapter is hierbij erg belangrijk.</simpara>
</section>
<section id="_memory_effect">
<title>Memory-effect</title>
<simpara>Het zogenaamd memory-effect is een term die vaak gebruikt wordt om aan te geven dat bepaalde types batterijen, met NiCd (Nikkel-Cadmium) op kop, vaak een effect vertonen waarbij het lijkt dat de batterijen snel hun capaciteit verliezen als je ze halverwege de ontlaadcyclus terug oplaadt. Dat fenomeen is eigenlijk de verzamelnaam van effecten die worden veroorzaakt door een combinatie van elektrische en chemische processen.</simpara>
</section>
<section id="_li_ion_accu_s">
<title>LI-ION accu’s</title>
<simpara>Tegenwoordig is dit zowat het meest voorkomende type in hoogwaardige mobiele apparatuur. Dit type onderscheidt zich door een erg hoge energiedichtheid, en het ‘memory-effect’ is niet bestaande.</simpara>

<simpara>Toch zijn er enkele belangrijke eigenschappen aan dit type, die je beter kent..
Het zwakke punt van Li-Ion: degradatie</simpara>
<simpara>Wie een laptop of gsm gebruikt, kent het fenomeen: na enkele jaren is de capaciteit van de batterij slechts nog een fractie van wat ze was bij aankoop. Dit fenomeen kan je niet omkeren, maar het kan wel vertraagd worden als je weet wat de factoren zijn die dit proces versnellen&#8230;&#8203;</simpara>
<simpara>Een Li-ion-accu verliest zijn capaciteit het snelst als hij zich in een warme ruimte bevindt, en opgeladen is. Een volledig opgeladen Li-ion accu zal bijvoorbeeld na een jaar rusten in een ruimte waar het gemiddeld 20°C is, 20 procent van zijn capaciteit verliezen.</simpara>
<simpara>Is diezelfde accu slechts half opgeladen, dan zal de capaciteit met slechts enkele procenten dalen. Het is dus niet verstandig een Li-ion-accu voor lange tijd weg te bergen in opgeladen toestand. Ook door stockage in koele ruimtes kan de capaciteit langer bewaard blijven. Een laptop die snel erg warm wordt bij gebruik zal dus meteen ook nefast zijn voor de capaciteit van de batterij op langere termijn.<?asciidoc-br?>
Bij een temperatuur van iets boven het vriespunt en een lading van ongeveer 40% zal dit type batterij de langste levensduur ‘on the shelf’ hebben.</simpara>
</section>
<section id="_toekomstige_ontwikkelingen">
<title>Toekomstige ontwikkelingen</title>
<simpara>Gezien de enorme markt die ontstaan is voor accu’s, is er enorm veel druk om betere modellen te ontwikkelen. Daarbij worden bestaande types geperfectioneerd, maar ook nieuwe types ontwikkeld.
Zo zijn er de <emphasis role="strong">LiPo</emphasis> (Lithium polymeer) batterijen die ongeveer 50% efficiënter zijn dan klassieke Li-Ion equivalenten, en ook de brandstofcellen (fuel cells) die mogelijks een oplossing kunnen vormen voor de steeds grotere autonomie-behoefte van toestellen. Omdat veel van deze technieken gebruik maken van erg zeldzame delfstoffen, komen ook geavanceerde technieken met courante materialen in het vizier ter optimalisatie of vervanging, zoals nanostructuren met koolstof. Deze blijven echter toekomstmuziek voor consumentenelektronica…</simpara>
</section>
</section>
</section>
<section id="_uninterruptible_power_supply_ups">
<title>Uninterruptible Power Supply (UPS)</title>
<simpara>Een UPS is een toestel dat het wegvallen van de netspanning kan opvangen. Hiervoor bestaat een UPS uit een accu en een elektronische schakeling die de accuspanning kan omzetten naar een netspanning.</simpara>
<figure>
<title>Rack-mountable UPS (bron: <ulink url="http://www.apc.com">www.apc.com</ulink>)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/ups/apc_ups.jpg" contentwidth="300" width="20%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>APC UPS</phrase></textobject>
</mediaobject>
</figure>
<simpara>Bij het wegvallen van de netspanning zal de UPS ogenblikkelijk de stroomvoorziening overnemen.
Voor de aangesloten toestellen treedt er dus geen onderbreking op. Een UPS kan de stroom natuurlijk niet onbeperkt in de tijd overnemen. Hoe lang de UPS dit kan volhouden, hangt af van de accu’s en het gevraagde vermogen. Om te vermijden dat apparatuur plotseling en ongecontroleerd stilvalt, heeft een UPS dikwijls ook een interface naar de computer. Deze laat toe dat de UPS de computer ‘proper’ afsluit op het ogenblik dat de accu-stroom een bepaalde ondergrens bereikt. Een alternatief kan erin bestaan dat de UPS gecombineerd wordt met een dieselgenerator.</simpara>
<simpara>De UPS zorgt dan voor de ogenblikkelijke overname van de stroomvoorziening en geeft de generator de nodige tijd om op te starten. Zodra de generator actief is (en de uitgangsspanning gestabiliseerd is), neemt deze de stroomvoorziening op zich.</simpara>
<simpara>Een UPS heeft meestal ook een spanningsbeveiliging aan boord die je apparatuur kan beschermen tegen storingen op het elektriciteitsnet.
UPS’en vind je in alle prijsklassen, wat vaak te maken heeft met de inwendige opbouw ervan. Er onderscheiden zich enkele grote types.</simpara>
<simpara>Een noodstroominstallatie die zonder onderbreking te veroorzaken de netspanning kan overnemen wordt een <emphasis role="strong">nobreak</emphasis> installatie genoemd. <xref linkend="WIKINOBREAK"/> Hiervoor wordt een combinatie van een UPS en een noodstroomaggregaat (generator die op diesel werkt) gebruikt. De UPS levert spanning tijdens de eerste minuten, hierna neemt de noodstroomaggregaat het over, en dan laadt de UPS weer op.</simpara>
<section id="_online_ups">
<title>Online UPS</title>
<simpara>De online UPS wordt ook wel “double conversion” UPS genoemd. Alle stroom die naar de IT-apparatuur gaat, loopt door de UPS. Hierdoor is het niet nodig om over te schakelen bij het uitvallen van de stroom. Met de bypass kan je evenwel de ups overbruggen. Dat kan bijvoorbeeld interessant zijn als er onderhoud nodig is. Omdat hierdoor veel gevraagd wordt van alle elektronica (die constant volledig belast wordt), is dit een relatief duur concept.</simpara>
<figure>
<title>Online UPS ( &#169; GFDL Joslee 2007 )</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/ups/Double_conversion_UPSII.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>APC UPS</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_offline_ups">
<title>Offline UPS</title>
<simpara>Dit type UPS vind je voornamelijk terug bij particuliere ups’en waar kostprijs een belangrijk criterium is. Bij het wegvallen van de spanning, wordt een bypass ingeschakeld. Die procedure duurt enkele milliseconden waarbij je geen uitgangsspanning hebt, en dat moet opgevangen worden door de voeding van je computer of server. Een nadeel van dit type UPS is dat je hem ook niet zonder risico kan testen.</simpara>
<simpara>Een ander nadeel is dat in gewone omstandigheden de netspanning rechtstreeks gekoppeld is aan je IT-apparatuur. Als er storingen op het net zitten, zal je IT apparatuur daar hinder van ondervinden. De apparatuur is dus niet beveiligd.</simpara>
<figure>
<title>Offline UPS ( &#169; Joslee 2007 GFDL)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/ups/Off_line_ups.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>offline UPS</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_line_interactive_ups">
<title>Line-interactive UPS</title>
<simpara>Deze vorm van UPS vormt een hybride oplossing. In feite gaat het om een off-line UPS waar de line-feed voorzien is van aanvullende filters. Zo ben je zeker dat de spanning die aan je servers aangelegd is, gezuiverd werd van pieken en storingen. In omgevingen waar veel storing optreedt is dat geen overbodige luxe. (bijvoorbeeld fabriekshallen, gebieden met gebrekkige stroomvoorziening)</simpara>
<figure>
<title>Line interactive UPS ( &#169; Joslee 2007 GFDL)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch01/images/ups/Line_interactive_UPSII.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>line interactive UPS</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
</chapter>
<chapter id="_link_naar_animatie">
<title>Link naar animatie</title>
<simpara><ulink url="https://www.youtube.com/watch?v=E5RKBWhEUAU">https://www.youtube.com/watch?v=E5RKBWhEUAU</ulink></simpara>
<section id="_bibliografie_bij_dit_hoofdstuk">
<title>Bibliografie bij dit hoofdstuk</title>
<bibliodiv>
<bibliomixed>
<bibliomisc><anchor id="GOOGLE" xreflabel="[GOOGLE]"/>[GOOGLE] Google. High efficient power supplies for home computers and servers. 2006.  <ulink url="http://static.googleusercontent.com/media/services.google.com/nl//blog_resources/PSU_white_paper.pdf">http://static.googleusercontent.com/media/services.google.com/nl//blog_resources/PSU_white_paper.pdf</ulink></bibliomisc>
</bibliomixed>
<bibliomixed>
<bibliomisc><anchor id="ANAND" xreflabel="[ANAND]"/>[ANAND] AnandTech. Samsung Chromebook Review. <ulink url="http://www.anandtech.com/show/6422/samsung-chromebook-xe303-review-testing-arms-cortex-a15/7">http://www.anandtech.com/show/6422/samsung-chromebook-xe303-review-testing-arms-cortex-a15/7</ulink></bibliomisc>
</bibliomixed>
<bibliomixed>
<bibliomisc><anchor id="WIKINOBREAK" xreflabel="[WIKINOBREAK]"/>[WIKINOBREAK] Bron Wikipedia. Noodstroomvoeding Wikipedia. [online] 2014. [Cited: 21/7/2014]</bibliomisc>
</bibliomixed>
</bibliodiv>
</section>
</chapter>
<chapter id="_cpu">
<title>CPU</title>
<section id="_overzicht">
<title>Overzicht</title>
<simpara>In onderstaande tabel worden een aantal processoren van de x86 familie weergegeven met hun belangrijkste eigenschappen. De processor die in de eerste (IBM-)PC werd gebruikt was een 8088. Eigenlijk was dit een 8086 waarvan de databus beperkt werd tot 8 bits in plaats van 16 bits. De enige reden hiervoor was dat op dat ogenblik er geen andere 16-bit componenten beschikbaar waren.
Deze processorfamilie komt uitgebreid aan bod binnen het vak processorarchitectuur.
Het is niet de bedoeling om hier terug te komen op programmeermodel, segmentering, &#8230;&#8203;</simpara>
<simpara>Wel zullen we de evolutie van een aantal eigenschappen bekijken.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>processoroverzicht</title>
<tgroup cols="8">
<colspec colname="col_1" colwidth="12*"/>
<colspec colname="col_2" colwidth="12*"/>
<colspec colname="col_3" colwidth="12*"/>
<colspec colname="col_4" colwidth="12*"/>
<colspec colname="col_5" colwidth="12*"/>
<colspec colname="col_6" colwidth="12*"/>
<colspec colname="col_7" colwidth="12*"/>
<colspec colname="col_8" colwidth="12*"/>
<thead>
<row>
<entry align="left" valign="top">type</entry>
<entry align="left" valign="top">jaar</entry>
<entry align="left" valign="top">data/adres-bus</entry>
<entry align="left" valign="top">L1 cache (kB)</entry>
<entry align="left" valign="top">FSB (MHz)</entry>
<entry align="left" valign="top">Clock(MHz)</entry>
<entry align="left" valign="top">transistoren (miljoen)</entry>
<entry align="left" valign="top">technologie (nm)</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>8088</simpara></entry>
<entry align="left" valign="top"><simpara>1979</simpara></entry>
<entry align="left" valign="top"><simpara>8/20</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>4,77..8</simpara></entry>
<entry align="left" valign="top"><simpara>4,77..8</simpara></entry>
<entry align="left" valign="top"><simpara>0.029</simpara></entry>
<entry align="left" valign="top"><simpara>3000</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8086</simpara></entry>
<entry align="left" valign="top"><simpara>1978</simpara></entry>
<entry align="left" valign="top"><simpara>16/20</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>4,77..8</simpara></entry>
<entry align="left" valign="top"><simpara>4,77..8</simpara></entry>
<entry align="left" valign="top"><simpara>0.029</simpara></entry>
<entry align="left" valign="top"><simpara>3000</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>80286</simpara></entry>
<entry align="left" valign="top"><simpara>1980</simpara></entry>
<entry align="left" valign="top"><simpara>16/24</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>6..20</simpara></entry>
<entry align="left" valign="top"><simpara>6..20</simpara></entry>
<entry align="left" valign="top"><simpara>0.134</simpara></entry>
<entry align="left" valign="top"><simpara>1500</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>80386DX</simpara></entry>
<entry align="left" valign="top"><simpara>1985</simpara></entry>
<entry align="left" valign="top"><simpara>32/32</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>16..33</simpara></entry>
<entry align="left" valign="top"><simpara>16..33</simpara></entry>
<entry align="left" valign="top"><simpara>0.275</simpara></entry>
<entry align="left" valign="top"><simpara>1500</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>80486DX/SX</simpara></entry>
<entry align="left" valign="top"><simpara>1989</simpara></entry>
<entry align="left" valign="top"><simpara>32/32</simpara></entry>
<entry align="left" valign="top"><simpara>8</simpara></entry>
<entry align="left" valign="top"><simpara>25..50</simpara></entry>
<entry align="left" valign="top"><simpara>25..50</simpara></entry>
<entry align="left" valign="top"><simpara>1.2</simpara></entry>
<entry align="left" valign="top"><simpara>1000</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>80486DX2</simpara></entry>
<entry align="left" valign="top"><simpara>1992</simpara></entry>
<entry align="left" valign="top"><simpara>32/32</simpara></entry>
<entry align="left" valign="top"><simpara>8</simpara></entry>
<entry align="left" valign="top"><simpara>25..40</simpara></entry>
<entry align="left" valign="top"><simpara>25..80</simpara></entry>
<entry align="left" valign="top"><simpara>1.2</simpara></entry>
<entry align="left" valign="top"><simpara>800</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>80486DX4</simpara></entry>
<entry align="left" valign="top"><simpara>1994</simpara></entry>
<entry align="left" valign="top"><simpara>32/32</simpara></entry>
<entry align="left" valign="top"><simpara>8+8</simpara></entry>
<entry align="left" valign="top"><simpara>25..40</simpara></entry>
<entry align="left" valign="top"><simpara>75..120</simpara></entry>
<entry align="left" valign="top"><simpara>1.2</simpara></entry>
<entry align="left" valign="top"><simpara>600</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium</simpara></entry>
<entry align="left" valign="top"><simpara>1993</simpara></entry>
<entry align="left" valign="top"><simpara>64/32</simpara></entry>
<entry align="left" valign="top"><simpara>8+8</simpara></entry>
<entry align="left" valign="top"><simpara>60..66</simpara></entry>
<entry align="left" valign="top"><simpara>60..200</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>600</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium MMX</simpara></entry>
<entry align="left" valign="top"><simpara>1997</simpara></entry>
<entry align="left" valign="top"><simpara>64/32</simpara></entry>
<entry align="left" valign="top"><simpara>16+16</simpara></entry>
<entry align="left" valign="top"><simpara>66</simpara></entry>
<entry align="left" valign="top"><simpara>166..233</simpara></entry>
<entry align="left" valign="top"><simpara>4.5</simpara></entry>
<entry align="left" valign="top"><simpara>350</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium Pro</simpara></entry>
<entry align="left" valign="top"><simpara>1995</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>8+8</simpara></entry>
<entry align="left" valign="top"><simpara>66</simpara></entry>
<entry align="left" valign="top"><simpara>150..200</simpara></entry>
<entry align="left" valign="top"><simpara>5.5</simpara></entry>
<entry align="left" valign="top"><simpara>350</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium II</simpara></entry>
<entry align="left" valign="top"><simpara>1997</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>16+16</simpara></entry>
<entry align="left" valign="top"><simpara>66/100</simpara></entry>
<entry align="left" valign="top"><simpara>300..450</simpara></entry>
<entry align="left" valign="top"><simpara>7.5</simpara></entry>
<entry align="left" valign="top"><simpara>250</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium III</simpara></entry>
<entry align="left" valign="top"><simpara>1999</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>16+16</simpara></entry>
<entry align="left" valign="top"><simpara>100/133</simpara></entry>
<entry align="left" valign="top"><simpara>450..1300</simpara></entry>
<entry align="left" valign="top"><simpara>28</simpara></entry>
<entry align="left" valign="top"><simpara>130</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>AMD Athlon</simpara></entry>
<entry align="left" valign="top"><simpara>1999</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>64+64</simpara></entry>
<entry align="left" valign="top"><simpara>200/266</simpara></entry>
<entry align="left" valign="top"><simpara>500..2200</simpara></entry>
<entry align="left" valign="top"><simpara>37</simpara></entry>
<entry align="left" valign="top"><simpara>130</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pentium IV</simpara></entry>
<entry align="left" valign="top"><simpara>2001</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>8+96</simpara></entry>
<entry align="left" valign="top"><simpara>400/533</simpara></entry>
<entry align="left" valign="top"><simpara>1400..2800</simpara></entry>
<entry align="left" valign="top"><simpara>42</simpara></entry>
<entry align="left" valign="top"><simpara>130</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>AMD 64</simpara></entry>
<entry align="left" valign="top"><simpara>2005</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>2*512k L2</simpara></entry>
<entry align="left" valign="top"><simpara>2000</simpara></entry>
<entry align="left" valign="top"><simpara>2,4GHz</simpara></entry>
<entry align="left" valign="top"><simpara>233</simpara></entry>
<entry align="left" valign="top"><simpara>102</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Core duo</simpara></entry>
<entry align="left" valign="top"><simpara>2006</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>2*2M L2</simpara></entry>
<entry align="left" valign="top"><simpara>800</simpara></entry>
<entry align="left" valign="top"><simpara>3,6GHz</simpara></entry>
<entry align="left" valign="top"><simpara>376</simpara></entry>
<entry align="left" valign="top"><simpara>65</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Intel Nehalem</simpara></entry>
<entry align="left" valign="top"><simpara>2008</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>32+32/core</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>3,2 GHz</simpara></entry>
<entry align="left" valign="top"><simpara>731 (QC)</simpara></entry>
<entry align="left" valign="top"><simpara>45/32</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Intel Sandy Bridge</simpara></entry>
<entry align="left" valign="top"><simpara>2011</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>32+32/core</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>3,8 GHz.<footnote id="turbo"><simpara>deze waarden zijn niet continue en kunnen pas tijdelijk gehaald worden met technologieën als Turboboost.</simpara></footnote></simpara></entry>
<entry align="left" valign="top"><simpara>995 (QC)</simpara></entry>
<entry align="left" valign="top"><simpara>32</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Intel Ivy bridge</simpara></entry>
<entry align="left" valign="top"><simpara>2012</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>32+32/core</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>3,9 GHz.<footnoteref linkend="turbo"/></simpara></entry>
<entry align="left" valign="top"><simpara>1400 (QC)</simpara></entry>
<entry align="left" valign="top"><simpara>22</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Intel Haswell</simpara></entry>
<entry align="left" valign="top"><simpara>2013</simpara></entry>
<entry align="left" valign="top"><simpara>64/36</simpara></entry>
<entry align="left" valign="top"><simpara>32+32/core</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>3,9 GHz.<footnoteref linkend="turbo"/></simpara></entry>
<entry align="left" valign="top"><simpara>1400</simpara></entry>
<entry align="left" valign="top"><simpara>22</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section id="_technologie_en_functionaliteit">
<title>Technologie en functionaliteit</title>
<simpara>Een eerste duidelijke evolutie is de toename van het aantal transistors. Volgens de wet van Moore verloopt deze stijging zelfs exponentieel. Elke vierentwintig maanden zou het aantal transistors in een processor verdubbelen . Die toename is uiteraard enkel mogelijk als de transistordichtheid kan toenemen. In het verleden werd hierbij vaak gedacht dat er technische beperkingen zouden opduiken, maar tot dusver blijven fabrikanten slagen om vast te houden aan de ontwikkelsnelheid die geponeerd werd door Gordon More, één van de oprichters van Intel.</simpara>
<blockquote>
<attribution>
Gordon Moore
<citetitle>Electronics Magazine 1965</citetitle>
</attribution>
<simpara>The number of transistors incorporated in a chip will approximately double every 24 months</simpara>
</blockquote>
<figure>
<title>Wet van Moore (CC, Wikimedia Commons)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/mooreslaw2011.png" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Bulldozer</phrase></textobject>
</mediaobject>
</figure>
<simpara>Met deze stijging van het aantal transistoren gaat uiteraard ook een toename in functionaliteit gepaard. Zo kent een x86 processor vanaf de 80286/80386 (in principe vanaf de 286, praktisch vanaf de 386) twee werkingsmodi: real mode en protected mode.</simpara>
<simpara>In real mode heeft de cpu dezelfde functionaliteit als een 8086.
In deze compatibiliteitsmodus gedraagt hij zich met andere woorden als een snellere versie van de 8086. In protected mode krijgt de processor extra functionaliteit. De naam protected mode komt van de extra toevoegingen op het vlak van geheugenbescherming. Daarnaast ondersteunde de processor vanaf deze modus een aantal, vandaag onmisbare, extra mogelijkheden.</simpara>
<simpara>Onder andere multitasking en virtueel geheugen zijn enkel mogelijk met een protected mode processor. Hier moet nog opgemerkt worden dat processoren nog steeds opstarten in real mode. Het is de taak van het besturingssysteem (of beter de loader ervan) om de processor om te schakelen naar protected mode.
Andere voorbeelden van extra functionaliteit zijn de integratie van functies die eerst door externe componenten werden vervuld. Bijvoorbeeld werd vanaf de 486 een floating point unit in de processor geïntegreerd. Een ander voorbeeld zijn cache geheugens. De extra functionaliteit uit zich ook op het vlak van de instructieset. Zo zijn in de loop der tijden een aantal extra instructies toegevoegd om aan bepaalde behoeften te voldoen. Een belangrijk voorbeeld zijn de instructies die het gebruik van multimedia moeten ondersteunen (bijvoorbeeld MMX, SSE, 3DNow) en de ondersteuning voor virtualisatie (bijvoorbeeld Intel VT-d, Amd-V).</simpara>
<simpara>Software die gebruik maakt van dit soort instructies, kan uiteraard niet uitgevoerd worden op processoren die deze instructies niet ondersteunen.</simpara>
<simpara>Intel, de grootste producent van x86 processoren, hanteert voor de ontwikkeling een model dat het tick/tock-model genoemd wordt. Afwisselend worden nieuwe modellen uitgebracht met nieuwe funcitonaliteit (tock) en verbeterde technologie (tick). Dit wordt duidelijk in volgende intel roadmap.</simpara>
<figure>
<title>Intel roadmap (copyright 2008-2012 WhiteTimberwolf GFDL )</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/IntelProcessorRoadmap-3.svg.png" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Intel CPU roadmap</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_kloksnelheid">
<title>Kloksnelheid</title>
<simpara>Een tweede evolutie is waar te nemen op het vlak van de kloksnelheid, die duidelijk toegenomen is. In de beginjaren van de pc was te zien dat CPU klok en FSB klok samen toenamen. Na verloop van tijd ontstaat er een verschil tussen de processorklok en de FSB klok, die nog wel stijgt, maar een stuk minder snel. De processor wordt met andere woorden duidelijk het snelste onderdeel in het computersysteem. Het zal erop aan komen de werkkracht van de CPU zo weinig mogelijk onbenut te laten. In het bijzonder zullen maatregelen genomen moeten worden om zo weinig mogelijk tijd te verliezen bij het wachten op tragere componenten. De trend naar steeds stijgende kloksnelheden is tijdens het laatste decennium afgenomen. Bij de Pentium 4 werd nog volop gemikt op de 4GHz grens, waar enige jaren tegenaan gebotst werd.</simpara>
<simpara>Het belangrijkste probleem bij steeds hogere kloksnelheden is de gegenereerde warmte. Die moet in de eerste plaats uiteraard afgevoerd worden, maar geeft daarnaast ook nog een hoger verbruik.<?asciidoc-br?>
In het bijzonder bij laptops zijn dit twee vervelende problemen: de warmteafvoer vraagt grotere (en dus zwaardere) koellichamen en ventilatoren. Extra verbruik verkleint uiteraard de autonomie van een draagbaar toestel (tijd dat op accu gewerkt kan worden).</simpara>
</section>
<section id="_processorarchitectuur">
<title>Processorarchitectuur</title>
<section id="_pipelining">
<title>Pipelining</title>
<simpara>Naast de kloksnelheid werd ook aan de interne opbouw van de processor gesleuteld om hem sneller bepaalde taken te laten uitvoeren. Zo werken processoren instructies niet na elkaar af, maar gedeeltelijk tegelijkertijd. Dit gebeurt in een zogenaamde pipeline. Het is eenvoudig om in te beelden dat terwijl de ene instructie uit het geheugen wordt opgehaald, een andere gedecodeerd kan worden en van nog een andere het resultaat berekend kan worden. Hieronder wordt dit principe grafisch voorgesteld.
Helaas is dit principe niet zaligmakend: soms zijn instructies afhankelijk van andere, waardoor er een ‘bubble’ optreedt: een tijdspanne waarin de processor verplicht moet wachten.</simpara>
<figure>
<title>processor pipeline (CC mediawiki)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/1000px-Pipeline4stage.png" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Sandy Bridge</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_superscalaire_processoren">
<title>Superscalaire processoren</title>
<simpara>Als dit principe verder gedreven wordt, kunnen stappen die veel tijd in beslag nemen dubbel uitgevoerd worden. Men spreekt dan over een superscalaire processor. In onderstaande afbeeldingen worden de blokschema’s getoond van de Sandy bridge en de Athlon Bulldozer microarchitectuur. In deze blokschema’s is duidelijk te zien hoe er verschilllende eenheden zijn die berekeningen kunnen maken, waardoor verschillende instructies tegelijkertijd uitgevoerd kunnen worden.
Een belangrijke uitdaging hierbij vormen voorwaardelijke spronginstructies. Aangezien pas bij de uitvoering van de instructie geweten is of de sprong uitgevoerd wordt of dat gewoon de volgende instructie wordt uitgevoerd. In het schema zijn hiervoor branch prediction eenheden voorzien.</simpara>
<simpara>Meer details over hun werking en de principes van pipelining en superscalaire architecturen krijg je in het vak "microprocessoren".</simpara>
<figure>
<title>Sandy bridge microarchitectuur</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/Sandy-Bridge-Microarchitecture-Small.jpg" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Sandy Bridge</phrase></textobject>
</mediaobject>
</figure>
<figure>
<title>AMD bulldozer-architectuur (copyright AnandTech)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/bulldozeruarch.jpg" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Bulldozer</phrase></textobject>
</mediaobject>
</figure>
<simpara>Multicore processoren (processoren met meerdere rekenkernen) zijn al geruime tijd niet meer weg te denken. Hexacores (processoren met 6 rekenkernen) en octacores (processoren met 8 rekenkernen) zullen de komende jaren eerder regel dan uitzondering worden.
Je zou dit een verder doorgedreven vorm van een superscalaire architectuur kunnen noemen. In plaats van delen van de processor te ontdubbelen, wordt een volledige processor ontdubbeld. Een grote moeilijkheid bij deze werkwijzes is om de caches op elkaar af te stemmen. Een probleem dat duidelijker zal worden in het volgende hoofdstuk.</simpara>
<simpara>Net zoals een superscalaire architectuur pas voordeel geeft als de verschillende eenheden tegelijk gebruikt worden, zal een dual-core pas voordeel geven als meerdere cores tegelijk werk verrichten. Dit kan als er bijvoorbeeld verschillende programma’s tegelijk actief zijn of als de software zodanig geschreven is, dat ze bestaat uit verschillende threads die naast elkaar (en dus tegelijk door verschillende processorkernen) kunnen uitgevoerd worden.</simpara>
<simpara>Een simpel voorbeeldje om de beperkingen van een multicore processor aan te tonen: als je een eenvoudige toepassing een rekenintensieve opdracht laat uitvoeren, dan zal een multicore processor slechts een deel belast worden. Eén processorkern verricht namelijk al het werk.</simpara>
<figure>
<title>single threaded applicatie op multicore processor</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/singlethread.png" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>singlethread</phrase></textobject>
</mediaobject>
</figure>
<simpara>Het voordeel van de multi-core merk je pas als je tegelijk nog een ander programma probeert te gebruiken. Dat zal met een multi-core vlot lukken, in tegenstelling tot een single core. Het OS zal op zoek gaan naar de minst belastte core, en het nieuwe proces daarop uitvoeren.</simpara>
<simpara>Uiteraard is dit principe nog verder schaalbaar. In servers worden vaak meerdere processoren op één moederbord geprikt, en als ook dat niet langer volstaat, wordt de rekenkracht van meerdere servers gecombineerd. Deze principes overstijgen deze cursus, en komen later in de opleiding aan bod.</simpara>
</section>
<section id="_cache">
<title>Cache</title>
<simpara>Een andere eigenschap die plots opduikt en doorheen de processorgeschiedenis steeds toeneemt is het cache geheugen. De toename van het cache volgt de trend van alle soorten geheugens die in een pc te vinden zijn.
Dit is een gevolg van de eerder opgemerkte trend dat de processor veruit het snelste onderdeel is in het systeem, dat zo optimaal mogelijk benut moet worden. Naarmate data en programma’s steeds groter werden, werd ook het belang van geheugen groter. Tot de intrede van de grafische interface was de belangrijkste parameter in het systeem de kloksnelheid van de processor. Met de intrede van de grafische interface was een groter geheugen soms te verkiezen boven een hogere kloksnelheid.
Het belang van cache geheugen is ook duidelijk als je de budget- en performance-processoren van fabrikanten met elkaar gaat vergelijken.</simpara>
<simpara>In onderstaand lijstje staan enkele desktop en serverprocessoren opgelijst. Je merkt dat ze qua kloksnelheid niet voor elkaar moeten onderdoen, maar dat de hoeveelheden cache wel verschillen.</simpara>
<simpara>De werking van de cache wordt verder in detail besproken in het derde hoofdstuk.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Cache in desktop en serverprocessoren (actuele topmodellen, feb 2014)</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top">CPU</entry>
<entry align="left" valign="top">doel</entry>
<entry align="left" valign="top">cache</entry>
<entry align="left" valign="top">maxCPU</entry>
<entry align="left" valign="top">#cores/threads</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Atom 7560</simpara></entry>
<entry align="left" valign="top"><simpara>mobile</simpara></entry>
<entry align="left" valign="top"><simpara>512KB</simpara></entry>
<entry align="left" valign="top"><simpara>2.13 GHz</simpara></entry>
<entry align="left" valign="top"><simpara>1/2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>i7-4771</simpara></entry>
<entry align="left" valign="top"><simpara>desktop</simpara></entry>
<entry align="left" valign="top"><simpara>8MB</simpara></entry>
<entry align="left" valign="top"><simpara>3.50 GHz</simpara></entry>
<entry align="left" valign="top"><simpara>4/8</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>E7-8893v2</simpara></entry>
<entry align="left" valign="top"><simpara>server</simpara></entry>
<entry align="left" valign="top"><simpara>37.5MB</simpara></entry>
<entry align="left" valign="top"><simpara>3.40 GHz</simpara></entry>
<entry align="left" valign="top"><simpara>15/30</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
</section>
<section id="_apu_soc">
<title>APU, SoC</title>
<simpara>De wet van Moore impliceert dat steeds meer mogelijk is op eenzelfde oppervlakte substraat. Die ruimte wordt ingenomen door bijvoorbeeld meerdere cores te huisvesten op eenzelfde processor, maar dat is maar een deel van het verhaal.</simpara>
<simpara>Het is namelijk ook zo dat men probeert om steeds meer functionaliteit die voorheen op andere plaatsen op het moederbord te vinden was, te verzamelen op eenzelfde chip.</simpara>
<simpara>Daar zijn een aantal goede redenen voor te bedenken:</simpara>
<itemizedlist>
<listitem>
<simpara>het aantal verschillende chips (en dus kostprijs) op een moederbord kan zo teruggedrongen worden</simpara>
</listitem>
<listitem>
<simpara>als alle componenten dicht bij elkaar zitten, zijn geen 'trage' bussen nodig tussen deze onderdelen</simpara>
</listitem>
<listitem>
<simpara>de oppervlakte die nodig is om het systeem te bouwen verkleint zo, een belangrijk argument bij de ontwikkeling van mobile devices.</simpara>
</listitem>
</itemizedlist>
<simpara>Bij recente processoren zit bijvoorbeeld steeds vaker een grafische chip ingebouwd. Dan spreekt men niet meer over CPU, maar over APU (=advanced processing unit) om dit verschil in de verf te zetten.</simpara>
<simpara>Het integratieproces gaat soms zo ver dat je kan spreken van een <emphasis>System On A Chip</emphasis>: alle belangrijke onderdelen (cpu, gpu, IO) zitten dan verzameld op één enkele chip.<?asciidoc-br?>
De rol van secundaire chips ("de chipset") wordt dus steeds kleiner.</simpara>
<example>
<title>oefening</title>
<simpara>Op welke SoC is jouw telefoon gebaseerd?</simpara>
</example>
</section>
<section id="_montage">
<title>Montage</title>
<simpara>Bij de montage van een processor moet je enkele zaken in acht nemen.</simpara>
<itemizedlist>
<listitem>
<simpara>De processor moet compatibel zijn met het moederbord. Meestal kom je dit te weten door de socket van de processor te vergelijken met die van het moederbord.</simpara>
</listitem>
<listitem>
<simpara>De processor plaatsen moet gebeuren zonder het uitoefenen van kracht: de processor valt normaalgezien in z’n socket (ZIF: zero insertion force), waarna je hem kan inklemmen.</simpara>
</listitem>
<listitem>
<simpara>Mobiele processoren zijn vaak vast op het moederbord gemonteerd, vervangen is dan onmogelijk.</simpara>
</listitem>
</itemizedlist>
<figure>
<title>LGA2011 socket zonder processor</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch02/images/lga2011_cooler_roundup_002.jpg" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>singlethread</phrase></textobject>
</mediaobject>
</figure>
<simpara>Tweede belangrijk aandachtspunt bij de installatie van een processor is dat gezorgd moet worden voor voldoende koeling. Dit betekent dat gezorgd moet worden voor een voldoende grote koelvin en ventilator en dat er goed contact is tussen de chip en de koelvin. Hiervoor moet eventueel koelpasta aangebracht worden. Een slecht gekoelde processor kan aanleiding geven tot een instabiel werkende computer en in het meest dramatische geval tot een beschadigde processor.</simpara>
</section>
<section id="_processoren_van_de_toekomst">
<title>Processoren van de toekomst</title>
<simpara>Voorspellingen maken is geen sinecure. De trends die ingezet zijn, zullen vermoedelijk nog een hele poos verder gaan, met een verdere miniaturisatie en toename van efficiëntie tot gevolg.
Een kaper op de kust voor de x86 technologie die momenteel monopolist is op de PC-markt, is de ARM-architectuur. Hoewel deze absoluut niet nieuw is (eerste ontwerpen midden jaren 80), biedt deze processorfamilie grote voordelen:</simpara>
<itemizedlist>
<listitem>
<simpara>Deze architectuur is steeds ontworpen voor toestellen met een laag verbruik. Het succes op de mobiele markt (iPAD2,3, nagenoeg alle android smartphones, consumer elektronica, …)</simpara>
</listitem>
<listitem>
<simpara>Deze architectuur is in licentie bij de meeste chipbakkers</simpara>
</listitem>
<listitem>
<simpara>Door een RISC (Reduced instruction set computing) architectuur van nature efficient</simpara>
</listitem>
</itemizedlist>
<simpara>De kans dat de RISC architectuur op korte termijn succesvol wordt op de desktopmarkt is gering, en ook het omgekeerde kan gezegd worden over CISC (x86) op mobiele devices. Voor specifieke servertoepassingen zijn er wel <ulink url="http://www.anandtech.com/show/7724/it-begins-amd-announces-its-first-arm-based-server-soc-64bit8core-opteron-a1100">aankondigingen gebeurd</ulink> door bijvoorbeeld AMD, dat zich hier sterk wil in specialiseren en profileren.</simpara>
<simpara>Toch lijken deze twee werelden van de gespecialiseerde ARM-architectuur en de meer universele x86 naar elkaar toe te groeien, en zullen de grenzen ongetwijfeld snel vervagen.
Microsoft heeft bijvoorbeeld eind 2012 z’n RT tablet vrijgegeven, met ARM SOC. Uiteraard zal software die gecompileerd werd voor x86 op dit soort toestellen niet werken. Ook Google Chromebooks worden zowel met ARM als met x86 gebouwd.</simpara>
</section>
<section id="_bibliografie_bij_dit_hoofdstuk_2">
<title>Bibliografie bij dit hoofdstuk</title>
<bibliodiv>
<bibliomixed>
<bibliomisc><anchor id="INTEL" xreflabel="[INTEL]"/>[INTEL] Intel. <ulink url="http://www.intel.com/content/www/us/en/history/museum-gordon-moore-law.html">http://www.intel.com/content/www/us/en/history/museum-gordon-moore-law.html</ulink>.</bibliomisc>
</bibliomixed>
</bibliodiv>
</section>
</chapter>
<chapter id="_het_geheugen">
<title>Het Geheugen</title>
<section id="_overzicht_2">
<title>Overzicht</title>
<simpara>Het belang van geheugen is tijdens de cursus computertechniek al voldoende gebleken. Zoals bekend worden zowel uit te voeren instructies als data opgeslagen in dit geheugen. (cfr de 'von Neumann architectuur') Dit legt twee belangrijke behoeften bloot: snelheid en grootte.</simpara>
<simpara><emphasis role="strong">Snelheid</emphasis> is erg belangrijk omdat het geheugen de processor moet voorzien van uit te voeren instructies. Een snelle processor met traag geheugen geeft een traag systeem.</simpara>
<simpara><emphasis role="strong">Grootte</emphasis> is dan weer belangrijk omdat zowel programma’s als de te bewerken data aanzienlijk zijn toegenomen. Bovendien moeten in een multitasking omgeving meerdere programma’s en dus ook grotere hoeveelheden data opgeslagen worden in het geheugen.</simpara>
<simpara>Als de verschillende soorten geheugens bekeken worden, wordt ook wel gesproken van de geheugenpiramide. Deze term wordt gebruikt omdat de hoeveelheid geheugen afneemt naarmate je stijgt in de piramide. De reden hiervoor is dat ook de prijs per byte toeneemt naarmate je hoger gaat in de piramide.</simpara>
<figure>
<title>Geheugenpiramide</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/geheugenpiramide.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>geheugenpiramide</phrase></textobject>
</mediaobject>
</figure>
<simpara>Daarnaast neemt de snelheid van het geheugen toe in de richting van de top van de piramide. In deze voorstelling is het begrip geheugen vrij ruim geïnterpreteerd. We zullen het in dit hoofdstuk niet hebben over registers of opslagmedia, wel over de technieken die toegepast worden om het geheugen voldoende snel en groot te maken.</simpara>
</section>
<section id="_lokaliteitsprincipes">
<title>Lokaliteitsprincipes</title>
<simpara>Bij het bestuderen van de technieken die gebruikt worden om het geheugen groot en snel te maken, zullen we regelmatig beroep doen op de zogenaamde lokaliteitsprincipes. Daarbij maken we een onderscheid tussen plaatsgebonden lokaliteit en tijdsgebonden lokaliteit. <xref linkend="PATT1"/></simpara>
<variablelist>
<varlistentry>
<term>Tijdsgebonden lokaliteit</term>
<listitem>
<simpara>Als je een bepaald item gebruikt, dan is de kans groot dat je dat binnenkort terug nodig hebt.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Plaatsgebonden lokaliteit</term>
<listitem>
<simpara>Als je een bepaald item gebruikt, dan is de kans groot dat je binnenkort iets nodig hebt dat in de buurt voorkomt&#8230;&#8203;</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Een paar voorbeeldjes bij deze principes:</simpara>
<itemizedlist>
<listitem>
<simpara>Sequentiële uitvoering van instructies in een programma. (plaatsgebonden)</simpara>
</listitem>
<listitem>
<simpara>Lussen in code, er is een regel die zegt dat programma’s 90% van hun tijd spenderen met het uitvoeren van 10% van de code, dus worden regelmatig dezelfde stukken geheugen aangesproken (tijdsgebonden &amp; plaatsgebonden)</simpara>
</listitem>
<listitem>
<simpara>Bestanden op een schijf worden, indien mogelijk, in opeenvolgende clusters opgeslagen. (plaatsgebonden)</simpara>
</listitem>
<listitem>
<simpara>bij een computerprogramma zullen bepaalde variabelen erg vaak gebruikt worden (tijdsgebonden)</simpara>
</listitem>
</itemizedlist>
<example>
<title>oefening</title>
<simpara>op welke manieren komen deze principes tot uiting in onderstaande java-code?</simpara>
</example>
<programlisting language="java" linenumbering="unnumbered">public class Vermenigvuldigingstafels {
	int score;<co id="CO1-1"/>

	public void test() {
		for (int i = 1; i &lt;= 10; i++) {
			vraagEnAntwoord();<co id="CO1-2"/>
		}

		drukResultaat();
	}

	public void vraagEnAntwoord() {
		int getal1 = (int)(Math.random() * 11);<co id="CO1-3"/>
		int getal2 = (int)(Math.random() * 11);

		System.out.print(getal1 + " * " + getal2 + " = ");

		if (Input.readInt() == getal1 * getal2) {
			score++;
		} else {
			System.out.println("fout");
		}
	}

	public void drukResultaat() {
		System.out.println("Je score: " + score + "/10");
	}

	public static void main (String args[]) {
			Vermenigvuldigingstafels tafels = new Vermenigvuldigingstafels();
			tafels.test();
	}
}</programlisting>
<calloutlist>
<callout arearefs="CO1-1">
<para>variabelen worden typisch meerdere keren opgevraagd tijdens de duur van een programma. (=tijdsgebonden lokaliteit)</para>
</callout>
<callout arearefs="CO1-2">
<para>een lus zorgt ervoor dat binnen bepaalde tijd code meerdere keren uitgevoerd wordt. (=tijdsgebonden lokaliteit)</para>
</callout>
<callout arearefs="CO1-3">
<para>deze regels code worden na elkaar uitgevoerd. Er is dus plaatsgebonden lokaliteit.</para>
</callout>
</calloutlist>
<example>
<title>oefening</title>
<simpara>Uiteraard speelt de programmeertaal geen rol bij dit principe. Kan je de dit aantonen met onderstaand assembler-fragment?</simpara>
</example>
<programlisting language="assembly" linenumbering="unnumbered">; x86 ASM code

.model small
.stack
.data
.code

start:
	mov ah,01h  ; karakter inlezen
	int 21h     ; resultaat in AL
	mov dl,31h  ; cijfer 1
	mov bl,al   ; AL wordt beïnvloedt door int 21h verderop
	inc bl		; eentje bijtellen
lus:
	mov ah,02h  ; karakter schrijven
	int 21h
	inc dl      ; teller verhogen
	cmp dl,bl   ; vergelijken met eindwaarde
	jnz lus     ; conditioneel springen

	mov ah,08h  ; karakter inlezen
	int 21h
	mov ah,4Ch  ; afsluiten
	int 21h
end start</programlisting>
</section>
<section id="_soorten_geheugens">
<title>Soorten geheugens</title>
<simpara>Tussen de verschillende soorten geheugens kan een onderscheid gemaakt worden op een aantal vlakken.</simpara>
<section id="_behuizing">
<title>Behuizing</title>
<simpara>Het meest tastbare onderscheid kan gemaakt worden op het vlak van de behuizing. Origineel gebruikte men op de PC geheugen onder de vorm van discrete chips.<?asciidoc-br?>
Naarmate de capaciteit van het geheugen steeg, werd dit te duur en ging men over op geheugenmodules.</simpara>
<simpara>Daarnaast spreekt men soms van het gebruik van geheugenbanken. Een geheugenbank op een moederbord bestaat uit een of meerdere sockets of geheugenvoeten (insteekplaatsen voor geheugenchips).
Het aantal sockets per geheugenbank hangt af van de uitvoeringsvorm van het gebruikte geheugen en van de breedte van de databus. Een geheugenbank heeft dezelfde breedte als de databus die voor de aansluiting op de datalijnen zorgt.</simpara>
<simpara>Niet alle geheugenbanken moeten gevuld zijn maar iedere geheugenbank waar geheugen in geplaatst werd, moet volledig gevuld zijn. In moderne systemen vult een module een volledige geheugenbank en is deze dus automatisch vervuld. Een geheugenmodule wordt gekenmerkt door het aantal contactpunten (pins), de werkspanning en het soort geheugenchip. Het is de geheugencapaciteit van alle chips samen die de capaciteit van de module bepalen.</simpara>
<simpara>Langs beide zijden van een geheugenmodule bevinden zich contactpunten. Indien deze contactpunten inwendig verbonden zijn spreekt men van een SIMM (Single Inline Memory Module). Indien deze contactpunten afzonderlijk werken en niet verbonden zijn spreekt men over een DIMM (Dual Inline Memory Module).
Een DIMM biedt op dezelfde afstand veel meer contactpunten en wordt dan ook toegepast in de moderne modules, die onder andere voor de steeds breder wordende databussen extra contactpunten nodig hebben.</simpara>
<figure>
<title>Courante DDR-dimm modules (Wikimedia public domain)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/DDR_Memory_Comparison.svg.png" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>DDR-dimm</phrase></textobject>
</mediaobject>
</figure>
<simpara>Een variante van DIMM is so-DIMM (small outline), een miniatuurversie van DIMM, specifiek geschikt voor mobiele apparatuur als laptops.</simpara>
<figure>
<title>SO-DIMM modules (Wikimedia public domain)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/Laptop_SODIMM_DDR_Memory_Comparison_V2.svg.png" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_technologie">
<title>Technologie</title>
<simpara>Een zeer belangrijk onderscheid tussen geheugens kan gemaakt worden op het vlak van de technologie die gebruikt werd om de geheugencellen te bouwen. Er zijn twee soorten: statisch en dynamisch geheugen. Statisch geheugen is opgebouwd uit actieve geheugencellen (flipflop schakelingen). Deze vragen een grotere complexiteit bij het IC ontwerp en zijn dus duur. Anderzijds zijn ze zeer snel. Uit deze eigenschappen kan je afleiden dat ze hoog in de piramide worden toegepast. Meer bepaald gebeurt dit bij de snelle cache geheugens.</simpara>
<figure>
<title>voorstelling statisch geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/statisch.jpg" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>statisch geheugen</phrase></textobject>
</mediaobject>
</figure>
<simpara>Dynamisch geheugen bestaat in essentie eigenlijk gewoon uit een condensator. Als je over een condensator een gelijkspanning aanbrengt en die vervolgens wegneemt, kan je achteraf nog meten welk spanning erop stond. Dit is een vorm van geheugen. Deze geheugens hebben twee belangrijke nadelen. Ten eerste zal een leesoperatie de condensator ontladen.</simpara>
<figure>
<title>Voorstelling leescyclus dynamisch geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/406px-Square_array_of_mosfet_cells_read.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>leescyclus dynamisch geheugen</phrase></textobject>
</mediaobject>
</figure>
<simpara>Een leesoperatie is met andere woorden destructief. Ten tweede bestaan er geen perfecte condensatoren en vertoont dit soort geheugen dus ook een lek. Dit betekent dat mettertijd de inhoud van het geheugen verloren gaat, tenzij die ververst wordt. Bij dit soort van geheugen is dan ook een regelmatige refresh noodzakelijk. Vergeleken met statisch geheugen is dynamisch geheugen trager. Het statisch geheugen is een actieve schakeling en kan dus stroom sturen of opnemen als het gelezen wordt. Dynamisch geheugen kan niet echt stroom sturen, het is de condensator die ontladen of opgeladen wordt. Anderzijds is dynamisch geheugen dan weer goedkoper, waardoor het toegepast wordt op een lager niveau in de piramide. Meer bepaald is dit de technologie die in geheugenmodules wordt gebruikt. Deze zijn ook gangbaar bekend onder de term RAM of DRAM.
=== DRAM technologie</simpara>
<section id="_gemultiplexte_adresklemmen">
<title>Gemultiplexte adresklemmen</title>
<simpara>Dynamische RAMs hebben vanwege de grote densiteit meestal ook een grote capaciteit op de chip (tegenwoordig tot 16 Gbit per chip). Een dergelijke capaciteit betekent ook dat er heel wat adressignalen noodzakelijk zijn om een welbepaalde geheugencel te selecteren. Wanneer elk signaal op een aparte pin zou aangesloten worden, zou het noodzakelijk zijn om zeer grote behuizingen te gebruiken.
Om dit probleem te omzeilen, wordt gebruik gemaakt van gemultiplexte adreslijnen: het volledige adres wordt opgesplitst in een Column Address een Row Address.</simpara>
<simpara>Deze twee adresgedeeltes worden de een na de ander aangeboden aan de adresklemmen van het IC. Hierbij wordt gebruik gemaakt van de RAS- en CAS-klem om de twee adresgedeelten te latchen.
De snelheid van het geheugen wordt in grote mate bepaald door de toegangstijd tacc.</simpara>
</section>
<section id="_destructieve_leescyclus">
<title>Destructieve leescyclus</title>
<simpara>Eerder werd al aangegeven hoe een leescyclus de data op de condensatoren zal vernietigen. Dit is uiteraard een onaanvaardbare situatie. De oplossing ligt voor de hand. Als data gelezen is, wordt dezelfde data nadien terug weggeschreven, zodat de originele toestand hersteld wordt. Uiteraard is het niet verstandig deze taak aan de processor toe te wijzen, het is iets wat in de geheugenchips zelf geregeld moet worden. Het geheugen is, zoals in vorige paragraaf werd aangegeven, opgebouwd als een matrix van rijen met een welbepaald aantal kolommen. Naast deze matrix van dynamische geheugencellen is er ook een rij van statische geheugencellen. Op het ogenblik dat een rij-adres aangelegd wordt, zal de dynamische rij gekopieerd worden naar de statische rij. Hierbij verliest de dynamische rij dus haar inhoud. Vervolgens kan de gewenste cel gelezen worden en daarna wordt de inhoud van de statische rij weer naar de matrix gekopieerd. Hierdoor wordt de inhoud van het geheugen hersteld.</simpara>
</section>
<section id="_refresh">
<title>Refresh</title>
<simpara>Met deze kennis wordt ook duidelijk hoe een refresh georganiseerd kan worden. Op regelmatige tijdstippen zal een zogenaamde RAS-only cylcus uitgevoerd worden. Hierbij wordt eigenlijk elke rij geselecteerd, gekopieerd naar de statische rij en weer weggeschreven. Hierdoor is de originele inhoud weer op peil gebracht, op voorwaarde dat deze cyclus voldoende regelmatig herhaald wordt. Met deze manier moet niet elke cel afzonderlijk gerefreshed worden, maar wordt een volledige rij ineens hersteld.</simpara>
<figure>
<title>Dynamisch geheugen met statische buffer</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/geheugenmetstatischbuffer.png" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>dynamisch geheugen</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_bandbreedte_bij_dram">
<title>Bandbreedte bij DRAM</title>
<simpara>DRAM heeft, zoals je verder zal lezen, de eigenschap te werken met cyclussen. Om te berekenen wat de effectieve bandbreedte is (=geheugendebiet) hoor je steeds dezelfde benadering te maken:</simpara>
<simpara>"Aantal bytes die getransfereerd worden bij een cyclus"//"tijdsduur van een cyclus" =  "bandbreedte"</simpara>
<simpara>Deze erg eenvoudige benadering wordt bij de verschillende types geheugen die volgen telkens toegepast.</simpara>
</section>
</section>
<section id="_fast_page_dram_fp_dram">
<title>Fast Page DRAM (FP-DRAM)</title>
<simpara>Hierboven werd reeds beschreven hoe met gemultiplexte adresklemmen eerst een rij-adres en vervolgens een kolomadres worden doorgegeven (langs dezelfde aansluitpinnen). Het voordeel hiervan is duidelijk: minder adresklemmen.<?asciidoc-br?>
Het nadeel is dat een lees- of schrijfcyclus langer wordt. Het kost immers extra tijd om de adressen na elkaar door te geven. FP-DRAM verbetert de snelheid door cycli te combineren.</simpara>
<simpara>Zoals aangehaald bij het lokaliteitsprincipe gaan opeenvolgende cycli meestal door op naburige cyclusadressen. De kans dat meer dan een byte gelezen wordt in dezelfde rij, is dus vrij groot. FP-DRAM maakt hiervan gebruik door eenmaal een rij-adres op te geven en vervolgens een kolom te selecteren en deze te lezen of te schrijven. Onmiddellijk hierna wordt een tweede kolom geselecteerd en wordt deze gelezen of beschreven, vervolgens kan een derde kolom geselecteerd worden&#8230;&#8203;Op die manier worden een aantal cycli vermeden. Het zal relatief lang duren vooraleer het eerste geheugenwoord gelezen kan worden, terwijl de volgende minder tijd vragen.</simpara>
<figure>
<title>Fast page DRAM</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/FPM.gif" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>fast page memory</phrase></textobject>
</mediaobject>
</figure>
<simpara>In praktijk wordt er bijna steeds gewerkt met een burst van vier leescycli waarbij aangeduid wordt hoeveel klokcycli er nodig zijn per transfert, bijvoorbeeld 5-3-3-3.<?asciidoc-br?>
FP-DRAM werd gebruikt tot busfrequenties van 66 MHz.</simpara>
<simpara>Op een computersysteem met een 486 processor (32-bit databus) met 5-3-3-3 FP-DRAM geheugen aan 66Mhz betekent dit dat het maximale geheugendebiet gelijk is aan:</simpara>
<simpara>(4 "bytes"/"transfer" xx 4 "transfers"/"burst" xx 66 "Mcycli"/"sec")/(14 "cycli"/"burst")= 75 "MB"/"sec" </simpara>
</section>
<section id="_edo_ram">
<title>EDO RAM</title>
<figure>
<title>EDO-RAM</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/edo.gif" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>fast page memory</phrase></textobject>
</mediaobject>
</figure>
<simpara>Extended Data Out-RAM is een aanpassing van het Fast Page-concept. Daarbij moest de memorycontroller wachten met het aanbieden van een nieuw kolomadres tot de vorige data gelezen waren. Bij EDO-RAM blijven de data op de uitgangen van het geheugen nog een tijd langer beschikbaar (zelfs tot na het aanbieden van het volgende kolomadres). Hierdoor wint men tijd: terwijl de data gelezen worden, kan men al het volgende kolomadres aanleggen.
EDO-RAM kon gebruikt worden tot een busklok van 75 MHz met een timing van 5-2-2-2 klokcycli. Als we EDO-RAM dan nog combineren met een 64-bit bus (Pentium) geeft dit een maximaal debiet van 218 MB/s</simpara>
<simpara>(8 "bytes"/"transfer" xx 4 "transfers"/"burst" xx 75 "Mcycli"/"sec")//(11 "cycli"/"burst")=218 "MB"/"sec" </simpara>
</section>
<section id="_synchronous_dram">
<title>Synchronous DRAM</title>
<figure>
<title>afbeelding 20 Leesoperatie bij SD-RAM (bron: Micron)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/timing/SDRAM_read.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Bij SDRAM gaat men nog een stap verder met het lokaliteitsprincipe. In plaats van uit te gaan van het lezen van naburige kolommen, wordt nu vertrokken van het idee dat opeenvolgende kolommen uitgelezen zullen worden. In het deel over cache geheugens zal duidelijk worden dat het RAM geheugen effectief op deze manier wordt aangesproken. De cyclus kan nu aangepast worden tot het aanleggen van een rij-adres, het selecteren van een kolom en vervolgens het inlezen of naar buiten brengen van een aantal opeenvolgende kolommen. Die kunnen naar buiten gebracht worden op het tempo van de klok. Vandaar spreekt men over synchroon DRAM.+
In de afbeelding krijgen we een timing van 2-1-1-1. Daarnaast is SD-RAM geschikt voor busfrequenties tot 133 MHz (PC133), wat neerkomt op een maximaal debiet van 851 MBps.</simpara>
<simpara>(8 "bytes"/"transfer"  xx 4 "transfers"/"burst"  xx 133 "Mcycli"/"sec" )//(5 "cycli"/"burst") = 851 "MB"/"sec"</simpara>
<section id="_ddr_sdram_ddr2_ddr3">
<title>DDR SDRAM - DDR2 - DDR3</title>
<simpara>Principieel werkt DDR op dezelfde manier als SDRAM. Er wordt nog steeds een rij-adres en een kolomadres aangelegd, waarna meerdere opeenvolgende cellen worden uitgelezen. Het verschil zit in het tempo waarop dit gebeurt. Bij Double Data Rate wordt data naar buiten gebracht op stijgende en dalende flank van de klok. Om dit te kunnen bereiken wordt gebruik gemaakt van een prefetch buffer. In elke cyclus worden nu 2 bits getransfereerd naar het prefetch buffer, dat de data dan aan een dubbele snelheid naar buiten kan brengen.</simpara>
<figure>
<title>Write cyclus bij DDR-RAM (bron: Micron)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/timing/DDRwritetiming.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>sd ram read</phrase></textobject>
</mediaobject>
</figure>
<simpara>Het voordeel van deze werkwijze is een hogere maximale bandbreedte (datasnelheid bij het effectief overbrengen van data). Het nadeel zit in een hogere latentietijd. Tussen het aanleggen van de adressen en het naar buiten brengen van de data verloopt iets meer tijd. De snelheid van de modules wordt uitgedrukt op een aantal verschillende manieren. Een eerste manier is in de naam, waar twee verschillende mogelijkheden bestaan. DDR400 en PC3200 duiden op hetzelfde soort geheugenchips. De 400 duidt de kloksnelheid aan (2x200MHz), de 3200 duidt de maximale transfersnelheid aan.</simpara>
<simpara>Op een 64-bit databus is die:</simpara>
<simpara>8 "bytes"/"transfer"  xx (2 xx 200 "MHz") = 3200 "MB"/"sec"</simpara>
<simpara>Er kan echter nog veel verschil zijn tussen twee PC3200 modules.
De werkelijke snelheid hangt namelijk ook af van de totale latentietijd. Die kan op verschillende manieren worden aangegeven, maar een gangbare manier is het opgeven van vier getallen: TCL-Trcd-Trp-Tras.</simpara>
<itemizedlist>
<listitem>
<simpara>T<subscript>CL</subscript> = CAS Latency Time: tijd tussen CAS en beschikbaar worden van data</simpara>
</listitem>
<listitem>
<simpara>T<subscript>rcd</subscript> = DRAM RAS to CAS Delay: tijd tussen RAS en CAS (ook tijd tussen active en read/write-commando )</simpara>
</listitem>
<listitem>
<simpara>T<subscript>rp</subscript> = DRAM RAS Precharge: tijd tussen selecteren van twee rijen</simpara>
</listitem>
<listitem>
<simpara>T<subscript>ras</subscript> = Precharge delay: minimale tijd tussen actief worden en precharge van volgende rij.</simpara>
</listitem>
</itemizedlist>
<simpara>In elke leescyclus is zeker T<subscript>rcd</subscript> en T<subscript>CL</subscript> nodig. Indien bursts uit verschillende rijen nodig zijn, dan is ook Trp belangrijk.</simpara>
<simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="./images/icons/globe.png"/>
</imageobject>
<textobject><phrase>globe</phrase></textobject>
</inlinemediaobject> Een goed achtergrondartikel dat dieper ingaat op timings en performantie van geheugen vind je <ulink url="http://www.anandtech.com/show/3851/everything-you-always-wanted-to-know-about-sdram-memory-but-were-afraid-to-ask/4">op de site van Ars Technica</ulink></simpara>
<figure>
<title>DDR-timing Tcl=2 (bron: Micron)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/TCL.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>TCL</phrase></textobject>
</mediaobject>
</figure>
<formalpara>
<title>Voorbeeld</title>
<para>
<screen>PC3200 geheugen met parameters 2-2-2-6 heeft voor een burst met vier transfers van 8 bytes 2 + 2 + (4 x 0.5)=6 klokcycli van 200 MHz nodig. Dit geeft een snelheid van 1067 MB/s.Voor twee dergelijke opeenvolgende transfers zijn

stem:[2(2+2+4 xx 0.5) + 2 = 14 klokcycli] van 200 MHz nodig. Dit geeft 914 MBps.</screen>
</para>
</formalpara>
<simpara>Bij DDR kan ook het aantal cellen dat in een burst gelezen wordt variëren. Hetzelfde geheugen dat in een burst 8 transfers van 8 bytes uitvoert, haalt een snelheid van 1600MBps.T<subscript>ras</subscript> is in dit verhaal niet naar voor gekomen. Tras bepaalt de tijd waarin de volgende rij nog niet geladen mag worden. Deze moet groot genoeg zijn om de buffer niet te overschrijven voordat het volledig getransfereerd is over de databus. Deze parameter moet minimaal T<subscript>rcd</subscript> +  T<subscript>CL</subscript> + 1 bedragen. Indien de parameter te klein is gaat uiteraard data verloren.</simpara>
<simpara>Opvolgers van DDR zijn DDR2 en DDR3. Behalve verbeteringen op het vlak van klokfrequenties en spanningen (DDR2 en DDR3 gebruiken telkens lagere spanningen) is het grootste verschil dat het prefetch buffer vergroot. Bij DDR2 worden vier bits gebufferd, bij DDR3 acht.<?asciidoc-br?>
DDR4, dat sinds kort beschikbaar is, verdubbelt dit <emphasis role="strong">niet</emphasis> nog eens , maar probeert de extra performantie vooral te halen uit hogere klokfrequenties en geoptimaliseerde signalering. Daarnaast geeft deze nieuwste specificatie ook de mogelijkheid om 3D-geheugen te gebruiken, waarbij meerdere lagen geheugen op elkaar kunnen gestapeld worden binnen dezelfde chips. <xref linkend="CORS"/></simpara>
<simpara>Het gevolg is dat deze geheugens nog sneller data naar buiten kunnen brengen (hogere maximale transfer), maar dat dit weer een hogere latentietijd met zich meebrengt. Hou wel in gedachten dat slechts een klein stukje van het geheugen aan deze hoge snelheid werkt. Intern wordt nog steeds een relatief lage snelheid gebruikt om de cellen te beschrijven, maar door de buffers kan data toch aan een dubbele (DDR), viervoudige (DDR2) of achtvoudige (DDR3) snelheid naar buiten gebacht worden.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>DDR3 snelheden (bron: wikipedia)</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Type geheugen</entry>
<entry align="left" valign="top">Alternatieve naam</entry>
<entry align="left" valign="top">kloksnelheid</entry>
<entry align="left" valign="top">Theoretische bandbreedte</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>PC3-10600 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1333</simpara></entry>
<entry align="left" valign="top"><simpara>167 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>10.667 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-11000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1375</simpara></entry>
<entry align="left" valign="top"><simpara>172 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>11 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-12800 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1600</simpara></entry>
<entry align="left" valign="top"><simpara>200 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>12.8 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-13000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1625</simpara></entry>
<entry align="left" valign="top"><simpara>203 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>13 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-14400 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1800</simpara></entry>
<entry align="left" valign="top"><simpara>225 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>14.4 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-14900 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1866</simpara></entry>
<entry align="left" valign="top"><simpara>233 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>14.933 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-15000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-1866</simpara></entry>
<entry align="left" valign="top"><simpara>233 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>14.933 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-16000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-2000</simpara></entry>
<entry align="left" valign="top"><simpara>250 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>16 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-17000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-2133</simpara></entry>
<entry align="left" valign="top"><simpara>266 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>17.066 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-17600 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-2200</simpara></entry>
<entry align="left" valign="top"><simpara>275 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>17.6 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-19200 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-2400</simpara></entry>
<entry align="left" valign="top"><simpara>300 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>19.2 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-21300 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-2666</simpara></entry>
<entry align="left" valign="top"><simpara>333 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>21.3 GB/s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PC3-24000 					DDR3 SDRAM</simpara></entry>
<entry align="left" valign="top"><simpara>DDR3-3000</simpara></entry>
<entry align="left" valign="top"><simpara>375 MHz</simpara></entry>
<entry align="left" valign="top"><simpara>24 GB/s</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Een belangrijke opmerking, die reeds gedeeltelijk aangehaald werd, is dat DDR, DDR2, DDR3 en DDR4 gebruik maken van een andere werkspanning. Deze wordt alsmaar lager om het gedissipeerd vermogen en de bijhorende warmteontwikkeling te verkleinen, wat nodig is om hogere kloksnelheden toe te laten. Bij DDR was dit nog 2,5 Volt, bij DDR4 is dit ondertussen verminderd tot 1.2 Volt <xref linkend="CORS"/><?asciidoc-br?>
Bovendien hebben de modules ook een verschillend aantal aansluitpinnen, waardoor het duidelijk zal zijn dat ze niet compatibel zijn.</simpara>
<simpara>Om ongelukken te vermijden wordt daarom een andere behuizing gebruikt (inkeping in de module zit op een andere plaats).</simpara>
</section>
</section>
<section id="_optimalisatietechnieken">
<title>Optimalisatietechnieken</title>
<simpara>De evolutie in DRAM technologie is er steeds op gericht om de maximale bandbreedte te verbeteren, terwijl bijzonder weinig aan de latentietijd werd gedaan. Deze verbeterde hooguit in absolute waarde, doordat de kloksnelheid verhoogde. Relatief gezien (dus uitgedrukt in klokcycli) is de latentietijd eerder gestegen. Uit het voorgaande zou al gebleken moeten zijn dat na elke rijtoegang een hersteltijd nodig is om de bufferrij(en) vrij te maken.</simpara>
<figure>
<title>normale geheugentoegang</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/optimalisatie/MEMACCESS_normal.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<section id="_interleaving">
<title>Interleaving</title>
<simpara>Een techniek die gebruikt kan worden om een deel van de dode tijd te vermijden, is interleaving. Meer bepaald gaat het dan om het vermijden van de tijd tussen twee rijen.
Deze hersteltijd kan vermeden worden indien de volgende operatie doorgaat op een andere geheugenmodule. Om dit te bereiken worden bij interleaving naburige geheugenblokken verdeeld over verschillende geheugenbanken, die onafhankelijk van elkaar (en dus zonder hersteltijd) aangesproken kunnen worden. Belangrijke opmerking hierbij is dat er enkel snelheidswinst kan zijn als er gewisseld kan worden tussen banken. Het is dan ook belangrijk dat de memory controller weet of er al dan niet gewisseld kan worden tussen banken, zodat hij al dan niet rekening kan houden met de hersteltijd.</simpara>
<figure>
<title>Memory interleaving</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/optimalisatie/MEMACCESS_interleaving.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>interleaving</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_dual_channel">
<title>Dual channel</title>
<simpara>Een andere heel eenvoudige techniek om de snelheid te verhogen is het vergroten van de databus. Dit brengt wel een paar problemen met zich mee. Eerst en vooral moeten er extra aansluitingen voorzien worden op zowel de geheugenmodule als het moederbord en bovendien moeten de signaallijnen ook voorzien worden op het moederbord. Daarnaast zal er, zeker bij steeds toenemende kloksnelheden, een probleem ontstaan van tijdverschillen tussen de verschillende datalijnen.</simpara>
<simpara>Dual channel is een techniek die probeert de datasnelheid te verhogen door de databus naar de memory controller te verdubbelen, zonder de databus van de geheugenmodules te vergroten. Dit gebeurt weer door gebruik te maken van verschillende geheugenbanken. Elke geheugenbank heeft een databus van 64 bit, maar aangezien deze niet samenvallen is er een 128 bit databus naar de memory controller. De DIMM sockets op een moederbord zijn dus fysiek verbonden met één van de twee 64 bit kanalen. Uiteraard kan je enkel voordeel halen als geheugenmodules aangesloten zijn op de twee kanalen.</simpara>
<figure>
<title>geheugentoegang met Dual Channel</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/optimalisatie/MEMACCESS_dualchannel.png" align="center"/>
</imageobject>
<textobject><phrase>dual channel</phrase></textobject>
</mediaobject>
</figure>
<simpara>Behalve het aanschakelen van meerdere modules is het dan ook belangrijk om ze in de juiste sockets te steken, zodat je beide kanalen gebruikt (en niet twee modules op hetzelfde kanaal). Moederborden met meerdere sockets op de kanalen, hebben overeenkomstige plaatsen op die kanalen die eenzelfde kleur hebben. Op deze manier zijn er dus matched sockets. Op deze matched sockets moet dus geheugen geïnstalleerd worden.</simpara>
<figure>
<title>dual channel sockets</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/optimalisatie/Dual-channel_DDR_memory_use_6026.JPG" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>dual channel memory placement</phrase></textobject>
</mediaobject>
</figure>
<simpara>Dit geheugen moet identiek zijn in capaciteit, anders zou een deel van het geheugen niet bereikbaar zijn in dual channel mode. Verder moeten de modules in principe niet gelijk zijn. Zelfs modules met verschillende snelheden zijn mogelijk, al zal dan tegen de traagste snelheid gewerkt worden. In principe betekent dit echter dat er in de praktijk wel problemen kunnen ontstaan, zodat moederbord fabrikanten het gebruik van identieke modules aanraden. Deze worden door verschillende geheugenfabrikanten ook aangeboden.</simpara>
<simpara>Hoewel dual channel een veelbelovende techniek is, blijkt uit benchmarks dat de winst (ondertussen) toch marginaal is. Een deel van de verklaring hiervoor zou liggen in het cache geheugen, dat steeds groter en efficiënter wordt. Later zullen we zien dat de cache geheugens het snelheidsverschil tussen geheugen en processor moeten opvangen. Je kan trouwens zelf aan de berekeningen bij DDR al zien dat dual channel weinig invloed heeft, tenzij echt grote opeenvolgende stukken gelezen worden. Vergelijk de tijd die nodig is voor een burst van 4 transfers met die voor een burst van 8 transfers. Op een dual channel systeem zullen de bursts immers maar half zo groot zijn als bij single channel.</simpara>
</section>
<section id="_buffered_registered_ram_en_foutdetectie">
<title>Buffered/registered RAM en foutdetectie</title>
<simpara>Een term die regelmatig terug te vinden is bij RAM geheugen is (un)buffered of registered. De termen buffered en registered hebben dezelfde betekenis. Op basis van de eerdere uitleg zou je kunnen vermoeden dat elk DRAM geheugen gebufferd is met de statische bufferrij. De term buffered slaat in dit geval niet op die statische rij, maar wel op de aanwezigheid van een extra bufferchip. Deze bufferchip doet dienst als elektrisch buffer/versterker tussen de geheugenIC’s en de rest van het systeem. Op die manier kan het bijvoorbeeld problemen met onvoldoende stroom helpen oplossen. De bufferchip is dikwijls te herkennen aan zijn dwarse plaatsing op de module.</simpara>
<simpara>Twee andere termen die je kan terugvinden zijn (non)ECC en parity. Beiden houden verband met het vermogen van het geheugen om fouten te laten detecteren. In het geval van pariteit wordt per byte een pariteitsbit berekend. Dit bit wordt mee verzonden. De ontvanger herberekent de pariteitsbit en vergelijkt het resultaat van zijn berekening met het ontvangen pariteitsbit. Indien ze verschillen is er een fout geweest en moet de transfer opnieuw gebeuren.</simpara>
<simpara>ECC werkt op gelijkaardige manier, maar maakt gebruik van een hash functie. Voordeel van deze manier van werken is dat meervoudige bitfouten gedetecteerd kunnen worden of dat enkelvoudige bitfouten gecorrigeerd kunnen worden. Pariteit kan enkel enkelvoudige bitfouten detecteren. Uiteraard kost deze foutcontrole ook rekenkracht en dus tijd. Door de betrouwbaarheid van moderne geheugens hebben deze technieken enkel zin in kritische toepassingen (bijvoorbeeld servers, procescontrole, &#8230;&#8203;)</simpara>
</section>
</section>
<section id="_cache_geheugen">
<title>Cache geheugen</title>
<simpara>Zelfs met alle optimalisatietechnieken blijft er een snelheidsprobleem. Instructies die de processor moet uitvoeren, zitten in het geheugen en als de snelheid waarmee het geheugen instructie kan leveren, vergeleken wordt met de snelheid waarmee de processor ze kan uitvoeren, blijkt die laatste een stuk sneller.
Een belangrijk verschil, want een processor kan nu eenmaal niet sneller instructies afwerken dan dat ze door het geheugen aangeboden kunnen worden. Sneller geheugen maken, ligt voor de hand. Zoals eerder al aangehaald is statisch geheugen sneller dan dynamisch geheugen.</simpara>
<simpara>Belangrijk nadeel van statisch geheugen is dat het per byte veel duurder is dan dynamisch geheugen. De hoeveelheid statisch geheugen in een computersysteem zal dus eerder klein zijn en het komt erop aan deze kleine hoeveelheid zo efficiënt mogelijk te gebruiken. Een tweede probleem is dat niet enkel de snelheid van het geheugen problemen geeft, maar ook de snelheid van de interface naar het geheugen. Om dit probleem aan te pakken was er ooit een snelle back-side bus die de verbinding met het cache geheugen verzorgde. Ondertussen zijn er al verschillende niveaus van cachegeheugens in de processor geïntegreerd, zodat de verbinding met dit geheugen ook in de processor zelf zit en daardoor veel sneller kan zijn.</simpara>
<section id="_werking">
<title>Werking</title>
<figure>
<title>Cache als buffer tussen CPU en geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/cache.png" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>cache als buffer</phrase></textobject>
</mediaobject>
</figure>
<simpara>Het cache geheugen vormt een buffer die het snelheidsverschil tussen het geheugen en de CPU moet opvangen. Aangezien het cache geheugen een stuk kleiner zal zijn dan het dynamisch geheugen, komt het erop aan om de nodige gegevens klaar te hebben zitten in het cache geheugen.</simpara>
<simpara>Om dit te realiseren wordt weer uitgegaan van het lokaliteitsprincipe. Zowel het cache geheugen als het hoofdgeheugen worden onderverdeeld in blokken van dezelfde grootte. De blokken in het cache geheugen (cache lines) kunnen een kopie bevatten van een blok uit het hoofdgeheugen.</simpara>
<simpara>Een leescyclus verloopt als volgt:</simpara>
<simpara>#de processor vraagt een adres
#Indien dat adres in een blok ligt dat in de cache te vinden is, wordt er gesproken van een cache-hit en heeft er een snelle leescyclus plaats vanuit de cache.
#In het andere geval (een cache-miss) wordt via een trage leescyclus het gevraagde woord opgehaald uit het centrale geheugen terwijl ook onmiddellijk het blok waarin dit woord zich bevindt naar de cache gekopieerd wordt.</simpara>
<simpara>Aangezien opeenvolgende geheugentoegangen meestal op naburige adressen doorgaan, is de kans groot dat een volgende toegang een cache-hit geeft en dus snel verwerkt kan worden.<?asciidoc-br?>
Een belangrijke parameter voor de snelheid van het cache geheugen is dus de hitrate. Dit is het percentage geheugentoegangen dat rechtstreeks via het snelle cache geheugen kan verlopen. De hitrate ligt typisch tussen 80 en 99%.</simpara>
<simpara>Een schrijfcyclus kan gelijkaardig verlopen, maar er stelt zich wel een nieuw probleem.+
In het geval van een schrijfcyclus worden er immers gegevens aangepast. Indien er een cache-hit is, lijkt het logisch om de inhoud van het cache geheugen aan te passen en pas later (bij het verwijderen van de cacheline) wordt de inhoud van het hoofdgeheugen aangepast. Deze manier van werken heet write-back cache.
Belangrijk nadeel hiervan is dat op een bepaald ogenblik de inhoud van het hoofdgeheugen niet consistent is met het cache geheugen. Dit kan bijvoorbeeld bij DMA-toegangen problemen opleveren. Tweede nadeel is dat het wegschrijven naar het geheugen gebeurt op het ogenblik dat de pagina uit het cache geheugen verwijderd wordt. Dit is het ogenblik waarop in het cache geheugen plaats gemaakt wordt voor een nieuwe pagina. Dit vertraagt dus het inladen van de nieuwe pagina.</simpara>
<simpara>Een alternatief is gebruik maken van write through cache. In dit geval worden steeds zowel het hoofdgeheugen als het cache geheugen aangepast. Nadeel is duidelijk dat steeds gebruik gemaakt wordt van het tragere hoofdgeheugen.</simpara>
<simpara>Dit kan gedeeltelijk opgevangen worden doordat de processor niet moet wachten tot de volledige cyclus is afgewerkt, maar bij opeenvolgende schrijfopdrachten zal het toch leiden tot vertragingen. Bij schrijfcycli zijn er nog verschillen mogelijk: write allocate en write no-allocate. Bij write allocate zal bij een cache miss het geheugenblok in het cache geheugen geladen worden, bij write no-allocate niet.</simpara>
<simpara>Het voordeel is dat een schrijfoperatie naar het geheugen typisch sneller is dan het ophalen van een volledig blok. Bijvoorbeeld bij write-through geheugen is makkelijk in te zien dat het interessant kan zijn om het blok niet volledig in te laden.</simpara>
</section>
<section id="_soorten_caches">
<title>Soorten caches</title>
<simpara>Er zijn een aantal onderscheiden te maken tussen cache geheugens. Een eerste belangrijk verschil is dat tussen level 1 en level 2 caches. In principe zijn zelfs nog meer niveau’s van cache geheugens mogelijk.
L1 cache is het cache geheugen dat het dichtst bij de processor staat. Het moet dan ook het snelste geheugen zijn, zodat het de processor kan volgen. Naarmate de snelheid van de processor toeneemt, werd het verschil in snelheid zo groot dat het interessant werd om een tweede niveau buffer in te zetten. Dit geheugen is minder kritisch op het vlak van snelheid (het moet de processor niet rechtstreeks voorzien van gegevens) en kan dus op andere vlakken geoptimaliseerd worden. Zo zal L2 cache typisch minder snel, maar wel een stuk groter zijn.</simpara>
<simpara>Een ander verschil tussen cache geheugens is dat L1 cache dikwijls opgedeeld worden in data cache en instructie cache. Hiervoor zijn verschillende redenen te bedenken. Een belangrijke reden is dat met pipelining, een deel van de processor (instruction fetch unit) instructies ophaalt en tegelijkertijd een ander deel (operand fetch) gegevens ophaalt om de bewerkingen uit te voeren.</simpara>
<simpara>Als beide geheugens gescheiden zijn, kunnen de twee units onafhankelijk van elkaar hun operaties uitvoeren. Anderzijds kunnen de cache geheugens ook geoptimaliseerd worden. Zo zal een processor nooit wijzigingen aanbrengen in de instructies die hij uitvoert. Voor de instructiecache moeten geen voorzieningen getroffen worden voor schrijfoperaties.</simpara>
</section>
<section id="_overschrijfstrategieën">
<title>Overschrijfstrategieën</title>
<simpara>Bij een cache miss zal in de meeste gevallen een volledig geheugenblok ingeladen worden. Dit betekent dat in het cache geheugen plaats zal moeten gemaakt worden. Er zal met andere woorden een lijn geselecteerd moet worden, die uit het cache geheugen verwijderd zal worden. Het selecteren van die lijn moet uiteraard doordacht gebeuren om de hit rate zo hoog mogelijk te houden. In principe is het best om de cacheline te verwijderen die het langst niet zal gebruikt worden. Het probleem met deze keuze is dat er kennis over de toekomst voor nodig is. In plaats daarvan zijn er een aantal strategieën die op een andere manier proberen de meest geschikte lijn te selecteren:</simpara>
<variablelist>
<varlistentry>
<term>First In First Out (FIFO)</term>
<listitem>
<simpara>selecteert de lijn die al het langst in het cachegeheugen zit. Het is een erg eenvoudig te implementeren techniek, aangezien de lijnen eigenlijk gewoon cyclisch overschreven worden. Deze techniek is daarentegen weinig efficiënt op het vlak van het optimaliseren van de hitrate. Een lang geleden, maar veel gebruikte lijn zal bijvoorbeeld eerder verwijderd worden dan een lijn, waar maar een keer data uit gelezen wordt, maar die wel later is ingeladen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Least Recently Used (LRU)</term>
<listitem>
<simpara>selecteert de lijn die al het langst niet meer gebruikt wordt. De kans dat deze lijn dan plots weer gebruikt zal worden, is een stuk kleiner dan bij FIFO. Hierdoor zal deze techiek leiden tot een hogere hitrate. Nadeel is dan weer dat er een pak meer bij komt kijken om bij te houden welke lijn geselecteerd wordt. Deze berekening kost zowel geld (om te implementeren) als tijd (om de lijn te selecteren). In het bijzonder als uit een groot aantal lijnen gekozen moet worden, is het gebruik van deze techniek niet aangewezen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Least Frequently Used (LFU)</term>
<listitem>
<simpara>deze techniek zal de lijn selecteren die het minst frequent gebruikt wordt. De techniek haalt gelijkaardige resultaten als LRU, maar heeft ook dezelfde nadelen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Adaptive Replacement Cache (ARC)</term>
<listitem>
<simpara>combineert zowel LRU als LFU. Hierdoor worden nog betere resultaten gehaald op het vlak van hitrate, maar de bewerkingen en de implementatie ervan worden anderzijds ook complexer.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Random</term>
<listitem>
<simpara>selecteert willekeurig een lijn. Dit is een eenvoudige te implementeren techniek, die toch aanvaarbare resultaten haalt, in het bijzonder als er een groot aantal lijnen zijn waaruit geselecteerd moet worden. Deze techniek wordt soms gecombineerd met LRU, door een bit te koppelen aan een lijn. Dit bit geeft aan of de lijn al gebruikt is. Als alle lijnen gebruikt zijn, worden alle bits weer gereset. Als dan een lijn gekozen moet worden, zal random geselecteerd worden uit alle lijnen die gemarkeerd zijn als “niet gebruikt”.</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
</section>
<section id="_associativiteit">
<title>Associativiteit</title>
<simpara>De associativiteit van het cache geheugen bepaalt op welke cachelines een welbepaald geheugenblok terecht kan komen. De associativiteit bepaalt dus ook het aantal lijnen waaruit geselecteerd kan worden en bepaald dus zowel rechtstreeks (beperking van lijnen) als onrechtstreeks (welke overschrijfstrategie) mee de hitrate.</simpara>
<section id="_fully_associative_cache">
<title>Fully Associative cache</title>
<figure>
<title>principe fully associative cache</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/fullyPrincipe.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Bij fully associative cache kan een blok uit het geheugen terecht komen in gelijk welke cacheline. Om te kunnen bepalen welk geheugenblok in een bepaalde cacheline zit, wordt een elke cacheline een tag gekoppeld. Deze is nodig om te kunnen bepalen of het blok aanwezig is in het cache en eventueel de juiste cacheline te kunnen selecteren.</simpara>
<figure>
<title>voorbeeld fully associative geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/associativiteit/vbfully.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Een voorbeeld zie je in bovenstaande afbeelding.<?asciidoc-br?>
De processor beschikt over een 32-bit adresbus en een cache geheugen van 16kB met cachelines die 64-byte breed zijn. Om binnen elke cacheline het juiste byte te selecteren zijn er 6 bits nodig.<?asciidoc-br?>
Hiervoor worden uiteraard de minst significante gebruikt. De overige 26 bits worden gebruikt om de inhoud van de cacheline te identificeren. Je zou dit kunnen zien als het nummer van het geheugenblok. Merk immers op dat voor elk byte van een geheugenblok, deze 26 bits van het adres steeds overeenkomen. Het zijn dan ook deze bits die opgeslagen worden in de tag. Naast de cachelines en de tags die eraan gekoppeld zijn, zijn er een aantal comperatoren voorzien. Bij het begin van een cyclus worden deze comperatoren gebruikt om de bovenste 26 bits van het adres te vergelijken met de inhoud van de tags. Indien de uitkomst van een van de comperatoren een gelijkheid aangeeft, is er een cache-hit en is meteen ook de juiste cacheline geselecteerd.</simpara>
<simpara>In het voorbeeld zijn er 256 tags van 26 bits elk (6656 bits) die vereist zijn naast de data-cache. Dit komt neer op bijna 5% van de cache-capaciteit.
Vermits elke pagina uit het geheugen in om het even welke cache-line geplaatst kan worden, kan de cache optimaal benut worden. Bovendien kan gebruikt gemaakt worden van de optimale overschrijfstrategie. Het nadeel van associative cache is dat het een vrij dure implementatie is. Er is immers behoefte aan veel supersnel geheugen om de tags te implementeren.
Daarnaast moeten ook de snelle comparatoren gerealiseerd worden. Binnen de tijd van een cyclus moet immers geweten zijn of er een cache hit is.</simpara>
<simpara>Fully associative cache geeft goede resultaten. Indien deze techniek dan ook nog gecombineerd wordt met de meest complexe overschrijfstrategieën, wordt het geheel extreem complex en duur. Zoals al aangehaald bij de overschrijfstrategieën is hier het aantal lijnen meestal te groot om gebruik te maken van LRU, LFU of ARC, zonder daarvoor een andere prijs te betalen.</simpara>
</section>
<section id="_direct_mapped_cache">
<title>Direct mapped cache</title>
<figure>
<title>principe direct mapped cache</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/directPrincipe.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Bij direct mapped cache kan elk geheugenblok slechts in één cacheline terecht. Dit maakt dat overschrijfstrategieën overbodig zijn, er is namelijk maar een plaats waar het geheugenblok terecht kan en de inhoud van die cacheline zal verwijderd worden. Evident nadeel is dat als er geen keuze mogelijk is, de optimale keuze niet gemaakt kan worden. Deze manier van werken heeft dus een negatief effect op de hitrate.
Om dit te staven met een extreem voorbeeld: bij direct mapped cache is het mogelijk dat een cacheline plaats moet maken voor een andere, terwijl een deel van het cache nog niet in gebruik is. Doordat een geheugenblok maar op een lijn terecht kan, worden de tags kleiner en is er ook slechts een comparator nodig.</simpara>
<figure>
<title>voorbeeld direct mapped</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/associativiteit/vbdirectmapped.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Een voorbeeld zal dit verduidelijken&#8230;&#8203;
De processor beschikt overeen 32-bit adres bus en een cache geheugen van 16kB met cachelines die 64-byte breed zijn. Naast de zes bits die nodig zijn om een byte binnen de cacheline te  selecteren, zijn er nu ook acht bits nodig om een van de 256 (=16kB/64B) lijnen te selecteren. Op die manier blijven er maar 18 bits over voor de tag. Dit soort cache-organisatie is dus veel goedkoper en eenvoudiger dan de vorige: er is slechts 1 comparator (van 18 bits) nodig, en het tag-gedeelte is ook kleiner: 256 x 18 bits (4608 bits, 3,4%). Dit soort cache wordt toegepast op plaatsen waar de snelheid minder kritisch is, met andere woorden in de caches die verder van de processor staan.</simpara>
</section>
<section id="_set_associative_cache">
<title>Set-associative cache</title>
<figure>
<title>principe set-associative cache</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/setAssociative.jpg" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Set-associative cache is de tussenvorm. Hierbij worden de cachelines gegroepeerd in sets. Elk geheugenblok kan terecht in slechts een set, maar binnen die set kan het in elke cacheline terecht.</simpara>
<figure>
<title>voorbeeld set associative</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/associativiteit/vbsetassociative.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>set associative voorbeeld</phrase></textobject>
</mediaobject>
</figure>
<example>
<title>voorbeeld</title>
<simpara>Een voorbeeld: een processor met een 32-bit brede adresbus en 16kB 4-way set associative cache geheugen met cachelines van 64 byte. 4-way betekent dat een set bestaat uit vier cachelines. De 256 lijnen worden nu verdeeld in 256/4=64 sets.</simpara>
<simpara>Zes bits zijn nog steeds nodig om een byte in de cache line te selecteren. Daarnaast zijn er nu een aantal bits nodig om een set te kiezen. Aangezien er 64 sets zijn, zijn er hiervoor zes bits nodig. De resterende bits (20) worden gebruikt voor de tag. Als nu een adres aangeboden wordt, wordt een set van vier lijnen geselecteerd en worden de vier tags vergeleken met de meest signicante bits van het adres. Als één van de tags gelijk is aan deze bits is er een cache hit.</simpara>
</example>
<example>
<title>voorbeeld</title>
<simpara>Rekenvoorbeeld (meer voorbeelden vind je in <xref linkend="PATT2"/> en <xref linkend="RAMA2"/>)</simpara>
<simpara><emphasis role="strong">Opgave:</emphasis>
Een 4-way set associative cache heeft een grootte van 64KB. De CPU werkt met 32-bit addressering, elk geheugenwoord bevat 4 bytes. Elke cache-line bevat 16 bytes. De cache gebruikt een write-through policy.
Bereken de totale benodigde hoeveelheid geheugen (geheugen+tags) die nodig is om dit te implementeren…</simpara>
<simpara><emphasis role="strong">Antwoord:</emphasis></simpara>
<simpara>het aantal bits is een adres is 32 <emphasis role="strong">(a)</emphasis><?asciidoc-br?>
Een cacheline omvat 16 bytes, wat betekent dat de vier <emphasis role="strong">(b)</emphasis> LSB’s niet moeten geadresseerd worden.<?asciidoc-br?>
Het aantal sets is dan 64KB/(4*16) = 1024 <emphasis role="strong">(c)</emphasis><?asciidoc-br?>
Het aantal bits dat nodig is om deze te kunnen adresseren: log<subscript>2</subscript> 1024= 10 bits <emphasis role="strong">(d)</emphasis><?asciidoc-br?>
Het aantal tag bits wordt dan: 32 – 4 (b) – 10 (d) = 18 bits<?asciidoc-br?></simpara>
<simpara>Om de totale grootte dan te berekenen kan je redeneren:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Elke cachelijn heeft 16 bits data, en een tag van 18 bits. Dit komt op een totaal van 146 bits.</simpara>
</listitem>
<listitem>
<simpara>Dit moet je met vier vermenigvuldigen (‘4’-way) en met het aantal sets (d), wat resulteert in 598016 bits.</simpara>
</listitem>
</itemizedlist>
<simpara>Het percentage overhead is dus (totaal benodigde bits)/('nuttige' bits)   of 14%</simpara>
</example>
<tip>
<simpara>bereken aan de hand van vorig voorbeeld hoe de overhead zich gedraagt bij 8-way en 16-way cache geheugen.</simpara>
</tip>
<simpara>Zoals al gezegd is set associative de tussenvorm. Eigenlijk kan je zeggen dat fully associative cache ook set associative cache is, maar met slechts één set. Direct mapped cache is anderzijs set associative met slechts één lijn per set.<?asciidoc-br?>
De eigenschappen van set associative liggen dan ook tussen de twee vormen in.
Het laat minder mogelijkheden voor het kiezen waar een cacheline terecht kan dan fully associative, maar meer dan direct mapped. Anderzijds heeft het minder bits nodig voor de tags en ook minder comparatoren dan bij fully associative cache. Vergeleken met direct mapped is het dan weer complexer.
Meer algemeen geldt dat naarmate de associativiteit toeneemt er meer keuze is in de cache lijnen, maar dat de kost die hieraan verbonden is ook hoger wordt. Omwille van de beperking van het aantal cachelines in een set is set-associative cache gemakkelijker te combineren met betere overschrijfstrategieën. Mede daardoor is fully associative cache een eerder zeldzame vorm van cache.</simpara>
<simpara>Opmerking: in literatuur worden de termen ‘cache line’, ‘cache block’, ‘cache entry’ en ‘cache set’ vaak door elkaar gebruikt. [4]</simpara>
</section>
<section id="_snelheid_van_de_cache">
<title>Snelheid van de cache</title>
<simpara>In het voorgaande hebben we reeds een aantal eigenschappen aangehaald die mee de efficiëntie van het cache geheugen bepalen. Dit is uiteraard een heel belangrijke eigenschap, aangezien bij cache hits, de processor aan zijn volle snelheid kan werken.</simpara>
<figure>
<title>cache misses in functie van grootte en associativiteit (bron: wikipedia)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/associativiteit/400px-Cache_missrate.png" align="center"/>
</imageobject>
<textobject><phrase>cash miss-rate</phrase></textobject>
</mediaobject>
</figure>
<simpara>In bovenstaande afbeelding toont een grafiek het aandeel missers in functie van de grootte van het cache geheugen en dit voor verschillende associativiteit.
Een deel van de missers zijn onvermijdelijk. Het zijn de zogenaamde coldstart misses, die afkomstig zijn van de eerste keer dat toegang tot een blok gezocht wordt.
Een tweede deel hangt samen met de capaciteit. Dit neemt duidelijk af naarmate het cache geheugen groter wordt.
Een derde deel hangt samen met de associativiteit. In deze grafiek komt duidelijk naar voor dat met toenemende associativiteit het aantal missers afneemt. Naast de hitrate zijn er nog een aantal andere eigenschappen, die samen de snelheid van het volledige geheugen bepalen.</simpara>
<simpara>Deze eigenschappen zijn:
Hit time:: de tijd nodig om bij een hit de gegevens op te halen.
Miss time:: de tijd nodig om bij een miss het nieuwe geheugenblok te laden en de gevraagde gegevens beschikbaar te maken
Miss penalty:: de extra tijd die nodig is bij een cache miss (eigenlijk misstime-hit time)
Hit rate:: percentage toegangen die rechtstreeks langs de cache gaan</simpara>
<simpara>De formule voor de totale toegangstijd van de gecombineerde caches is dan:</simpara>
<simpara>"t"_"totaal"="HR"_"L1"  xx "t"_"L1"  + (1 - "HR"_"L1") xx "HR"_"L2"  xx t_"L2"  + (1 - "HR"_"L1") xx (1 - "HR"_"L2") x "t"_"RAM"</simpara>
<simpara>Waarbij:<?asciidoc-br?>
HR = hitrate<?asciidoc-br?>
t = aantal cycli<?asciidoc-br?></simpara>
<example>
<title>Voorbeeld</title>
<simpara>Een computer heeft een L1-cache, toegangstijd 1 ns en een hitrate van 96%. De L2 cache heeft een hitrate van 88 % bij een toegangstijd van 2 ns. Het externe geheugen heeft een toegangstijd van 8 ns.
De gemiddelde toegangstijd wordt dan:</simpara>
<simpara>0.96 xx 1 "ns" + 0.04 xx 0.88 xx 2 "ns" + 0.04 xx 0.12 * 8 "ns" = 1.0688 "ns"</simpara>
<simpara>Probeer zelf eens uit wat de invloed is van de toegangstijd van het RAM-geheugen in dit systeem. Probeer eens wat er gebeurt zonder L2 cache. De verschillende factoren worden niet op dezelfde manier beïnvloed door de eigenschappen van het cache. Bijvoorbeeld de asscociativiteit van de cache biedt meer mogelijkheden op het vlak van cachelines selecteren, waardoor de hitrate hoger kan zijn. Daar staat tegenover dat een complexere berekening nodig is om een lijn te selecteren, waardoor bij een cache miss er extra tijd verloren gaat (hogere miss time).</simpara>
</example>
<simpara>Een ander voorbeeld zijn de grootte van de cachelines. Grotere cachelines geven in eerste instantie een hogere hit rate, omdat meer naburige gegevens gekopieerd worden.
Anderzijds zijn grotere cachelines nefast voor de miss time. Bij heel grote cachelines zal bovendien zelfs de hitrate dalen, omdat lijnen te snel uit het cachegeheugen verdwijnen (omdat bij dezelfde grootte er nu eenmaal minder lijnen zijn).</simpara>
<simpara>Een groter cachegeheugen geeft dan weer meer cachelines. Mits een goede overschrijfstrategie toegepast wordt en de associativiteit hoog genoeg is, kan de hit rate toenemen. Nadeel is dat de selectie van een lijn dan weer complexer wordt waardoor de miss time weer toeneemt.</simpara>
</section>
</section>
<section id="_virtueel_geheugen">
<title>Virtueel geheugen</title>
<simpara>Virtueel geheugen is een oplossing om het tekort aan fysiek geheugen op te lossen. Het tekort aan geheugen komt van steeds groter wordende toepassingen en bestanden die bewerkt worden. Bovendien worden ook verschillende programma’s naast elkaar uitgevoerd. Toch zijn er vandaag ook een aantal situaties waarin een computer ruim voldoende heeft met het fysieke geheugen. In dat geval biedt virtueel geheugen weinig meerwaarde.</simpara>
<section id="_werking_2">
<title>Werking</title>
<simpara>Virtueel geheugen zal gebruik maken van de beschikbare ruimte op een of ander medium voor massaopslag om het geheugen groter te laten lijken.</simpara>
<simpara>Meestal zal het gebruikte medium een harde schijf zijn. We zullen hier in het volgende van uitgaan.
Op de harde schijf zal ruimte voorzien worden die gebruikt wordt als swapruimte. Het kan een swap-file zijn of een swap-partitie. Indien de processor toegang wil tot een bepaald adres, zal aan de hand van het adres nagegaan worden of de gevraagde gegevens aanwezig zijn in het fysieke geheugen. Indien de gegevens in het fysieke geheugen zitten, worden ze opgehaald en wordt de instructie gewoon verder afgewerkt. Als de gegevens niet in het fysieke geheugen zitten, treedt er een page fault op. Dit is een speciale exceptie. De processor wordt met andere woorden onderbroken en zal de exceptieroutine uitvoeren. In dit geval gaat het om een roll-back exception. De processor zal eerst terugkeren naar de toestand vlak voor de uitvoering van de instructie, die het probleem veroorzaakte en vervolgens de exception handler uitvoeren. De exception handler zal indien nodig plaats maken en vervolgens de nodige gegevens verplaatsen naar het fysieke geheugen. Uiteraard zal het hier niet gaan over een byte, maar wel over een groter stuk geheugen. We zullen later terugkomen op de grootte van dit geheugenblok.</simpara>
<figure>
<title>Page-faults bij opstarten software</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/pagefaults.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>pagefaults</phrase></textobject>
</mediaobject>
</figure>
<simpara>Na de uitvoering van de handler keert de processor terug naar de toestand bij de oproep van de handler. Dit is uiteraard de instructie die in eerste instantie het probleem veroorzaakte. Deze keer zal bij de uitvoering van die instructie blijken dat de gegevens beschikbaar zijn in RAM.</simpara>
<simpara>Om virtueel geheugen te ondersteunen is, naast het opslagmedium, ook een processor nodig die de roll-back exception ondersteund. Daarnaast moet ook het besturingssysteem de nodige routines omvatten en tenslotte is er ook behoefte om bij te kunnen houden waar de gegevens zich bevinden (fysiek geheugen of swap).
Belangrijk is ook dat bepaalde delen nooit mogen verdwijnen uit het fysieke geheugen. Een voorbeeld is de handler: als die op de swap staat, is er geen routine meer beschikbaar om hem naar het fysiek geheugen te verplaatsen.</simpara>
</section>
<section id="_paging_segmenting">
<title>Paging - segmenting</title>
<simpara>De meest gebruikte manier om met virtueel geheugen te werken, is zowel de swap als het fysieke geheugen te verdelen in stukken van dezelfde grootte. Zo’n blok wordt dan een pagina genoemd. Voor elke pagina zou dan in een tabel opgeslagen kunnen worden waar de pagina zich bevindt. In deze tabel zou dan een bit aangeven of het fysiek dan wel virtueel aanwezig is en de andere bits zouden de locatie kunnen aanduiden. Uiteraard moet deze tabel ook ten allen tijde in het fysiek geheugen aanwezig blijven. Soms is het noodzakelijk om de grootte van deze tabel te beperken.</simpara>
<figure>
<title>Paging table (Wikimedia Commons, BSD)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch03/images/2000px-Virtual_address_space_and_physical_address_space_relationship.svg.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<example>
<title>Voorbeeld</title>
<simpara>Op een 32-bit processor met pagina’s van 4kB is een tabel nodig van 4MB (op voorwaarde dat de elementen van de tabel 32 bit groot zijn).</simpara>
<simpara>Om de tabellen klein te houden kan gewerkt worden met meerdere niveaus van tabellen. In het reeds aangehaalde voorbeeld zouden er 1024 tabellen van 4kB nodig zijn. Deze tabellen bevinden zich op het tweede niveau. Op het eerste niveau is er een tabel van 4kB, die toelaat een van de 1024 secundaire tabellen te selecteren.</simpara>
<simpara>Een groot voordeel is dat het enkel de eerste niveau tabel aanwezig moet zijn in het fysieke geheugen. De secundaire tabellen kunnen zich in de swapruimte bevinden.<?asciidoc-br?>
Het alternatief voor paging is werken met segmenten. In grote lijnen is het verhaal hetzelfde, er is bijvoorbeeld ook een tabel die bijhoudt waar de segmenten zich bevinden. Het grote verschil is dat de gegevens nu niet opgedeeld worden in pagina’s van gelijke grootte. Het grootste gevolg hiervan situeert zich op het vlak van geheugenfragmentatie. Bij het vervangen van geheugenpagina’s of segmenten is er nu extra tijd (traagheid van harde schijf laat complexe berekeningen toe). Er kan dus een optimale keuze gemaakt worden. Bij segmentering kan het gebeuren dat een groot segment vervangen wordt door een veel kleiner segment, waardoor een stuk van het geheugen niet in gebruik zou zijn. Dit soort fragmentatie heet externe fragmentatie.</simpara>
<simpara>Bij paging gebeurt dit uiteraard niet. Daar worden immers pagina’s van gelijke grootte vervangen. Bij paging kan wel interne fragmentatie optreden. In feite worden de gegevens van een segment verdeeld in pagina’s van 4kB. Voor een bestand van 13kB geeft dit drie volledig gevulde pagina’s en een pagina met 3kB ongebruikte ruimte.</simpara>
</example>
</section>
<section id="_snelheid_en_virtueel_geheugen">
<title>Snelheid en virtueel geheugen</title>
<simpara>Virtueel geheugen heeft de reputatie om de computer te vertragen. Hoewel dit strikt genomen wel waar kan zijn, klopt dit niet helemaal. De reputatie komt namelijk van het swappen van gegevens naar de harde schijf. Aangezien de harde schijf een stuk trager is dan het RAM, gaat dit uiteraard een stuk trager dan gewoon lezen van gegevens uit het RAM.</simpara>
<simpara>Dit is echter geen eerlijke vergelijking. Indien de swap ruimte niet gebruikt zou kunnen worden, zou er gewoon onvoldoende geheugen beschikbaar zijn om in deze situatie te komen. De gebruiker zou zelf bestanden of programma’s moeten afsluiten om te kunnen doen wat het swappen veroorzaakte. Het gebruik van virtueel geheugen biedt de gebruiker dus in eerste instantie extra mogelijkheden. Als die extra mogelijkheden gebruikt worden, gaat dat inderdaad trager.</simpara>
<simpara>Los daarvan kan het gebruik van virtueel geheugen wel vertraging geven. Een eerste evidente reden is dat in plaats van een adres gewoon op te zoeken in het geheugen, nu het adres eerst opgezocht moet worden in twee tabellen, alvorens de eigenlijke operatie kan doorgaan. Aangezien de tabel in het geheugen zit, zijn er dus drie geheugentoegangen nodig om een gegeven te manipuleren. Dit probleem wordt grotendeels opgelost door een Translation Lookaside Buffer. Dit is een snel soort cachegeheugen in de processor waar de meest recent gebruikte fysieke adressen opgeslagen worden. De hitrate van dit buffer ligt weer bijzonder dicht bij 100%, zodat deze vertraging vrijwel geen probleem meer is.</simpara>
<simpara>Een tweede vertraging kan ontstaan als het besturingssysteem onnodig voorbereidingen treft om een toekomstige swap-operatie te versnellen. Zoals daarnet vermeld is swappen een trage operatie. Bovendien moet eerst een pagina geswapt worden naar de harde schijf, waarna de gevraagde pagina in het fysieke geheugen geladen kan worden. Dit betekent tweemaal 4kB verplaatsen naar en van de harde schijf.
Om op het ogenblik dat er gegevens uit de swap-ruimte nodig zijn, de transactie te versnellen, kan het besturingssysteem proberen om op de achtergrondpagina’s te zoeken die waarschijnlijk niet onmiddellijk gebruikt zullen worden en deze dan al naar de swap te verplaatsen.</simpara>
<simpara>Als dan gegevens uit de swap nodig zijn, kan dat met een 4kB verplaatsing van de harde schijf. Het kan natuurlijk gebeuren dat de verplaatste pagina’s toch eerder nodig zijn dan dat er een swapping nodig is. In dat geval zullen de verplaatste pagina’s, wanneer ze terug nodig zijn, uit de swap moeten gehaald worden.
Hierdoor reageert de computer trager dan in het geval er geen virtueel geheugen zou zijn.</simpara>
</section>
</section>
<section id="_bronvermelding_bij_dit_hoofdstuk">
<title>Bronvermelding bij dit hoofdstuk</title>
<itemizedlist mark="Bibliography">
<listitem>
<simpara><anchor id="PATT1" xreflabel="[PATT1]"/>[PATT1] 'Computer Organization And Design'. David A. Patterson, John L. Hennessey. fifth edition. p374</simpara>
</listitem>
<listitem>
<simpara><anchor id="CORS" xreflabel="[CORS]"/>[CORS] 'DDR4 White paper', Corsair, <ulink url="http://www.corsair.com/~/media/Corsair/download-files/manuals/dram/DDR4-White-Paper.pdf">http://www.corsair.com/~/media/Corsair/download-files/manuals/dram/DDR4-White-Paper.pdf</ulink></simpara>
</listitem>
<listitem>
<simpara><anchor id="PATT2" xreflabel="[PATT2]"/>[PATT2] 'Computer Organization And Design'. David A. Patterson, John L. Hennessey. fifth edition. p409</simpara>
</listitem>
<listitem>
<simpara><anchor id="RAMA2" xreflabel="[RAMA2]"/>[RAMA2] 'Computer Systems'. Umakishore Ramachandran, William D. Leahy Jr. Pearson Education, 2011. p419</simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter id="_opslagmedia">
<title>Opslagmedia</title>
<simpara>In dit hoofdstuk duiken we onder de motorkap van het secundair geheugen. Heel vaak wordt dit geïmplementeerd met HDD&#8217;s of SSD&#8217;s. Naast de fysieke eigenschappen bespreken we ook de logica die softwarematig een managementlaag (=bestandssysteem) voorziet voor gebruik door het besturingssysteem.</simpara>
<section id="_harde_schijf">
<title>Harde schijf</title>
<section id="_fysieke_opbouw">
<title>Fysieke opbouw</title>
<figure>
<title>Fysieke opbouw harde schijf</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/harddiskfysiekeopbouw.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>hdd fysieke opbouw</phrase></textobject>
</mediaobject>
</figure>
<simpara>Bovenstaande afbeelding toont de fysieke opbouw van een harde schijf.<?asciidoc-br?>
Een harde schijf bestaat uit een aantal aluminium schijven, die men platters noemt. De keuze voor aluminium is ingegeven door de mechanische eigenschappen van dit materiaal. Aluminium is licht en toch voldoende stijf. Belangrijk nadeel van aluminium is dat het een niet magnetisch materiaal is, zodat het niet bruikbaar is voor magnetische opslag.</simpara>
<simpara>Dit probleem wordt verholpen door de platter te voorzien van een dun laagje magnetisch materiaal. Uiteraard kan een dergelijk laagje langs beide kanten van de platter voorzien worden.<?asciidoc-br?>
Vlak boven (en meestal ook onder) het schijfoppervlak zweeft een schijfkop (head).</simpara>
<simpara>Voor een goed functionerende schijf is het dus belangrijk dat de lucht rond de platters zuiver is. Daarom worden schijven bij de productie luchtdicht verpakt. De platters zitten allemaal op eenzelfde as, die door een motor aan hoge snelheid wordt rondgedraaid.<?asciidoc-br?>
Op die manier beweegt de schijfkop over het oppervlak.</simpara>
<simpara>Wanneer door de kop een positieve stroom loopt, worden de magnetische deeltjes op de schijf in een bepaalde zin georiënteerd. Wanneer een negatieve stroom door de kop gestuurd wordt, zullen de deeltjes in tegengestelde zin gericht worden.</simpara>
<simpara>Omgekeerd, als een kop, waarin geen stroom gestuurd wordt, over het schijfoppervlak beweegt, dan zal in de kop een positieve of negatieve stroom geïnduceerd worden naargelang de oriëntatie van de deeltjes op het schijfoppervlak.Wanneer de kop stil wordt gehouden, passeren een opeenvolgende reeks bits op de schijf die men een track of spoor noemt.</simpara>
<simpara>De verschillende sporen vormen concentrische cirkels op de schijf. Alle sporen met dezelfde straal, die op de verschillende platters liggen, vormen samen een cilinder (afbeelding 38).</simpara>
<figure>
<title>logische indeling van een schijf (bron: technet.microsoft.com)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/logischeopbouw.jpg" contentwidth="450" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Door het ronddraaien van de schijf bewegen de koppen over een cilinder. De verplaatsing naar een andere cilinder gebeurt door een axiale verplaatsing van de arm, waarop alle koppen bevestigd zijn.</simpara>
<section id="_sectoren_tracks">
<title>Sectoren, tracks, &#8230;&#8203;</title>
<simpara>De kleinste hoeveelheid data, die een kop in een keer kan verwerken is een sector. Een sector vormt een onderverdeling van een spoor en kan dus gelezen worden zonder de kop te verplaatsen.</simpara>
<figure>
<title>Onderverdeling van tracks in sectors en bits</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/sector.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Bovenstaande afbeelding toont de onderverdeling van tracks in sectors en sectors in bits. Een track is opgebouwd uit een aantal sectoren met tussen de sectoren een tussenruimte.<?asciidoc-br?>
De sectoren zelf beginnen met een preamble. Dit is een vastgelegd patroon waaraan de schijfcontroller de start van een sector kan herkennen.</simpara>
<simpara>Vervolgens volgen een aantal databits. Dit aantal kan variëren, maar zal bijna altijd gelijk zijn aan 4096 of 512 bytes. Bij recente schijven wordt steevast een sector size verkozen van 4096 bytes. (dit wordt Advanced Format genoemd) Door een verminderde overhead kan zo ongeveer 13% meer nuttige ruimte op een harde schijf ontstaan. <xref linkend="MANGAN"/><?asciidoc-br?>
Na de databits volgt een foutcorrigerende code (ECC - Error Correcting Code). Deze laat toe om fouten in de databits te herstellen. Meestal is dit een Reed-Solomon code. Ook deze eigenschappen werden verbeterd door het 4k advanced format van sectoren.</simpara>
<simpara>De verdeling van de schijf in sectoren en tussenruimte en van de sectoren in preamble, data en ECC gebeurt tijdens het formatteren. Bij het formatteren gaat er dus een stuk schijfruimte verloren aan tussenruimte, preambles en ECC-bits. Hierdoor kan de capaciteit afnemen met 15% ten opzichte van de ongeformatteerde capaciteit. Hier moet je op letten als je verschillende schijven met elkaar vergelijkt. Sommige fabrikanten geven de ongeformatteerde grootte op.</simpara>
<simpara>In de afbeelding zijn ook maten opgegeven voor de breedte van een spoor en de breedte van een bit in een spoor. Hoewel deze maten ondertussen al achterhaald zullen zijn, geven ze wel aan dat de bitdichtheid op een spoor groter is dan de bitdichtheid in radiale richting.</simpara>
<simpara>De bitdichtheid is uiteraard een belangrijke parameter, waar hard aan gewerkt wordt om deze zo groot mogelijk te maken. Een grotere bitdichtheid maakt immers schijven met grotere capaciteit mogelijk of maakt het mogelijk om kleinere platters te maken met behoud van de capaciteit.<?asciidoc-br?>
Ondertussen botst men in het streven naar steeds grotere dichtheden op fysische limieten. Wanneer een magnetisch materiaal gemagnetiseerd wordt, worden dipool moleculen in een bepaalde richting georiënteerd. Het is niet mogelijk om de moleculen individueel te gaan draaien, het gaat steeds om een groep van moleculen die samen gericht worden. De kleinste dergelijke groep heet een magnetisch domein.<?asciidoc-br?>
Omdat men met de dichtheden die op een spoor zitten stilaan in de buurt komt van het oriënteren van een domein en dus niet kleiner meer kan gaan in die richting, is er ondertussen een nieuwe techniek ontstaan. Deze nieuwe techniek gaat geen gebieden in de tangentiële richting gaan magnetiseren, maar gaat werken in de diepte.<?asciidoc-br?>
Dit heet perpendicular recording (loodrechte opname).</simpara>
<figure>
<title>Perpendicular recording (bron: Wikipedia)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/2000px-Perpendicular_Recording_Diagram.svg.png" contentwidth="300" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_toegangstijd">
<title>Toegangstijd</title>
<simpara>De snelheid van schijven hangt van diverse factoren af. Een eerste stap is dat de schijfkop boven het juiste spoor gebracht moet worden, de kop moet in radiale richting gepositioneerd worden.<?asciidoc-br?>
Deze actie noemt men een seek. De seek time is dus een belangrijke parameter bij een harde schijf. Dikwijls worden twee verschillende seek times opgegeven: een track-to-track seek time en een average seek time. De eerste is de tijd nodig om de kop te bewegen tussen twee aan elkaar grenzende sporen, de tweede is de gemiddelde tijd die nodig is om de kop te verplaatsen naar een willekeurig ander spoor. Uiteraard is de eerste tijd een stuk korter dan de tweede tijd (mogelijk reeds achterhaalde richtwaarden: 1ms voor track-to-track, 10ms voor average seek time).</simpara>
<simpara>Eens de kop boven het juiste spoor zweeft, is er nog een rotatiewachttijd nodig alvorens de kop boven de gewenste locatie komt. Deze rotatie wachttijd is vooral afhankelijk van de rotatiesnelheid. Gangbare snelheden zijn 5400, 7200, 10000 of 15000 toeren per minuut. De gemiddelde wachttijd (average latency) is de tijd die nodig is om de schijf een halve rotatie te laten uitvoeren. Bij de vermeldde snelheden is dit 5,56ms, 4,16ms en 3ms. Tenslotte is er nog de tijd nodig om de gegevens effectief te verwerken.<?asciidoc-br?>
Een moderne schijf haalt gemiddelde overdrachtssnelheden van ongeveer 60MB/s (opgelet: niet vergelijken met de maximale overdrachtssnelheid die fabrikanten opgeven).<?asciidoc-br?>
Bij deze snelheid duurt het 8,5ms om een sector van 512 bytes te verplaatsen. Het zal dus duidelijk zijn dat de seek time en de average latency duidelijk domineren ten opzichte van de eigenlijke overdrachtstijd. Het komt er dus ook op aan om te vermijden dat willekeurige sectoren over de schijf gelezen moeten worden.</simpara>
</section>
<section id="_invloed_van_fysieke_geometrie_op_de_performantie">
<title>Invloed van fysieke geometrie op de performantie</title>
<simpara>Eerder werd al de fysieke opbouw van de harde schijf besproken. Deze fysieke geometrie bepaalt mee de snelheid die gehaald kan worden.<?asciidoc-br?>
Helaas zijn sommige eigenschappen tegenstrijdig met andere kwaliteiten die nagestreeft  worden, waaronder ook het goedkoop kunnen aanbieden van de schijven. Een eerste duidelijk voorbeeld is de rotatiesnelheid van de harde schijf. Hoe sneller de schijf rond draait, hoe kleiner de average latency kan zijn. Daar staat tegenover dat een sneller draaiende schijf meer energie vraagt, wat een ongewenste eigenschap is in het geval van batterijgevoede apparaten zoals laptops. Een tweede voorbeeld is het aantal platters. Meer platters betekent dat er meer gegevens beschikbaar zijn, zonder dat de leeskoppen radiaal verplaatst moeten worden. Daar staat dan weer tegenover dat de motoren krachtiger moeten zijn (grotere massa roteren of verplaatsen), met een groter verbruik tot gevolg. Door de grotere massa zullen de schijven ook trager op gang komen, waardoor het minder interessant wordt om ze uit te schakelen (wat het verbruik uiteraard nog meer negatief beïnvloed).<?asciidoc-br?>
Bovendien geven extra platters aanleiding tot grotere trillingen en dus meer lawaai. Tenslotte moeten de platters natuurlijk fysiek in de behuizing van de schijf passen. Een laatste voorbeeld is de capaciteit van de schijf. Als de capaciteit van de schijf vergroot, terwijl alle andere parameters (aantal platters, grootte van platters) dezelfde blijven, dan vergroot de bitdichtheid. Een grotere bitdichtheid betekent dat bij dezelfde rotatiesnelheid bits sneller onder de kop passeren en dus sneller gelezen of geschreven kunnen worden.</simpara>
<simpara>Omwille van de eenvoud van de omrekening werden eerst over de gehele schijf hetzelfde aantal sectoren per cilinder gebruikt. Cilinders die aan de buitenkant van de schijf lagen, hebben een grotere omtrek. Als op een grotere omtrek eenzelfde aantal sectoren ligt met eenzelfde aantal bits per sector, dan betekent dit dat de bitdichtheid aan de buitenkant kleiner is dan aan de binnenkant en dus ook kleiner dan wat technologisch haalbaar is. Op deze manier worden dus zowel snelheid als capaciteit beperkt, voldoende redenen om de schijf ook nog eens te verdelen in zones.</simpara>
<figure>
<title>HDD opdeling in zones</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/zones.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Cilinders die binnen eenzelfde zone liggen hebben hetzelfde aantal sectoren per cilinder. In de figuur is te zien dat het aantal sectoren toeneemt naar de buitenkant van de schijf toe.</simpara>
<example>
<title>voorbeeld</title>
<simpara>Je koopt jezelf een SATA harde schijf, waarvan enkele specificaties gekend zijn.
256 bytes/sector
100 sectors per track
1000 tracks per oppervlak
3 platters
gemiddelde zoektijd van 8ms
rotatiesnelheid is 15000 RPM</simpara>
<simpara>Hoe lang duurt het om tien opeenvolgende sectoren te lezen van dezelfde track?
Hoe lang duurt het om 10 random sectoren te lezen?</simpara>
</example>
<simpara>Op <ulink url="http://en.wikipedia.org/wiki/Hard_disk_drive">http://en.wikipedia.org/wiki/Hard_disk_drive</ulink> vind je een aanvullend educatief filmpje over de werking van de harde schijf.</simpara>
</section>
<section id="_schijfcontroller">
<title>Schijfcontroller</title>
<simpara>Een laatste belangrijk onderdeel van de harde schijf is de schijfcontroller. Deze stuurt enerzijds de motoren en leeskoppen aan, zodat de juiste gegevens bereikt worden, anderzijds verzorgt hij de communicatie met de buitenwereld.</simpara>
<simpara>Zoals al eerder vermeld zal deze controller onder andere een omzetting doen van de LBA adressen die hij binnenkrijgt, naar een fysieke kop, cilinder en sector.</simpara>
<simpara>Samen met deze vertaling houdt de controller ook een mapping bij van slechte sectoren. Sommige sectoren kunnen een permanent gemagnetiseerde plek vertonen, waardoor ze onbruikbaar worden voor het opslaan van variabele informatie. Op elk spoor worden een aantal reserve sectoren voorzien, die de plaats kunnen innemen van een van de defecte sectoren.</simpara>
<simpara>Uiteraard moet de controller dan zijn mapping van logische naar fysieke adressering aanpassen. Controllers kunnen ook sectoren bufferen in een cache, zodat operaties naar de schijf sneller kunnen verlopen.</simpara>
</section>
</section>
<section id="_adressering">
<title>Adressering</title>
<simpara>Origineel gebruikte men voor harde schijven een bijzonder logische Cylinder Head Sector (CHS)-adressering. Elke willekeurige sector wordt uniek gekenmerkt door een (kant van een) platter te kiezen (head), op die platter een cilinder (radiale positie kop boven schijf) en een sector op het geselecteerde spoor (tangentiële positie kop boven schijf).</simpara>
<simpara>De oorspronkelijke CHS adressering gebruikte tien bits voor de cilinder, vier bits voor de kop en 6 bits voor de sector. Merk op hoe opeenvolgende adressen zich eerst op hetzelfde spoor bevinden, vervolgens op verschillende platters en tenslotte pas de cilinder wijzigt. Zolang bestanden dus op opeenvolgende locaties staan, kunnen ze met minimale verplaatsingen (en dus minimale seek en latency times) verwerkt worden. De originele adressering had twee belangrijke nadelen.</simpara>
<simpara>Een eerste belangrijk nadeel is dat er slechts twintig bits beschikbaar zijn voor het adres van een sector.
Bovendien startte de nummering van de eerste sector (vermoedelijk door een fout in de (in assembler geschreven) BIOS routines) bij 1 inplaats van 0. Daardoor waren er 1024 cilinders, 16 koppen en 63 sectoren mogelijk.</simpara>
<simpara>Met een sectorgrootte van 512 bytes betekent dit dat maximaal 512*1024*16*63 = 504MB op de schijf kunnen worden aangesproken. Een dergelijke schijf leek op dat ogenblik waarschijnlijk gigantisch, maar is op dit ogenblik belachelijk klein.</simpara>
<simpara>Tweede nadeel is dat de adressering direct gelinkt is aan de geometrie van de harde schijf. Een schijf met bijvoorbeeld 2048 cilinders, 8 koppen en 63 sectoren, had de maximale grootte van 504MB, maar kon niet volledig geadresseerd worden. De schijf zou slechts 252MB groot lijken.</simpara>
<simpara>Om het tweede probleem te omzeilen begonnen schijfcontrollers te liegen. Ze maakten de computer wijs dat ze een andere geometrie hadden dan de werkelijke fysieke opbouw en vertaalden het CHS-adres naar een fysiek adres op de schijf. De oplossing voor de capaciteit van de schijf kan enkel zijn dat er meer bits werden voorzien om de sectoren te adresseren. Een eerste uitbreiding gebruikte 10 bits voor de cilinder, 8 voor de kop en 6 voor de sector. Wat een capaciteit gaf van 8GB. Bij verdere uitbreiding van dit aantal bits koos men meteen ook voor een ander soort adressering, die niet rechtstreeks aan de geometrie van de harde schijf gelinkt was. Deze vorm van adressering werd dan Logical Block Addressing (LBA). Hierbij krijgt elke sector gewoon een volgnummer, dat dan op de schijf zelf omgezet werd naar een fysiek CHS-adres. Dit laatste CHS adres wordt enkel op de schijf zelf gebruikt en kan dus volledig aan de fysieke geometrie van de schijf worden aangepast.</simpara>
<simpara>Bij de eerste versie van LBA werden 28 bits voorzien voor het adresseren van een sector. Dit geeft een maximale grootte van 512 * 2<superscript>28</superscript> = 128GB.</simpara>
<simpara>Ondertussen blijkt ook dit ontoereikend en is er al een nieuwe adressering die 48 bits gebruikt en dus 128PB (petabyte) toelaat. Hiervan wordt vermoed dat dit voldoende zal zijn tot 2035. De gebruikte adressering is belangrijk omdat ze ervoor kan zorgen dat niet de volledige capaciteit van de harde schijf beschikbaar is.
In het bijzonder kan dit een probleem zijn indien de BIOS nog een oudere vorm van adressering gebruikt. De bios moet immers bij het opstarten van de computer de schijf aanspreken om het besturingssysteem te laden. Dan moeten de relevante gegevens zich wel bevinden binnen de beperkingen van de adressering van de BIOS. Eens het besturingssystemen is opgestart, neemt dit de taken van de bios over en bepalen de mogelijkheden van het besturingssysteem in hoeverre de schijf volledig aangesproken kan worden.</simpara>
</section>
<section id="_scheduling">
<title>Scheduling</title>
<simpara>Gezien de werking van een schijf zal de tijd nodig om een bepaalde sector te lezen bestaan uit drie componenten:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>de tijd nodig om de kop boven een bepaald spoor te positioneren (seek time)</simpara>
</listitem>
<listitem>
<simpara>de tijd totdat de gewenste sector zich onder de kop bevindt (latency time)</simpara>
</listitem>
<listitem>
<simpara>de tijd nodig om de gegevens fysiek te transfereren (transfer time)</simpara>
</listitem>
</orderedlist>
<simpara>Om de totale verloren tijd zoveel mogelijk te beperken zal men de sectoren meestal niet één per één van de schijf lezen, maar in blokken of clusters. Een dergelijk blok zal minstens één sector moeten bevatten. Vaak zal een blok 4 tot 8 kB zijn terwijl een sector typisch 512 bytes is. Hoe groter de blokken, des te efficiënter de gegevensoverdracht, maar ook des te groter de interne fragmentatie gezien een blok de kleinste hoeveelheid schijfruimte is die gealloceerd kan worden. De blokgrootte kan bij de generatie van het bestandensysteem gekozen worden en zal afhangen van de kenmerken van de bestanden op de schijf. Indien men louter met zeer grote bestanden werkt, kan men de voorkeur geven aan vrij grote blokken.<?asciidoc-br?>
Voortaan zullen we ervan uitgaan dat alle interactie met de harde schijf in blokken gebeurt.</simpara>
<simpara>Indien er verschillende schijfoperaties staan te wachten op de schijf kunnen we, door de volgorde ervan te veranderen de prestaties van de schijf verbeteren. Deze strategie zal enkel een verschil opleveren op het ogenblik dat de schijf effectief zwaar belast wordt (en er dus keuze is).</simpara>
<simpara>Schijfstrategieën kunnen door het besturingssysteem geïmplementeerd worden (rekening houdend met de kenmerken van het besturingssysteem), of (meer en meer) ook door de schijfregelaar (rekening houdend met de kenmerken van de schijf).
Wanneer het in de harde schijf zelf gebeurt wordt het ook wel NCQ genoemd (Native Command Queuing). Indien NCQ niet ondersteund wordt door de schijf dan zorgt enkel het besturingssysteem voor de scheduling, indien wel is het een combinatie van beide wat voor minder processorbelasting zorgt in de computer.</simpara>
<simpara>In de nu volgende bespreking wordt verondersteld dat de volgorde van sporen waarnaar gelezen of geschreven moet worden is: <emphasis role="strong">98, 183, 37, 122, 14, 124, 65, 67</emphasis> en dat de kop initieel op positie <emphasis role="strong">53</emphasis> staat.</simpara>
<section id="_fcfs_first_come_first_serve">
<title>FCFS: First-Come First-Serve</title>
<simpara>Deze strategie is de eenvoudigste, en bovendien is ze eerlijk omdat schijfoperaties niet oneindig lang kunnen uitgesteld worden. Ze kan echter niet de beste prestatie van de schijf garanderen omdat opeenvolgende schijfoperaties kunnen plaatsvinden op totaal verschillende delen van de schijf waardoor er dus veel tijd verloren gaat aan het zoeken van de sporen.</simpara>
<figure>
<title>First-Come First-Served Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/fcfs.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>fcfs</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_sstf_shortest_seek_time_first">
<title>SSTF: Shortest Seek Time First</title>
<simpara>Om te vermijden dat de lees/schrijfkop zich wild heen en weer gaat bewegen over de harde schijf indien FCFS gebruikt wordt kan men de voorkeur geven aan die schijfoperaties die in de onmiddellijke nabijheid van de huidige koppositie moeten doorgevoerd worden. Het voordeel van deze strategie is dat de zoektijden hierdoor zullen afnemen, maar anderzijds is deze strategie niet langer gegarandeerd eerlijk, omdat bij een zware belasting er blijvend aanvragen kunnen binnenkomen voor een bepaald deel van de schijf waardoor verder afgelegen delen van de schijf niet bediend worden. In tegenstelling met SJF is SSTF geen optimaal algoritme. In de afbeelding zou het bijvoorbeeld efficiënter zijn om eerst naar cilinder 37 te gaan en dan pas SSTF toe te passen.</simpara>
<figure>
<title>Shortest Seek Time First Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/sstf.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>sstf</phrase></textobject>
</mediaobject>
</figure>
<section id="_scan_scannen">
<title>SCAN: Scannen</title>
<simpara>Dit algoritme tracht de voordelen van SSTF te combineren met een eerlijk gedrag. Het overloopt de schijf van het eerste tot het laatste spoor en omgekeerd hierbij alle operaties uitvoerend `en passant'. Dit garandeert dat alle schijfoperaties finaal zullen uitgevoerd geraken en is te vergelijken met een bus die op zijn heen- en terugweg bij alle haltes stopt waar personen staan te wachten.</simpara>
<figure>
<title>Scan Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/scan.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>scan</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_c_scan_cirkulair_scannen">
<title>C-SCAN: Cirkulair Scannen</title>
<simpara>Dit is een verbetering van de SCAN strategie. Op zijn terugweg zal de kop in het begin nauwelijks of geen operaties ontmoeten (deze sporen werden immers pas net bediend). Indien er dan toch al operaties zijn, zullen ze alle zeer recent zijn. De operaties aan de overzijde van de schijf staan echter reeds geruime tijd te wachten. Daarom zal C-SCAN op zijn terugweg geen sporen bedienen maar meteen bij spoor 0 herbeginnen (zie figuur). Hier zullen de gemiddeld oudere aanvragen eerst bediend worden. Dit algoritme is in zekere zin eerlijker dan SCAN, maar geeft wel een slechtere doorvoercapaciteit omdat de terugweg onderbenut wordt. Deze strategie zal zich bijzonder slecht gedragen indien de sporen sequentieel van rechts naar links moeten gelezen worden.</simpara>
<figure>
<title>Circular Scan Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/cscan.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>cscan</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_look_c_look_aangepaste_scan_c_scan">
<title>LOOK + C-LOOK: Aangepaste SCAN + C-SCAN</title>
<simpara>In de praktijk zal men de kop van de schijf niet tussen de twee uiterste uiteinden van de schijf laten bewegen, maar wel tussen die twee uiterste sporen waarvoor er aanvragen zijn (vergelijkbaar met een lift)</simpara>
<figure>
<title>Look Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/look.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>look</phrase></textobject>
</mediaobject>
</figure>
<figure>
<title>Cirkular Look Disk Scheduling</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/scheduling/clook.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>clook</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
</section>
<section id="_solid_state_drive">
<title>Solid state drive</title>
<figure>
<title>SSD drive zonder behuizing</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/zones.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>In plaats van een magnetische schijf wordt in een SSD gebruik gemaakt van DRAM of flash geheugen om de gegevens op te slaan. DRAM heeft uiteraard als nadeel dat met het wegvallen van de stroom ook de gegevens verdwijnen.<?asciidoc-br?>
Daarom worden dergelijke ‘schijven’ uitgerust met een batterij, die toelaat om de gegevens nog naar een backup schijf te schrijven. Dergelijke schijven zijn geschikt om dienst te doen als opslagmedium voor de swap. Hoewel er nog een beperking is van de interface waarmee de SSD verbonden is met het systeem, zal dit sneller zijn dan een magnetische schijf. Daar staat tegenover dat DRAM duur is en dat het logischer is om het gewoon rechtstreeks in de geheugenbanken te voorzien.<?asciidoc-br?>
Deze oplossing is dus vooral interessant als het fysieke geheugen niet uitgebreid kan worden (bijvoorbeeld maximum 4GB met 32-bit processor).<?asciidoc-br?>
Veel fabrikanten werken aan drives met flash geheugen. Deze technologie is een stuk goedkoper en verliest zijn inhoud niet bij het wegvallen van de stroom. Hoewel flash nog steeds een stuk duurder is dan magnetische opslag, lijkt deze technologie toch een alternatief te kunnen vormen voor magnetische harde schijven.<?asciidoc-br?>
Recente productlanceringen lijken erop te wijzen dat deze technologie heel snel matuur wordt.<?asciidoc-br?>
In 2014 lijkt de SSD-prijs te stabiliseren rond 0.8USD/GB <xref linkend="PCPART"/>, en de trend is nog steeds dalend.</simpara>
<simpara>De meeste voordelen volgen uit het ontbreken van mechanische onderdelen:</simpara>
<itemizedlist>
<listitem>
<simpara>De schijf moet niet draaien en moet dus ook niet opstarten, geen kop die bewogen moet worden, dus willekeurige toegang kan sneller.</simpara>
</listitem>
<listitem>
<simpara>Fragmentatie van bestanden wordt minder belangrijk</simpara>
</listitem>
<listitem>
<simpara>Geen bewegende onderdelen, dus geen lawaai</simpara>
</listitem>
<listitem>
<simpara>Stroomverbruik ligt lager dan bij conventionele schijven</simpara>
</listitem>
<listitem>
<simpara>Beter bestand tegen schokken, temperatuur, hoge hoogte tenzij voor high-end schijven, ligt het verbruik lager</simpara>
</listitem>
</itemizedlist>
<simpara>Uiteraard zijn er ook nadelen. Zoals al vermeld is er voorlopig nog de kostprijs. Daarnaast is er ook de specifieke eigenschap van flash dat het slechts een beperkt aantal keer beschrijfbaar is.<?asciidoc-br?>
Door recente ontwikkelingen valt dit nadeel echter bijna volledig weg. Tegenwoordig zijn cellen in SSD-schijven meer dan 1 000 000 keer herschrijfbaar, en dat zou voldoende moeten zijn om bij normaal gebruik vele jaren correct te functioneren. Behalve bij erg specifieke schrijfintensieve taken (vb logging server) zal deze limiet nooit een probleem vormen.<?asciidoc-br?>
Een belangrijke rol hierbij is weggelegd voor de controller, het intelligente hart van de SSD-schijf. Die zal ervoor zorgen dat elk deel van het geheugen ongeveer evenveel beschreven wordt, zodat de slijtage over het hele geheugenbereik ongeveer gelijk is.<?asciidoc-br?>
Aangezien verspreidde bestanden toch geen invloed hebben op de snelheid, veroorzaakt dit geen performantieverlies.<?asciidoc-br?>
Het gebruik van de erase-blocks maakt ook dat meer gegevens moeten worden aangepast, waardoor echt random schrijven trager wordt (veel meer extra gegevens die moeten worden aangepast). SDD’s zijn eigenlijk al goed ingeburgerd onder de vorm van geheugenkaarten en USB sticks. Stilaan beginnen ook laptops op te duiken die voorzien zijn van een solid state schijf.<?asciidoc-br?>
Ook voor specifieke servertoepassingen wordt de SSD stilaan een interessant alternatief voor ‘gewone schijven’. Denk daarbij maar aan webservers, die heel veel kleine bestanden (webpagina’s) moeten lezen vanop de schijf: die hebben duidelijk baat bij snelle access-tijden.</simpara>
<section id="_flash_technologie">
<title>Flash technologie</title>
<simpara>Flash geheugen bestaat uit cellen die in staat zijn om een spanningsniveau te onthouden. er onderscheiden zich twee belangrijke types:</simpara>
<section id="_slc">
<title>SLC</title>
<simpara>Flash-geheugen bestaat uit cellen die data bevatten. Bij SLC zal elke cel één bit bevatten. Dat is de meest eenvoudige en snelle manier om geheugen te produceren, maar helaas ook de duurste: je hebt immers veel cellen nodig om een grote capaciteit te behalen.</simpara>
<figure>
<title>SLC geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/slc.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_mlc">
<title>MLC</title>
<simpara>MLC (multi level cell) houdt in dat iedere cell in het geheugen meerdere bits kan onthouden. Beschouw daarvoor onderstaande figuur:</simpara>
<figure>
<title>MLC geheugen</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/mlc.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Iedere cel zal dus in staat zijn om bijvoorbeeld vier verschillende spanningsniveaus te bewaren. Je ziet dat MLC gevoeliger zal zijn voor fouten: als er een klein beetje van het spanningsniveau is weggelekt zal je de data niet meer juist uitlezen.<?asciidoc-br?>
Vanwege die nood aan precisie zal MLC dus trager gelezen en beschreven kunnen worden. MLC wordt dus voornamelijk gebruikt waar een grote capaciteit belangrijker is dan een erg grote betrouwbaarheid of snelheid.</simpara>
</section>
</section>
<section id="_schrijfcyclus_van_flash_memory">
<title>Schrijfcyclus van Flash Memory</title>
<simpara>Het beschrijven van Flash is in tegenstelling tot lezen (gebeurt in één beweging) een heel karwei. Beschouw onderstaande figuur, waarbij een document moet geschreven worden, gespreid over drie plaatsen in een datablok.</simpara>
<figure>
<title>Schrijfcyclus Flash</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/flash_write.png" contentwidth="500" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>De verschillende stappen die nodig zijn gaan als volgt:
. De huidige data wordt in de snelle cache ingelezen
. De cellen die aangeduid staan als waardeloos worden effectief leeggemaakt
. De huidige data en de te schrijven data worden samengevoegd in de cache
. De cache wordt terug weggeschreven naar een (leeg!) block in flash.</simpara>
</section>
<section id="_optimalisatie_van_flash">
<title>Optimalisatie van Flash</title>
<simpara>De SSD-technologie staat nog in zijn kinderschoenen. De recentste types kampen dan ook vaak nog met problemen. Zeker als ze zwaar belast worden vallen ze vaak door de mand. Ook het besturingssysteem vervult hierin een belangrijke rol. Enkele van de problematieken&#8230;&#8203;</simpara>
<section id="_buffering">
<title>Buffering</title>
<simpara>Het concept van cache/buffering is jullie uiteraard niet onbekend. Een bijzonderheid van flashgeheugen is dat je voor het schrijven eerst de benodigde blokken moet wissen. Bij reeds gewiste cellen is dit uiteraard niet nodig. Je begrijpt dat deze werkwijze flink wat tijd vraagt. Een cache zal dan ook de schrijfacties bufferen. Als de cache te klein is, zal na een periode van continu schrijven de prestatie sterk degraderen.</simpara>
</section>
<section id="_schijfverlamming">
<title>Schijfverlamming</title>
<simpara>Enkele maanden na het lanceren van SSD’s in 2009 zaten verschillende reviewers met de handen in het haar. Toen ze de schijven reviewden vlak na verschijnen waren die erg snel en enkele maanden later bleek daar amper nog iets van over te blijven. [4]</simpara>
<simpara>De verklaring zit in de manier waarop data geschreven wordt naar SSD disks. Uit de uitleg bij ‘cache’ had je al begrepen dat schrijven enkel snel lukt als dat gebeurt naar volledig vrije blokken, anders moeten ze eerst ingelezen/leeggemaakt worden.</simpara>
<simpara>Naarmate de tijd vordert zullen die vrije blokken uiteraard zeldzamer worden.
De fabrikanten die getroffen werden door dit gênant verschijnsel bakten daarom een nieuwe firmware. Ze bouwden een feature in die soms wel ‘garbage collection’ genoemd wordt. Het concept is dat je schijf probeert op rustige momenten om op schijfniveau  te defragmenteren. informatie in blokken wordt samengevoegd zodat er terug lege blokken bij komen. Die zijn immers veel sneller te beschrijven dan ‘half gevulde’ blokken.</simpara>
<figure>
<title>Garbage collection bij Flash Memory</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/flash_garbage_collection.png" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase></phrase></textobject>
</mediaobject>
</figure>
<simpara>Een bijkomende manier om hetzelfde probleem te verhelpen is het besturingssysteem laten communiceren met de SSD door middel van het ATA-Trim commando. Het besturingssysteem zal met dit commando aan de schijf vertellen welke data niet meer nodig is. (bijvoorbeeld bestanden die door NTFS als verwijderd staan aangeduid) Dit commando werd geïntroduceerd bij Windows 7 en is ingebakken in Linux kernels vanaf 2.6.28. Zo wordt vermeden dat sectoren verplaatst worden op de SSD, die door NTFS reeds lang als verwijderd werden aangeduid.</simpara>
</section>
<section id="_alignment">
<title>Alignment</title>
<simpara>Bij SSD’s is het belangrijk dat de grenzen van partities exact overeenkomen met de grenzen van SSD-blocks. Zo komt elke cluster (4k) precies overeen met één block (4k) op de harde schijf. Als er dan data moet geschreven worden in een cluster, dan hoeft maar één block geschreven te worden, en geen twee. Vista en Windows 7 schijnen hier in de setup rekening mee te houden. Van 3rd party tools is dat natuurlijk minder zeker. Je kopieert een gewone schijf dan ook beter niet via sector-based copy tools als Ghost of dd (linux commando)</simpara>
</section>
</section>
</section>
<section id="_logische_structuur_van_een_opslagmedium">
<title>Logische structuur van een opslagmedium</title>
<simpara>In het voorgaande werd de harde schijf voornamelijk bekeken vanuit zijn fysieke kenmerken. In wat volgt zullen we de logische indeling van de schijf bekijken.
We zullen met andere woorden bekijken hoe de schijf toegankelijk is voor bijvoorbeeld het besturingssysteem. Harde schijven worden in de eerste plaats verdeeld in één of meerdere partities (= fysieke formatering), terwijl elke partitie dan georganiseerd wordt volgens de regels van een welbepaald bestandsysteem. (=logische formatering)</simpara>
<simpara>Sommige toepassingen die zeer intensief gebruik maken van secundair geheugen (zoals gegevensbanken) vereisen dat een schijf(-partitie) niet logisch geformateerd wordt. Zij gebruiken de `raw disk' en gebruiken hun eigen logische formatering. Hetzelfde geldt voor de swapruimte op een aantal systemen. De bedoeling is steeds om de overhead van het bestandensysteem te omzeilen.</simpara>
<section id="_boot_blok">
<title>Boot blok</title>
<simpara>Bij het opstarten van een computer is het niet duidelijk wat die computer precies zal moeten uitvoeren (Linux, MS-DOS, Windows). De keuze van het besturingssysteem zal onder andere gemaakt worden door de inhoud van de schijf die als `systeemschijf' bekend staat. Het opstarten van een computersysteem staat bekend onder de naam `bootstrappen'. Na het aanleggen van de spanning begint de processor code uit te voeren op een bepaalde vaste plaats in het geheugen. Door op die plaats een ROM-geheugen aan te brengen (geheugen met een voorgedefinieerde vaste inhoud), zal een programma beginnen uitvoeren. Dit (kleine) generische programma gaat na of de hardware van de computer zich gedraagt zoals het hoort, en gaat dan op zoek naar de systeemschijf en tracht daar één of meerdere sectoren te lezen (de zogenaamde boot sectoren). Deze sectoren bevatten de code die nodig is om andere delen van het besturingssysteem in te lezen. Deze code zal op zijn beurt het volledige besturingssysteem inladen, de configuratiebestanden lezen en de controle overleveren aan het besturingssysteem. Het proces van bootstrappen is dus een proces waarbij stap voor stap complexere software van de schijf ingeladen wordt en er gaandeweg meer en meer functies van het besturingssysteem ter beschikking komen.</simpara>
</section>
<section id="_master_boot_record_mbr_layout">
<title>Master Boot Record (MBR) layout</title>
<table frame="all" rowsep="1" colsep="1">
<title>Inhoud Master Boot Record</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">offset</entry>
<entry align="left" valign="top">lengte (bytes)</entry>
<entry align="left" valign="top">inhoud</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>446</simpara></entry>
<entry align="left" valign="top"><simpara>MBR programmacode</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>446 (1BEh)</simpara></entry>
<entry align="left" valign="top"><simpara>16</simpara></entry>
<entry align="left" valign="top"><simpara>eerste partitie-record</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>462 (1CEh)</simpara></entry>
<entry align="left" valign="top"><simpara>16</simpara></entry>
<entry align="left" valign="top"><simpara>tweede partitie-record</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>478 (1DEh)</simpara></entry>
<entry align="left" valign="top"><simpara>16</simpara></entry>
<entry align="left" valign="top"><simpara>derde partitie-record</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>494 (1EEh)</simpara></entry>
<entry align="left" valign="top"><simpara>16</simpara></entry>
<entry align="left" valign="top"><simpara>vierde partitie-record</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>510 (1FEh)</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>55 AA (einde markering)</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Het master boot record is de eerste fysieke sector van de harde schijf. Deze bevat twee gedeeltes: de primaire partitietabel en de MBR-programmacode.
De MBR programmacode bevat de nodige instructies om te beslissen van welke primaire partitie opgestart moet worden, om de bootsector van de betreffende partitie in het geheugen te laden en om te starten met het laden van het betreffende besturingssysteem. In de meest eenvoudige vorm zoekt de MBR-code in de partitietabel naar de actieve partitie (zie verder), laadt de bootsector van die partitie in het geheugen en voert de code uit die daarin opgeslagen is. Soms kan de MBR-code ook meer gesofisticeerd zijn en interactie met de gebruiker mogelijk maken.<?asciidoc-br?>
Dit is het geval bij Boot-managers als LILO (Linux Loader), grub en BootMagic.
Partitionering is het onderverdelen van de harde schijf in verschillende blokken, met elk een bestandsysteem. Partitioneren kan interessant zijn om bijvoorbeeld verschillende soorten gegevens te groeperen (bijvoorbeeld aparte data partitie, die niet aangepast wordt als het besturingssysteem opnieuw geïnstalleerd wordt). Het kan ook gebruikt worden om bijvoorbeeld een aparte swap-partitie te voorzien of om meerdere besturingssystemen (multi-boot systeem) mogelijk te maken.
Bij het partitioneren is het wel belangrijk om op voorhand goed na te denken wat je wil, want achteraf aanpassen van groottes van partities is (afhankelijk van het gebruikte bestandsysteem) niet altijd mogelijk en dikwijls gevaarlijk voor dataverlies.<?asciidoc-br?>
Hoe een schijf is onderverdeeld in partities wordt opgeslagen in een partitietabel.<?asciidoc-br?>
De primaire partitietabel bevat voor elke primaire partitie een record van zestien bytes. De inhoud van zo’n record wordt weergegeven in onderstaande tabel.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Inhoud partitietabel-record</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">offset</entry>
<entry align="left" valign="top">lengte (bytes)</entry>
<entry align="left" valign="top">inhoud</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>80h (actieve partitie) of 00h (niet actief)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>CHS adres eerste sector van de partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>type partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>5</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>CHS adres laatste sector van partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8</simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>LBA adres eerste sector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>12</simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>aantal sectoren in partitietabel</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Het eerste byte duidt aan of de partitie actief is of niet. Dit kan belangrijk zijn, in het bijzonder in het geval waarbij de MBR op zoek gaat naar de actieve partitie om te booten. Daarnaast zijn er een aantal parameters die de locatie en grootte van de partitie vastleggen en er is een byte dat het type vastlegt. Met dit byte kan aangegeven worden welk bestandsysteem op de partitie staat (b.v. FAT16, FAT32, EXFAT, NTFS, EXT4, ZFS, &#8230;&#8203;).</simpara>
<simpara>Aangezien er slechts vier records zijn in de primaire partitietabel, kunnen slechts vier primaire partities gedefinieerd worden. Indien meer partities nodig zijn, moet gebruik gemaakt worden van extended of uitgebreide partities. Belangrijke opmerking hierbij is dat niet alle informatie op een extended partitie terecht mag komen. Een belangrijk voorbeeld is een partitie waar Windows op geïnstalleerd wordt. In de primaire partitietabel is er slechts een extended partitie mogelijk.
Deze partitie krijgt een type aanduiding die aangeeft dat het gaat om een extended partitie.<?asciidoc-br?>
Op de eerste sector van de extended partitie bevindt zich een extended master boot record (EMBR). In het EMBR is er plaats voor twee partietabel-records.
Een van de partities kan weer een uitgebreide partitie zijn.<?asciidoc-br?>
Op die manier kunnen in principe oneindig veel partities aangemaakt worden (al zijn er natuurlijk wel beperkingen, zoals de eindige capaciteit van de schijf). De partities die aangemaakt worden binnen een uitgebreide partitie, noemt men logische partities.</simpara>
<figure>
<title>partitiestructuur (bron:Microsoft Technet)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/MBRvsGPTbrontechnet.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>partitiestructuur</phrase></textobject>
</mediaobject>
</figure>
<simpara>Meestal moet men slechts eenmaal een extended partitie aanmaken en kan men vervolgens in deze partitie logische partities definiëren. Het partitioneringsprogramma maakt automatisch de nodige EMBR’s aan. Bij het aanmaken van een extended partitie moet je goed opletten dat je voldoende ruimte voorziet voor het definiëren van alle logische partities.<?asciidoc-br?>
In onderstaande twee afbeeldingen worden twee voorbeelden gegeven van de indeling van een harde schijf.
Het eerste is een eenvoudig voorbeeld met een primaire en een logische DOS-partitie (Microsoft laat slechts een FAT per partitietabel toe). Het tweede voorbeeld toont een complexer voorbeeld met meerdere logische partities. Nu is te zien dat elke extended partitie een EMBR bevat waarin informatie zit voor een logische partitie en een verwijzing naar de volgende extended partitie.</simpara>
<figure>
<title>Voorbeeld partitietabel met uitgebreide partitie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/partitie1.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>partitiestructuur met uitgebreide partitie</phrase></textobject>
</mediaobject>
</figure>
<figure>
<title>Partitietabel met meerdere logische partities</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/partitie2.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>partitiestructuur met meerdere logische partities</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_gpt_layout">
<title>GPT layout</title>
<simpara>De disk-layout met het MBR wordt tegenwoordig nog vaak gebruikt. Toch zijn er enkele belangrijke nadelen:</simpara>
<itemizedlist>
<listitem>
<simpara>Partitiegrootte is beperkt tot 2TB, wat met de huidige nieuwe harde schijven problematisch wordt.</simpara>
</listitem>
<listitem>
<simpara>De partitietabel is een erg belangrijk stukje data op de schijf, maar het wordt op geen enkele manier beschermd. Als deze cluster defect is, dan is het moeilijk om de logische layout van de schijf te achterhalen.</simpara>
</listitem>
</itemizedlist>
<simpara>De GPT layout probeert hier oplossingen voor te verzinnen. Zo staat de partitietabel ook op het einde van de schijf, zodat een defect in het begin van de schijf niet hoeft te betekenen dat je de data op de partities kwijt bent. De eerste sector van een GPT-schijf bevat een valse MBR-record (protective MBR) om oude partitioneringstools te misleiden.<?asciidoc-br?>
Het maximale aantal partities is bij GPT 128 stuks. De grootte voor elke partitie is geen limiet meer. (om precies te zijn: bij sectoren van 512 bytes kan je 2^64 *512 bits opslaan in elke partitie.)+
Elke partitie-entry bij GPT bevat volgende gegevens:</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">#bytes</entry>
<entry align="left" valign="top">Naam</entry>
<entry align="left" valign="top">Beschrijving</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>16 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Partition Type GUID</simpara></entry>
<entry align="left" valign="top"><simpara>Bevat een GUID die zegt over welk soort partitie het gaat. Vb Linux Swap Partition, Windows Basic Data Partition, Apple HFS+ partitie, …</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>16 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Unique Partition GUID</simpara></entry>
<entry align="left" valign="top"><simpara>Unieke GUID voor deze partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Starting LBA</simpara></entry>
<entry align="left" valign="top"><simpara>Begin van de partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Ending LBA</simpara></entry>
<entry align="left" valign="top"><simpara>Einde van de partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Attribute bits</simpara></entry>
<entry align="left" valign="top"><simpara>Extra info over de partitie</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>72 bytes</simpara></entry>
<entry align="left" valign="top"><simpara>Partition name</simpara></entry>
<entry align="left" valign="top"><simpara>Leesbare naam voor de partitie</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<figure>
<title>GPT versus MBR layout (bron: Microsoft Technet)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/MBRvsGPTbrontechnet.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>partitiestructuur</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_bestandssystemen">
<title>Bestandssystemen</title>
<section id="_algemeen">
<title>Algemeen</title>
<simpara>Een bestandssysteem bestaat uit verschillende lagen die elk van de diensten van de onderliggende lagen gebruik maken.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Op het bovenste niveau is er het \textbf{logische bestandssysteem}. Dit is het niveau waarmee de gebruiker in contact komt. Hier wordt er met bestandsnamen, protecties, enz. gewerkt. Dit niveau beheert ook de directories die als speciale gegevensbestanden beschouwd worden.</simpara>
</listitem>
<listitem>
<simpara>Het logische bestandssysteem maakt gebruik van de <emphasis role="strong">bestandsorganisatie</emphasis> die de verbinding vormt tussen het logische en het fysieke niveau. Hier wordt aan het beheer van de vrije schijfruimte gedaan, hier worden de bestandsnamen omgezet naar de logische schijfadressen.</simpara>
</listitem>
<listitem>
<simpara>Het fysieke bestandssysteem krijgt van de bestandsorganisatie de logische schijfadressen binnen en vertaalt deze naar fysieke schijfadressen voor de betreffende schijven.</simpara>
</listitem>
<listitem>
<simpara>IO-controle: dit zijn de drivers voor de schijven. Deze drivers verbergen alle details van de schijfhardware voor de bovenliggende lagen.</simpara>
</listitem>
</orderedlist>
<simpara>Een bestandssysteem zal de bestanden op een partitie organiseren en zorgen dat het besturingssysteem over voldoende informatie beschikt om elk bestand terug te vinden. Er zijn veel verschillende soorten bestandssystemen, we zullen ons hier beperken tot FAT16 en NTFS. Eigenschappen van andere bestandssystemen zullen in de cursus besturingssystemen nog besproken worden. Elke partitie begint met een Partition Boot Sector (PBS). Dit is dus weer de eerste fysieke sector die bij een bepaalde partitie behoort. De PBS bestaat weer uit twee delen. Helemaal vooraan staat een spronginstructie naar de eventueel aanwezige boot routine. Deze boot routine zal het besturingssysteem laden (dus op elke partitie waarop een besturingssysteem geïnstalleerd is, zullen een dergelijk programma en spronginstructie terug te vinden zijn). Daarnaast is er het BIOS Parameter Block. Dit gedeelte bevat een aantal parameters die belangrijk zijn om toegang te krijgen tot het bestandsysteem. Welke parameters hier terug te vinden zijn, hangt natuurlijk af van het type bestandssysteem.</simpara>
</section>
<section id="_bestanden">
<title>Bestanden</title>
<simpara>Het probleem van de allocatie van bestanden betreft de vraag op welke manier de blokken of clusters van de schijf samengevoegd kunnen worden tot een bestand. Er zijn verschillende mogelijkheden:</simpara>
<itemizedlist>
<listitem>
<simpara>Contigu</simpara>
</listitem>
<listitem>
<simpara>Gelinkt</simpara>
</listitem>
<listitem>
<simpara>Gebaseerd op een allocatietabel</simpara>
</listitem>
<listitem>
<simpara>Gebaseerd op een indextabel.</simpara>
</listitem>
</itemizedlist>
<simpara>De keuze van een bepaalde methode zal onder meer afhangen van de manier waarop de gegevens van een schijf gebruikt zullen worden: sequentieel, direct of geïndexeerd, en van de prestaties die men van de schijf verwacht. Doordat de schijf zeer traag is in vergelijking met de processor, zal men doorgaans trachten om het aantal toegangen naar de schijf zoveel mogelijk te beperken door bepaalde tabellen in het geheugen te houden, door gegevens intelligent over de schijf/schijven te verdelen zodat de kopbewegingen beperkt worden, enz. Vaak kan het de moeite lonen om de processor een complexer algoritme te laten uitvoeren indien dit het gebruik van de schijf kan verminderen.</simpara>
<section id="_contigue_allocatie">
<title>Contigue allocatie</title>
<simpara>Contigue allocatie is de eenvoudigste allocatiemethode Een bestand bestaande uit n blokken zal n opeenvolgende fysieke blokken op de schijf innemen. De verplaatsingen van de lees/schrijfkop zullen hierdoor minimaal zijn: bij het sequentieel lezen zal de kop enkel op het einde van het laatste spoor van een cilinder moeten veranderen naar een volgende cilinder en ook bij directe toegang zullen de verplaatsingen van de kop minimaal zijn. Contigue allocatie is hierdoor de snelste allocatiemethode.</simpara>
<figure>
<title>Contigue allocatie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/allocatie/contigue.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>contigue allocatie</phrase></textobject>
</mediaobject>
</figure>
<simpara>Ze heeft echter ook heel wat nadelen. Vooreerst is er het probleem van de externe fragmentatie. Doordat het schijfgeheugen dat gealloceerd moet worden contigu moet zijn heeft men in werkelijkheid stukken geheugen van ongelijke lengte waarvoor het geheugenbeheer relatief moeilijk is. Compactering kan hier een oplossing brengen, maar meestal zal het bestandssysteem tijdens het compacteren onbruikbaar zijn. Dit is niet steeds aanvaardbaar.</simpara>
<simpara>Ten tweede is er het probleem dat men nog vóór de creatie van een bestand moet weten hoe groot het zal worden. Schat men de werkelijke grootte te hoog, dan krijgt men een aanzienlijke interne fragmentatie, schat men het te klein, dan zal het programma dat het bestand aanmaakt afgebroken worden. Dit laatste kan vermeden worden door in dat geval het bestand te copi\"eren naar een grotere vrije ruimte en daar de uitvoering verder te zetten. Het hoeft geen betoog dat dit de turn around time van een proces negatief zal beïvloeden. Langzaam groeiende bestanden zoals log-bestanden zijn vrij moeilijk efficiënt te implementeren.</simpara>
<simpara>Sommige systemen laten daarom toe om de contigue allocatie stuksgewijs te ondersteunen. Men begint dan met een bestand met een gegeven grootte, en indien het te klein zou blijken te zijn, kan men een bijkomende uitbreiding toevoegen. De grootte van deze uitbreiding moet ook op voorhand vastgelegd worden. Ofschoon deze oplossing efficiënter is dan het volledig kopi\"en van het bestand, heeft ze ook te lijden onder het probleem van de externe fragmentatie.</simpara>
</section>
<section id="_gelinkte_allocatie">
<title>Gelinkte allocatie</title>
<simpara>Deze allocatiemethode lost alle externe-fragmentatieproblemen van de contigue allocatie op. In de plaats van alle blokken contigu op de schijf op te slaan worden de blokken op de schijf met elkaar gelinkt (zie figuur \ref{gelinkte}). Zolang er vrije blokken zijn, kan een bestand blijven groeien. Ofschoon deze methode het probleem van de externe fragmentatie effectief oplost, heeft ze ook haar problemen. Vooreerst wordt directe toegang nagenoeg onmogelijk omdat steeds de lijst van blokken moet afgelopen worden. Ten tweede kan het sequentieel lezen van een bestand zeer traag worden omdat er per nieuw in te lezen blok in principe een verplaatsing van de kop kan nodig zijn. Ten derde zullen de blokken nu een beetje kleiner zijn omdat de link naar het volgende blok ook moet opgenomen worden. Tenslotte is gelinkte allocatie ook niet zeer betrouwbaar omdat van zodra er één blok corrupt wordt de hele schijf onbetrouwbaar wordt.</simpara>
<figure>
<title>Gelinkte allocatie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/allocatie/gelinkte.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>gelinkte allocatie</phrase></textobject>
</mediaobject>
</figure>
<simpara>Om het sequentieel lezen te versnellen kan men bij de allocatie van de blokken er trachten voor te zorgen dat ze toch zoveel mogelijk sequentieel op de schijf staan zodat de bewegingen van de lees/schrijfkop beperkt worden. Bijgevolg kan de contiguïteit en dus de snelheid door regelmatig te compacteren verbeterd worden.</simpara>
<simpara>Het derde probleem kan minder erg gemaakt worden door de blokgrootte te vergroten. Gezien er slechts één link per blok opgeslagen wordt, verkleint hierdoor het percentage aan links.</simpara>
</section>
<section id="_allocatietabel">
<title>Allocatietabel</title>
<simpara>De overige problemen kunnen opgelost worden door alle wijzers naar de blokken bij te houden in afzonderlijke blokken, de zogenaamde FAT of file allocation table.</simpara>
<simpara>Deze tabel bevat een wijzer per blok. In de plaats van de wijzers fysiek in de blokken te schrijven worden ze nu in de FAT geschreven.</simpara>
<simpara>Dit heeft als voordelen:
*  om een bestand te zoeken moet men slechts een paar blokken van de schijf lezen(de FAT)
* er moeten geen wijzers meer in de gegevensblokken opgeslagen worden
* men kan de FAT meer dan eens kan opslaan op de schijf om beperkte schijfdefecten op te vangen.</simpara>
<simpara>Vrije blokken kunnen teruggevonden worden door een speciaal teken op de plaats van de wijzer in de FAT. MS-DOS en OS/2 maken gebruik van een FAT.</simpara>
<simpara>Meestal bewaart men een kopie van de FAT (of delen ervan) in het geheugen om snel een blok op de schijf terug te kunnen vinden. Indien de FAT niet in het geheugen bijgehouden wordt, zal het telkens heen en terug swingen tussen de FAT-blokken en de werkelijke gegevens een aanzienlijke extra belasting van de schijf vormen.</simpara>
<figure>
<title>Allocatietabel</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/allocatie/allocatietabel.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>tabel voor allocatie</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_indextabel">
<title>Indextabel</title>
<simpara>Gelinkte allocatie of allocatietabellen zijn een afdoende oplossing voor het probleem van de externe fragmentatie, maar laten geen efficiënte directe toegang tot een bestand toe omdat de links sequentieel moeten afgelopen worden. Geïndexeerde allocatie laat dit wel toe. Het idee is dat alle wijzers naar de gealloceerde blokken sequentieel opgenomen worden in een zogenaamd indexblok. Dit indexblok kan dan gebruikt worden om een gegevensblok rechtstreeks terug te vinden.</simpara>
<figure>
<title>Geïndexeerde allocatie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/allocatie/indextabel.jpg" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>index voor allocatie</phrase></textobject>
</mediaobject>
</figure>
<simpara>Om niet beperkt te zijn tot bestanden met een te kleine maximale lengte kan men ofwel de indexblokken linken, ofwel verschillende niveaus van indexblokken creëren. Het topniveau verwijst dan naar indexblokken die op hun beurt verwijzen naar de gegevensblokken. Gecombineerde systemen komen ook voor.</simpara>
<simpara>Geïndexeerde allocatie maakt doorgaans minder efficiënt gebruik van de schijfruimte dan gelinkte allocatie. De meeste indexblokken zullen immers maar gedeeltelijk gevuld zijn. Bovendien zal men voor kleine bestanden i.p.v. een paar wijzers in de gegevensblokken zelf, een volledige indexblok moeten alloceren.</simpara>
<note>
<title>Opmerking: optimalisatie</title>
<simpara>De bovenstaande methodes zijn enkel de basisprincipes voor het beheer van bestanden op een schijf. In de praktijk zijn er veel variaties mogelijk om een snellere werking van het bestandssysteem te verkrijgen.
In het bijzonder zal het nuttig blijken om:</simpara>
<itemizedlist>
<listitem>
<simpara>De blokken zo groot mogelijk te nemen, rekening houdend met de interne fragmentatie dat dit met zich mee zal brengen. BSD Unix verandert de grootte van de blokken zelfs naarmate het bestand groter wordt. Dit laat toe om het percentage interne fragmentatie toch nog laag te houden.</simpara>
</listitem>
<listitem>
<simpara>De dynamische informatie in de directories beperkt te houden. Het bijhouden van het tijdstip waarop een bestand voor het laatst gebruikt werd zal een schrijfoperatie veroorzaken ook indien het bestand enkel gelezen werd.</simpara>
</listitem>
<listitem>
<simpara>Zoveel mogelijk blokken van de schijf in het geheugen te bewaren om meer dan eens lezen te vermijden. Sommige schijfregelaars zullen i.p.v. een sector steeds een volledig spoor inlezen omdat zij ervan uitgaan dat door de lokaliteit meer dan één sector zal gelezen worden. De meeste besturingssystemen hebben ook voorzieningen voor \textit{disk caches}. Solaris en Linux zal al het ongebruikte interne geheugen ter beschikking stellen als disk cache (zowel voor bestands-IO als voor paginering).</simpara>
</listitem>
<listitem>
<simpara>Free-behind - Read-ahead zijn twee methodes die naast LRU gebruikt kunnen worden om de disk cache beter te beheren bij sequenti\"ele toegang. Free-behind zal een blok vrijgeven van zodra een volgend blok ingelezen werd, en read-ahead zal ervoor zorgen dat er steeds 1 blok verder ingelezen wordt in een blokbuffer om de wachttijden bij het effectief opvragen van gegevens uit dat blok te beperken.</simpara>
</listitem>
<listitem>
<simpara>Om de schijfcapaciteit beter te benutten kan men de gegevens gecomprimeerd op de schijf plaatsen. Afhankelijk van het soort van gegevens dat men wil opslaan kan de hoeveelheid die men op deze manier kan opslaan een veelvoud zijn van de originele schijfcapaciteit. Bovendien kan de bandbreedte naar de schijf hierdoor in sommige gevallen vergroot worden omdat er minder gegevensuitwisseling zal zijn met de schijf terwijl het comprimeren en decomprimeren vrij snel kan gaan. Deze compressie is totaal transparant voor de gebruiker.</simpara>
</listitem>
</itemizedlist>
</note>
</section>
</section>
<section id="_mappen_directories">
<title>Mappen (directories)</title>
<simpara>Tegenwoordige hebben de meeste bestandssystemen een boomvormige directorystructuur waarbij alle gebruikers voorkomen als deelbomen van de boomstructuur die geassocieerd wordt met het volume. In deze vorm heeft de gebruiker beschikking over subdirectories die op hun beurt bestanden en subdirectories kunnen bevatten. Bestanden hebben nu niet enkel een naam, maar ook een pad, dit is een opeenvolging van de namen van subdirectories. Het pad en de bestandsnaam vormen dan een eenduidige specificatie van een bestand. Doordat alle gebruikers opgenomen zijn in dezelfde boomstructuur is het ook mogelijk om naar bestanden van andere gebruikers te refereren door zowel hun padnaam als hun bestandsnaam op te geven.</simpara>
<simpara>Padnamen kunnen zowel absoluut (ten opzichte van de root-directory), als relatief (ten opzichte van de huidige directory) zijn. Absolute padnamen hebben als voordeel dat ze in alle omstandigheden verwijzen naar dezelfde directory, maar ze kunnen hierbij wel aardig lang worden (100 tekens zijn geen uitzondering). Relatieve padnamen hebben als voordeel dat ze korter kunnen zijn, en dat ze in zekere zin `positie-onafhankelijk' zijn, dit wil zeggen dat ze binnen een bepaalde boomstructuur geldig blijven, ook wanneer de totale boom verplaatst wordt.</simpara>
<simpara>Boomvormige directorystructuren hebben echter ook hun nadelen:
. men zal het concept van `huidige directory' moeten invoeren om te weten in welke directory men aan het werken is,
. om bestanden terug te vinden kan men in verscheidene directories moeten gaan kijken, en soms wil men hierbij een bepaalde volgorde kiezen (PATH),
. er moeten voorzieningen getroffen worden om bepaalde bestanden in meer dan één directory op te nemen zonder deze te moeten kopi\"en of telkens opnieuw de volledige padnaam te moeten ingeven.</simpara>
<simpara>Om aan dit euvel te verhelpen bestaan er directorystructuren die kunnen voorgesteld worden door een acyclische graaf die zal toelaten dat een bepaald bestand in twee subdirectories voorkomt.</simpara>
<simpara>Om dit te realiseren kan men gebruik maken van zogenaamde links of shortcuts. Unix onderscheidt twee soorten links: symbolische links en harde links. Een symbolische link is gewoon een verwijzing naar een ander bestand. Uitwendig ziet een symbolische link eruit als een gewoon bestand, maar het is wel een bestand van een speciaal type, en het bevat geen gegevens, enkel de naam van het bestand waarnaar het wijst. Als het bestand waarnaar gewezen wordt verdwijnt, dan zal de symbolische link blijven bestaan, maar verwijzen naar een niet langer bestaand bestand.</simpara>
<simpara>De tweede soort link is de harde link. Deze is te vergelijken met het delen van geheugen door dezelfde frame-adressen op te nemen in twee paginatabellen. In dit geval zullen twee entries in de directorytabel wijzen naar hetzelfde fysieke bestand. Hierbij wordt een teller bijgehouden met het aantal links die verwijzen naar het bestand. Het wissen van een harde link zal enkel het wissen van het bestand tot gevolg hebben indien deze link de laatste link met een bestand was. Dit verklaart meteen waarom het wissen van een bestand in Unix soms ook unlink genoemd wordt. Voorbeelden van harde links zijn de bestanden `.' en `..' in de directories. Zij komen zowel voor in de huidige directory als in de ouderdirectory.</simpara>
<simpara>Het gebruik van links zorgt ervoor dat een directorystructuur niet langer een boomstructuur is maar een graaf. Indien er geen lussen voorkomen in de graaf spreekt men van een acyclische graaf. Een probleem met grafen is dat het doorzoeken van een graaf op zoek naar bepaalde informatie (bv. een bestand) complexer is dan het doorzoeken van een boom omdat men moet vermijden tweemaal hetzelfde deel van een graaf te doorzoeken. Bij acyclische grafen heeft het meermaals doorzoeken van een graaf enkel een effect op de snelheid waarmee een algoritme uitgevoerd wordt. Bij cyclische grafen kan dit aanleiding geven tot oneindige lussen, en dus een niet-terminerend algoritme.</simpara>
</section>
<section id="_swapruimte">
<title>Swapruimte</title>
<simpara>Zoals aangetoond wordt in het hoofdstuk over geheugenbeheer is het effect van een paginafout op de uitvoeringssnelheid van een programma dramatisch en moet men dan ook al het mogelijke doen om de interactie met de swapruimte zo efficiënt mogelijk te maken. We hebben gezien dat een virtueel-geheugensysteem gebruik maakt van pagina&#8217;s en dat deze pagina&#8217;s in paginering op aanvraag moeten kunnen uitgewisseld worden met de swapruimte.</simpara>
<simpara>Deze pagina&#8217;s zullen direct moeten kunnen geadresseerd worden. Met de technieken die gebruikt worden bij het klassieke bestandsbeheer zal deze directe toegang soms het lezen van meer dan één blok tot gevolg hebben. Bovendien zijn de blokken van het bestandssysteem niet steeds even groot als de pagina&#8217;s en de frames.</simpara>
<simpara>Men zal dan ook meestal verkiezen om de swapruimte onder te brengen in een afzonderlijke partitie met een eigen beheerssysteem waardoor het aantal schijftoegangen absoluut minimaal gehouden wordt bij het pagineren. Het voornaamste nadeel van deze aanpak is dat de swapruimte bij de generatie van het besturingssysteem moet vastgelegd worden (in de vorm van een partitie). Naderhand uitbreiden (als gevolg van het vergroten van het intern geheugen) is moeilijk omdat het het uitbreiden van een schijfpartitie betreft. Anderzijds zal bij een overdimensionering van de swapruimte de ongebruikte ruimte niet gebruikt kunnen worden voor bestandsopslag. Deze oplossing, ofschoon efficiënt, is heel wat minder flexibel dan het gebruik van een gegevensbestand als swapruimte.</simpara>
<simpara>Sommige systemen zoals Windows alloceren de swapruimte als een contigu bestand. Het voornaamste voordeel van deze aanpak is de eenvoud en het feit dat de swapruimte gemakkelijk kan uitgebreid worden. Het nadeel van deze aanpak is de traagheid omdat elke toegang tot de swapruimte via het bestandssysteem moet gaan.</simpara>
<simpara>De keuze tussen beide is een compromis tussen gewenste snelheid en gebruikersgemak.</simpara>
</section>
<section id="_vrije_ruimte">
<title>Vrije ruimte</title>
<simpara>De vrije ruimte op een schijf moet op een efficiënte manier kunnen bijgehouden worden om snel een vrij blok te kunnen terugvinden. Een aantal gebruikelijke methoden wordt hier besproken.</simpara>
<variablelist>
<varlistentry>
<term>Bitmap</term>
<listitem>
<simpara>Er wordt een bitrij bijgehouden waarbij elk bitje een blok voorstelt. Een vrij blok kan dan voorgesteld worden door 1, en een blok dat in gebruik is door een 0. Voor grote schijven kunnen de bitmaps ook een aanzienlijke ruimte in het geheugen gaan innemen. Ze moeten nu en dan op de schijf bewaard worden als beveiliging. Na een systeemcrash zal deze lijst opnieuw moeten opgebouwd worden uitgaande van de bestanden die op de schijf teruggevonden worden.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Gelinkte lijst</term>
<listitem>
<simpara>Gezien de vrije blokken toch niet gebruikt worden, kan een deel van elk blok gebruikt worden om ze met elkaar te linken. De kop van de lijst wijst steeds naar een vrij blok indien er een aanwezig is. Nadeel van deze methode is dat indien er bijvoorbeeld 100 blokken moeten gealloceerd worden, er ook 100 schijftoegangen nodig zijn om de gelinkte lijst af te lopen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Wijzerblok</term>
<listitem>
<simpara>Net zoals bij de gelinkte allocatie kunnen ook de vrije blokken in indexblokken opgenomen worden. In dit geval zal men meestal kiezen voor gelinkte indexblokken i.p.v. voor verschillende niveaus. Het voordeel van deze methode is dat men verschillende blokken ineens kan alloceren.</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_fragmentatie">
<title>Fragmentatie</title>
<simpara>Welke allocatiemethode men ook gebruikt na verloop van tijd zal de vrije ruimte geen aaneengesloten blok meer vormen, maar verspreid geraken over de volledige schijf. Het gevolg van deze versnippering zal zijn dat bestanden opgebouwd zullen worden uit blokken die zich op verschillende plaatsen op de schijf bevinden (behalve bij contigue allocatie). Doordat de kop van de schijf zich verschillende keren zal moeten verplaatsen om een dergelijk bestand te lezen, zal de prestatie van het bestandssysteem sterk dalen. Dit probleem is gekend, en wordt fragmentatie van de schijf genoemd.</simpara>
<simpara>Het probleem kan opgelost worden door de bestanden op de schijf te herschikken (defragmentatie en compactering). Hierbij zullen alle bestanden contigu gemaakt worden en wordt ook de vrije ruimte samengebracht. Deze techniek heeft zijn aanhangers en zijn tegenstanders. Aanhangers claimen dat de fragmentatie van de bestanden weggewerkt wordt hetgeen nuttig is voor de prestatie. Tegenstanders argumenteren dat door de compactie de volgorde van bestanden gewijzigd wordt, en dat dit een negatieve impact kan hebben op de prestatie. Indien men een pakket installeert op een nagenoeg lege schijf, is de kans groot dat alle bestanden van het pakket na elkaar op de schijf zullen komen te staan. Bij het opstarten van het pakket kunnen de bestanden dan één na één ingelezen worden, zonder dat de kop zich veel moet verplaatsen. Na compactering kunnen deze bestanden verspreid geraken over heel de schijf waardoor er tijd verloren wordt bij het springen van het ene bestand naar het andere.</simpara>
</section>
<section id="_een_bestandssysteem_mounten">
<title>Een bestandssysteem 'mounten'</title>
<simpara>Het secundair geheugen van een computersysteem kan uit verscheidene schijven bestaan. Deze schijven kunnen op verschillende manieren aan de gebruiker aangeboden worden. Ofwel krijgen ze een naam zoals in Windows: A: B: C: enz. waardoor ze expliciet zichtbaar blijven, ofwel worden ze opgenomen als subdirectory in een bestandssysteem waardoor ze transparant worden voor de gebruiker. (zoals bij unix/linux het geval is)</simpara>
<simpara>Men kan de directories van een bestandssysteem verdelen over de schijven, of met andere woorden, een schijf met haar eigen bestandssysteem (of systemen) wordt als subdirectory van het bestandssysteem van een andere schijf beschouwd. Dit laat toe om bestandssystemen te creëren die groter zijn dan één fysiek volume. Indien een schijf niet fysiek aanwezig is (bij DVD-stations bijvoorbeeld), zal deze subdirectory gewoon leeg zijn; indien de schijf aanwezig is, zal men in deze directory gegevens kunnen opvragen en bewaren. Eenmaal geconfigureerd is dit totaal transparant voor de gebruiker.</simpara>
</section>
<section id="_types_journaling_file_systems">
<title>Types: journaling file systems</title>
<simpara>Bestandssystemen zijn meestal grote datastructuren, veranderingen eraan veroorzaken meestal meerdere schrijfoperaties aan bestanden en directories. Dit introduceert een race-conditie, waarbij een onderbreking (zoals een stroomstoring of systeemcrash) kan leiden tot een inconsistente toestand.</simpara>
<simpara>Bijvoorbeeld, het wissen van een bestand op een UNIX systeem veroorzaakt twee stappen:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>het verwijderen van de directory-ingang</simpara>
</listitem>
<listitem>
<simpara>item het aanduiden van de bestandsinode als vrij ruimte</simpara>
</listitem>
</orderedlist>
<simpara>Als stap 1 uitgevoerd wordt net voor een crash dan zal er een inode als wees achterblijven.<?asciidoc-br?>
Omgekeerd als stap 2 als eerste voor de crach uitgevoerd wordt dan wordt de inode als vrije ruimte aangeduid en kan overgeschreven worden.</simpara>
<simpara>Een manier tot herstel is om de complete datastructuren van het bestandssysteem te doorlopen bij een volgende aankoppeling zodat onvolkomenheden kunnen gedetecteerd worden. Dit kan zeer traag verlopen voor grote bestandssystemen.</simpara>
<simpara>Een andere manier tot herstel is om een logbestand (journaal) bij te houden met alle veranderingen die moeten gemaakt worden.<?asciidoc-br?>
Herstellen kan dan eenvoudig door het logbestand te doornemen en alle onvolkomenheden te herstellen.</simpara>
<simpara>Enkele voorbeelden van journalizing bestandssystemen zijn JFS, EXT3/4, ReiserFS en NTFS</simpara>
</section>
<section id="_case_study_1_fat_file_system">
<title>Case study 1: FAT file system</title>
<simpara>Het FAT bestandssysteem komt voor in een aantal varianten, waarvan FAT16 (1986) en FAT32 (1996) ontegensprekelijk de bekendste zijn. Als primair bestandssysteem hebben ze allebei reeds lang afgedaan om redenen die later aan bod komen, maar ze vormen wel een ideale educatieve instap in de wereld van bestandssystemen. Recentere bestandssystemen zijn een stuk complexer, zoals we later zullen leren. FAT wordt tegenwoordig vanwege zijn eenvoud wel nog gebruikt op USB dongles, flash kaartjes etc.</simpara>
<figure>
<title>FAT organisatie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/fatstructureBb457122.f28zs06_big(l=en-us).jpg" contentwidth="500" width="45%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>fat organisatie</phrase></textobject>
</mediaobject>
</figure>
<simpara>In bovenstaande afbeelding zie je de opbouw van een FAT16 partitie. Vooraan bevindt zich, zoals altijd, het PBS met de nodige parameters. De PBS is een van de gereserveerde sectoren vooraan de partitie. Onmiddellijk na de gereserveerde sectoren volgen een aantal File Alocation Tables (FATs). In de figuur is dit aantal gelijk aan twee, het meest voorkomende geval.<?asciidoc-br?>
Na de FATs komt de root folder, gevolgd door de data clusters. In deze data clusters worden uiteraard de bits opgeslagen die de bestanden vormen. Belangrijke opmerking is dat deze bits georganiseerd worden in clusters. Een cluster is een reeks sectoren die steeds bij een welbepaald bestand horen.<?asciidoc-br?>
Bijvoorbeeld: indien een cluster bestaat uit 16kB (32 sectoren), dan zal een bestand van 1kB 16kB schijfruimte bezetten (een sector). <?asciidoc-br?>
Een bestand van 20kB zal verspreid worden over twee clusters, deze clusters moeten geen opeenvolgende clusters zijn (fragmentatie).<?asciidoc-br?>
Soms kan je de grootte van de clusters kiezen (bij het formatteren, afhankelijk van het bestandsysteem). Grotere clusters betekent dat bestanden minder snel gefragmenteerd zullen worden, maar betekent anderzijds dat meer ruimte verloren zal gaan (door onvolledig gevulde clusters).</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>PBS van een FAT32 partitie</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Offset</entry>
<entry align="left" valign="top">beschrijving</entry>
<entry align="left" valign="top">grootte</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>00h</simpara></entry>
<entry align="left" valign="top"><simpara>Jump Code + NOP</simpara></entry>
<entry align="left" valign="top"><simpara>3 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>03h</simpara></entry>
<entry align="left" valign="top"><simpara>OEM Name (Probably MSWIN4.1)</simpara></entry>
<entry align="left" valign="top"><simpara>8 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>0Bh</simpara></entry>
<entry align="left" valign="top"><simpara>Bytes Per Sector</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>0Dh</simpara></entry>
<entry align="left" valign="top"><simpara>Sectors Per Cluster</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>0Eh</simpara></entry>
<entry align="left" valign="top"><simpara>Reserved Sectors</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>10h</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Copies of FAT</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>11h</simpara></entry>
<entry align="left" valign="top"><simpara>Maximum Root DirectoryEntries (N/A for FAT32)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>13h</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Sectors inPartition Smaller than 32MB (N/A for FAT32)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>15h</simpara></entry>
<entry align="left" valign="top"><simpara>Media Descriptor (F8h forHard Disks)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>16h</simpara></entry>
<entry align="left" valign="top"><simpara>Sectors Per FAT in Older FATSystems (N/A for FAT32)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>18h</simpara></entry>
<entry align="left" valign="top"><simpara>Sectors Per Track</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1Ah</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Heads</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1Ch</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Hidden Sectors inPartition</simpara></entry>
<entry align="left" valign="top"><simpara>1 Double Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>20h</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Sectors inPartition</simpara></entry>
<entry align="left" valign="top"><simpara>1 Double Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>24h</simpara></entry>
<entry align="left" valign="top"><simpara>Number of Sectors Per FAT</simpara></entry>
<entry align="left" valign="top"><simpara>1 Double Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>28h</simpara></entry>
<entry align="left" valign="top"><simpara>Flags</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>2Ah</simpara></entry>
<entry align="left" valign="top"><simpara>Version of FAT32 Drive (HighByte = Major Version, Low Byte = Minor Version)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>2Ch</simpara></entry>
<entry align="left" valign="top"><simpara>Cluster Number of the Startof the Root Directory</simpara></entry>
<entry align="left" valign="top"><simpara>1 Double Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>30h</simpara></entry>
<entry align="left" valign="top"><simpara>Sector Number of the FileSystem Information Sector (See Structure Below)(Referenced from the Start of the Partition)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>32h</simpara></entry>
<entry align="left" valign="top"><simpara>Sector Number of the BackupBoot Sector (Referenced from the Start of the Partition)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>34h</simpara></entry>
<entry align="left" valign="top"><simpara>Reserved</simpara></entry>
<entry align="left" valign="top"><simpara>12 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>40h</simpara></entry>
<entry align="left" valign="top"><simpara>Logical Drive Number ofPartition</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>41h</simpara></entry>
<entry align="left" valign="top"><simpara>Unused (Could be High Byteof Previous Entry)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>42h</simpara></entry>
<entry align="left" valign="top"><simpara>Extended Signature (29h)</simpara></entry>
<entry align="left" valign="top"><simpara>1 Byte</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>43h</simpara></entry>
<entry align="left" valign="top"><simpara>Serial Number of Partition</simpara></entry>
<entry align="left" valign="top"><simpara>1 Double Word</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>47h</simpara></entry>
<entry align="left" valign="top"><simpara>Volume Name of Partition</simpara></entry>
<entry align="left" valign="top"><simpara>11 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>52h</simpara></entry>
<entry align="left" valign="top"><simpara>FAT Name (FAT32)</simpara></entry>
<entry align="left" valign="top"><simpara>8 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>5Ah</simpara></entry>
<entry align="left" valign="top"><simpara>Executable Code</simpara></entry>
<entry align="left" valign="top"><simpara>420 Bytes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1FEh</simpara></entry>
<entry align="left" valign="top"><simpara>Boot Record Signature (55hAAh)</simpara></entry>
<entry align="left" valign="top"><simpara>2 Bytes</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Hierboven zie je de inhoud van de partition boot sector van een FAT32 partitie.
We zullen niet alle parameters aanhalen, maar wel aantonen hoe het besturingssysteem een welbepaald bestand kan terugvinden en hoe het daarbij gebruik maakt van de opgeslagen informatie.</simpara>
<simpara>FAT32 heeft de volgende voordelen tegenover FAT16:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>FAT32 kan met grotere harde schijven (max. 2 Terabyte) werken dan FAT16 (max. 2 GB).</simpara>
</listitem>
<listitem>
<simpara>In FAT16 zijn er maar 512 entries mogelijk in de hoofddirectory. Met lange bestandsnamen die meerdere entries innemen kan dit al snel problemen geven. Daarom wordt de hoofddirectory in FAT32 opgeslagen zoals een gewone directory, zodat er een onbeperkt aantal entries in kunnen.</simpara>
</listitem>
<listitem>
<simpara>FAT32 gebruikt kleinere clusters, zodat er minder slack is. Dit is vooral van belang voor grotere schijven. Op een schijf van 2 GB kan je bijvoorbeeld gemakkelijk 200 tot 300 MB winnen met FAT32 (dat is 10 tot 15\%).</simpara>
</listitem>
<listitem>
<simpara>De beide FAT-tabellen staan niet meer in het begin van de schijf, zodat ze minder snel beschadigd worden.</simpara>
</listitem>
</orderedlist>
<simpara>In onderstaande afbeelding zie je de PBS van een SD-kaartje dat uit een Android smartphone komt. De sector werd hexadecimaal voorgesteld met een hex-editor. Probeer enkele van de eerder aangehaalde parameters terug te vinden. (de entries zijn gelijkaardig aan de entries voor een FAT16 partitie)</simpara>
<formalpara>
<title>hexadecimale voorstelling van de PBS van een FAT16 SD-kaart</title>
<para>De root folder bevat al de informatie over bestanden en mappen die opgeslagen zijn op de root folder. Als we ons beperken tot namen die voldoen aan het 8.3 formaat, dan is elk element in de root folder 32 bytes groot. Een belangrijk deel hiervan zijn de eerste elf bytes, die de karakters van de naam bevatten.<?asciidoc-br?>
Indien een bestand niet in de root folder zit, maar is ondergebracht in een andere map, kan vanuit de root folder het volledige pad gevolgd worden tot we uiteindelijk in de juiste map terecht komen. Daar staat de informatie dan op gelijkaardige manier opgeslagen als in de root folder.</para>
</formalpara>
<example>
<title>Voorbeeld: zoeken van een bestand in een FAT-partitie.</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>De eerste stap is het opzoeken van de root folder. Uit het partition boot sector kan je de structuur van de partitie afleiden:</simpara>
<itemizedlist>
<listitem>
<simpara>het aantal gereserveerde sectoren</simpara>
</listitem>
<listitem>
<simpara>het aantal FAT’s</simpara>
</listitem>
<listitem>
<simpara>het aantal sectoren per fat</simpara>
</listitem>
<listitem>
<simpara>aantal bytes per sector</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Op basis hiervan kan het besturingssysteem bepalen op welk sectornummer de root folder start (start root = aantal gereserveerde sectoren + aantal FAT’s * aantal sectoren per FAT). Merk op dat in het PBS ook het aantal bytes per sector is opgegeven, zodat je ook het byte-adres kan berekenen (sectornummer * aantal bytes per sector).</simpara>
</listitem>
<listitem>
<simpara>Zodra het adres van de root folder gevonden is kan het besturingssysteem op zoek naar de naam van het gevraagde bestand.</simpara>
</listitem>
<listitem>
<simpara>Als dan het juiste element in de root folder gevonden is (op basis van bestandsnaam), kan de overige informatie gebruikt worden om het bestand terug te vinden op de partitie.
Vooral de laatste 4 bytes zijn belangrijk. Die bevatten namelijk de lengte van het bestand (in bytes) en de 16 bits daarvoor bepalen het eerste clusternummer waar er data terug te vinden is.</simpara>
</listitem>
<listitem>
<simpara>Op basis van het clusternummer moet het besturingssysteem gaan kijken in de FAT tabel om zo te weten te komen als het bestand bestaat uit één dan wel uit meerdere clusters.</simpara>
<itemizedlist>
<listitem>
<simpara>De verschillende FAT-tabellen zijn in principe (tenzij er fouten optreden) kopieën van elkaar, dus maakt het in principe niet uit in welke tabel gekeken wordt.</simpara>
</listitem>
<listitem>
<simpara>Bij FAT16 bestaat elk element in de FAT tabel uit 16 bits. Elk element is gelinkt met een welbepaald clusternummer (element 2 hangt samen met cluster 2, element 3 hangt samen met cluster 3, &#8230;&#8203;).</simpara>
</listitem>
<listitem>
<simpara>De inhoud van de twee bytes bepalen hoe een cluster samenhangt met de andere:</simpara>
<itemizedlist>
<listitem>
<simpara>0000h: 		Available Cluster</simpara>
</listitem>
<listitem>
<simpara>0002h-FFEFh	used, Next Cluster in File</simpara>
</listitem>
<listitem>
<simpara>FFF0h-FFF6h 	reserved Cluster</simpara>
</listitem>
<listitem>
<simpara>FFF7h		BAD Cluster</simpara>
</listitem>
<listitem>
<simpara>FFF8h-FFFF	Used, Last Cluster in File</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Op basis van het eerste clusternummer kan het besturingssysteem alle clusters en de volgorde waarin ze een bestand vormen terug vinden. Het komt er dan op aan om alle clusters volledig uit te lezen, behalve het laatste cluster, waarvan enkel voldoende bytes gelezen moeten worden om in totaal aan de in de root folder terug te vinden grootte te voldoen.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
</example>
<figure>
<title>voorbeeld FAT-tabel met fragmentatie</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/FAT16example.png" contentwidth="300" width="30%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>FAT-tabel met fragmentatie</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_case_study2_ntfs">
<title>Case study2: NTFS</title>
<simpara>NTFS is een bestandssysteem dat standaard gebruikt wordt op alle recente Windows versies. Het is een gesloten systeem, ontstaan door een doorontwikkeling van HPFS, een samenwerking tussen IBM en Microsoft.<?asciidoc-br?>
NTFS werkt op een andere manier dan FAT16 en zal dus ook andere informatie opslaan in de PBS. NTFS maakt bijvoorbeeld geen gebruik van FATs, dus zal er ook geen aantal FATs of grootte van de FAT opgegeven worden in de PBS. NTFS maakt gebruik van een Master File Table (MFT), waarin alle relevante informatie over een bestand wordt opgeslagen. [3]</simpara>
<simpara>Deze informatie is een stuk uitgebreider dan in de root folder van een FAT systeem, het is zelfs mogelijk dat voor een klein bestand de data volledig in de MFT wordt opgeslagen. Is dit niet het geval, dan is voor het opzoeken van het bestand de meest relevante informatie die in het MFT aanwezig is, de naam van het bestand en de runlist.<?asciidoc-br?>
Bij het opzoeken van een bestand is de eerste stap dus het terugvinden van de MFT. Hiervoor staat in het PBS het cluster nummer opgegeven waar het MFT start. Aangezien in het PBS ook het aantal sectoren per cluster terug te vinden zijn, kan weer het sector adres van de MFT teruggevonden worden. Binnen de MFT zal gezocht moeten worden op de naam van het gevraagde bestand. Als het betreffende record dan wordt teruggevonden, kan binnen dit record de runlist worden opgezocht.<?asciidoc-br?>
De runlist is onderdeel van het $DATA attribuut (start van dit attribuut wordt gekenmerkt door 80H), waarbinnen ook de ingenomen en werkelijke grootte van het bestand terug te vinden is. De runlist bestaat uit een aantal opeenvolgende bytes:</simpara>
<orderedlist numeration="arabic">
<title>opbouw van een runlist</title>
<listitem>
<simpara>Het eerste byte wordt opgesplitst in twee nibbles.</simpara>
<itemizedlist>
<listitem>
<simpara>Het meest significante nibble duidt aan hoeveel bytes gebruikt worden voor de offset (stel K)</simpara>
</listitem>
<listitem>
<simpara>Het minst significante nibble geeft aan hoeveel bytes gebruikt worden voor de lengte (stel N)</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>De volgende N bytes geven in little endian notatie aan hoeveel clusters na elkaar in gebruik zijn voor deze stream.</simpara>
</listitem>
<listitem>
<simpara>De volgende K bytes geven aan op welke clusteroffset de stream begint (weer in little endian notatie).</simpara>
</listitem>
</orderedlist>
<simpara>Indien het volgende byte 0x00 is, eindigt de runlist hier, anders moet je vanaf hier de bytes weer op dezelfde manier interpreteren.</simpara>
<example>
<title>interpretatie van een runlist</title>
<simpara>runlist = <emphasis>31 0A 21 23 05 00 34</emphasis> &#8230;&#8203;</simpara>
<simpara>Het eerste byte geeft aan dat het eerstvolgende het aantal clusters bepaalt en de drie daarop volgende een offset. Daarna volgt er 00, dus verder geen data. Dus de data staat in 10 clusters te beginnen vanaf cluster 0x052321. Op deze manier is het mogelijk om verschillende reeksen clusters in de juiste volgorde te gaan lezen.</simpara>
<simpara>Van de laatste cluster moeten weer net genoeg bytes gelezen worden om evenveel bytes te lezen als opgegeven bij de werkelijke grootte van het bestand.</simpara>
</example>
</section>
<section id="_case_study_3_ext4">
<title>case study 3: Ext4</title>
<simpara>EXT staat voor Extended file system. Dit bestandssysteem bouwt verder op standaard linux file systems. Het wordt gezien als een brug tussen Ext3 en de meer geavanceerde bestandssystemen, en is tegenwoordig zowat op alle linux distributies standaard. (al lijkt het rijk van EXT bedreigd: bijvoorbeeld op RHEL is tegenwoordig XFS de standaard bestandsindeling. Ook op Android is EXT sinds versie 2.3 het default bestandssysteem.</simpara>
<section id="_inodes">
<title>Inodes</title>
<simpara>In Unix maakt men gebruik van een gecombineerd systeem met inodes.</simpara>
<simpara>Inodes komen voor in twee types:</simpara>
<variablelist>
<varlistentry>
<term>Directory inodes</term>
<listitem>
<simpara>Deze bevatten de info van een bepaalde map, met onder meer de subdirectories en bestanden.
Merk op dat deze inodes ook de bestandsnaam bevatten.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Data file inodes</term>
<listitem>
<simpara>De data file inodes bevatten de informatie over waar een bepaald bestand kan gevonden worden op de schijf. Merk op dat deze inodes de bestandsnaam NIET bevatten. Door deze werkwijze kan je in principe twee verschillende bestandsnamen gebruiken voor één fysiek bestand. In Linux heet zoiets ‘hard-linking’.
Zo’n inode voor een bestand bevat Directe, single indirecte, double indirecte en zelfs triple indirecte verwijzigingen naar bestandslocaties. Deze constructie wordt snel duidelijker met een afbeelding:</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Hierbij wordt een vast aantal indices opgenomen als attributen van een bestand in de zogenaamde inode (dit is een gegevensstructuur die zich tussen de directory-entry en het fysiek bestand bevindt. Per fysiek bestand is er slechts 1 inode, maar kunnen er verschillende directory-entries zijn. De inode houdt o.m. bij hoeveel harde links er naar een bestand bestaan). Naast dit beperkt aantal directe indices (bv. 12) die zullen volstaan voor de bestanden kleiner dan bv. 48 Kb, is er nog een wijzer naar een indexblok van niveau 1, en ook nog een wijzer naar een indexblok van niveau 2 (en zelfs naar niveau 3).</simpara>
<simpara>Deze oplossing laat toe om snel directe toegang te hebben tot kleine bestanden, redelijk snel tot de middelgrote bestanden, en aanvaardbaar voor de echt grote bestanden waarbij de grootte van de bestanden niet beperkt wordt door de implementatie van het bestandssysteem, maar door de grootte van de schijf. Dit is prima omdat in de praktijk toch blijkt dat minder dan 5% van alle bestanden groter zijn dan 48KB en dus een indexblok nodig hebben. Alle andere kunnen het stellen zonder afzonderlijk indexblok.</simpara>
<figure>
<title>Inode structuur (bron onbekend)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch04/images/unix_filesys5.png" contentwidth="500" width="75%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>inode structuur</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_andere_bestandssystemen">
<title>Andere bestandssystemen</title>
<simpara>Met de opgesomde bestandssystemen is de lijst uiteraard niet compleet.  Een niet limitatief overzichtje met de meest opvallende features. Deze zijn vaak niet toegankelijk met Windows, omdat Microsoft hiervoor geen drivers ontwikkelt.</simpara>
<section id="_btfrs">
<title>BTFRS</title>
<simpara>BTFRS wordt algemeen beschouwd als de opvolger van EXT4 in Linux. Het bestandssysteem kan reeds gebruikt worden, maar wordt niet nog stabiel genoeg geacht voor productieomgevingen. Bij elke nieuwe versie van de Linuxkernel worden nieuwe features toegevoegd en bugs geplet.</simpara>
<simpara>Features:</simpara>
<itemizedlist>
<listitem>
<simpara>Ondersteuning voor snapshots</simpara>
</listitem>
<listitem>
<simpara>Ondersteuning voor quotas</simpara>
</listitem>
<listitem>
<simpara>…</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_zfs">
<title>ZFS</title>
<simpara>ZFS werd oorspronkelijk ontwikkeld door SUN, en heeft een erg rijke featureset, die BTFRS en EXT4 ruim achter zich laat. Door conflicterende licenties is het niet standaard te vinden in linux-distributies, maar het kan meestal wel achteraf geconfigureerd worden.</simpara>
</section>
<section id="_re_fs">
<title>Re-Fs</title>
<simpara>Dit nieuwe bestandssysteem is momenteel enkel ondersteund door Windows server 2012, en ervan booten is nog niet ondersteund. Het bevat enkele features die vooral bij kritieke data belangrijk zijn.</simpara>
</section>
<section id="_f2fs">
<title>F2FS</title>
<simpara>Dit nieuwe bestandssysteem is speciaal opgebouwd om een hoog rendement te halen op flash disks.</simpara>
</section>
</section>
<section id="_bestanden_wissen">
<title>Bestanden wissen</title>
<simpara>Bestanden verwijderen van een harde schijf is soms minder eenvoudig dan het lijkt. Indien de bits herschreven worden, zijn er technologisch nog mogelijkheden die toelaten om na te gaan wat vorige waarden waren. Hier gaan we niet op die technieken in. Het is ook interessant om te weten wat er op een bestandsysteem gebeurt wanneer een bestand gewist wordt. Aan de snelheid waarmee een grote hoeveelheid of grote bestanden gewist worden kan je al merken dat niet elk byte op de schijf gewist wordt. In plaats daarvan zal de verwijzing in het bestandsysteem worden aangepast.<?asciidoc-br?>
In het geval van FAT16 wordt een speciaal karakter gebruikt om de naam in de root folder mee te beginnen en worden alle clusters die gebruikt werden, in de FAT tabel als ongebruikt gemarkeerd.<?asciidoc-br?>
Het is in dit geval nog mogelijk om het bestand terug te vinden, op voorwaarde dat het niet gefragmenteerd was. In geval van fragmentatie is de (gewiste) FAT tabel nodig om de juiste clusters en hun volgorde terug te vinden.<?asciidoc-br?>
Bij NTFS wordt enkel het MFT record aangepast, waarin een parameter zal aangeven dat het bestand gewist is. Aangezien dit anders gemarkeerde, maar niet gewiste MFT record nog steeds alle informatie bevat (via de runlist) is het nu mogelijk om ook gefragmenteerde gewiste bestanden terug te vinden. Belangrijke voorwaarde is wel dat de vrijgekomen ruimte nog niet beschreven mag zijn voor een ander bestand (en uiteraard mag het MFT record ook nog niet overschreven zijn).</simpara>
<simpara>Bedenk zelf of data nog terug te vinden is als je een schijf formatteert. Bij het formatteren worden de nodige controlestructuren (PBS, FATs/MFT, &#8230;&#8203;) aangebracht en worden alle preambules van de sectoren vastgelegd.</simpara>
</section>
</section>
<section id="_snelheid_bij_disks_iops">
<title>Snelheid bij disks: IOPS</title>
<simpara>Zie bijkomend lesmateriaal op Toledo
===	Opslagmedia combineren: RAID</simpara>
<section id="_types">
<title>Types</title>
<section id="_raid0">
<title>RAID0</title>
<simpara>Zie slides op Toledo</simpara>
</section>
<section id="_raid1">
<title>RAID1</title>
<simpara>Zie slides op Toledo</simpara>
</section>
<section id="_raid10">
<title>RAID10</title>
<simpara>Zie slides op Toledo</simpara>
</section>
<section id="_raid5">
<title>RAID5</title>
<simpara>Zie slides op Toledo</simpara>
</section>
</section>
<section id="_gecombineerde_snelheid">
<title>Gecombineerde snelheid</title>
<simpara>Zie slides op Toledo</simpara>
</section>
</section>
<section id="_bronvermelding_bij_dit_hoofdstuk_2">
<title>Bronvermelding bij dit hoofdstuk</title>
<itemizedlist mark="Bibliography">
<listitem>
<simpara><anchor id="MANGAN" xreflabel="[MANGAN]"/>[MANGAN] 'Advanced format 4K disk drives and performance'. Tim Mangan, <ulink url="http://www.brianmadden.com/blogs/timmangan/archive/2010/08/16/advanced-format-4k-disk-drives-and-performance.aspx">http://www.brianmadden.com/blogs/timmangan/archive/2010/08/16/advanced-format-4k-disk-drives-and-performance.aspx</ulink></simpara>
</listitem>
<listitem>
<simpara><anchor id="PCPART" xreflabel="[PCPART]"/>[PCPART] 'storage trends'. <ulink url="https://pcpartpicker.com/trends/internal-hard-drive/">https://pcpartpicker.com/trends/internal-hard-drive/</ulink> . accessed 27/08/2014</simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter id="_opstartroutine">
<title>Opstartroutine</title>
<section id="_geheugens_voor_opstartroutinge">
<title>Geheugens voor opstartroutinge</title>
<simpara>Een processor kan bij het opstarten enkel spreken met geheugen. Om een besturingssysteem te laden op een harde schijf is dus een tussenstap nodig.
Dit geheugen mag uiteraard niet volatiel zijn.</simpara>
<simpara>Er zijn verschillende soorten ROM geheugens die momenteel nog relevant zijn:</simpara>
<variablelist>
<varlistentry>
<term>MROM</term>
<listitem>
<simpara>Masked-programmed ROM is echt read-only geheugen. Het krijgt zijn inhoud tijdens de fabricage en deze inhoud kan nadien niet meer veranderd worden door een gebruiker.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>PROM</term>
<listitem>
<simpara>Programmable ROM is eigenlijk ook read-only. De inhoud kan met behulp van een speciaal programmeertoestel eenmaal vastgelegd worden. Nadien kan de inhoud niet meer gewijzigd worden.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>EEPROM</term>
<listitem>
<simpara>(<emphasis>Electrically Erasable PROM</emphasis>). Ook met dit type geheugen kan de inhoud gewist en vervolgens aangepast worden. Het verschil met EPROM is dat nu geen UV-licht nodig is, maar dat elektrische signalen volstaan voor het wissen. Dit kan dus met hetzelfde toestel als waarmee geprogrammeerd wordt. Het nadeel van EEPROM is de kostprijs. Voor dezelfde densiteit is het een pak duurder dan EPROM.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Flash</term>
<listitem>
<simpara>is net zoals EEPROM te wissen en opnieuw te beschrijven met elektrische signalen. Bovendien is voor flash geen speciaal programmeertoestel nodig. Aan de andere kant haalt het met EPROM vergelijkbare densiteiten. Bovendien is geen speciale verpakking met glas nodig.<?asciidoc-br?>
Het nadeel van flash is dat het minder dikwijls herschreven kon worden dan EEPROM. Voor toepassingen waar regelmatig de data moet worden aangepast, bestaat ondertussen high-endurance flash. Gewoon flash geheugen kan tussen 300.000 en 500.000 keer herschreven worden. De high-endurance variant een paar miljoen keer. Extra probleem hierbij is dat geen individuele cellen aangepast kunnen worden, maar dat steeds ganse blokken in een keer geschreven moeten worden. Hierdoor kan deze beperking nog zwaarder doorwegen (cel wordt meer beschreven dan dat ze wordt veranderd).</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>De BIOS routines worden nu meestal opgeslagen op flash geheugens, wat toelaat om de routines te upgraden. Bij dergelijke upgrades is het natuurlijk cruciaal dat er niets mis gaat, want dan zal de computer niet meer in staat zijn om op te starten. Sommige moederbord fabrikanten voorzien in een procedure om terug te keren naar een vorige versie wanneer een flash operatie mislukt. Als een dergelijke procedure niet voorhanden is, kan je enkel nog hopen dat de flash-IC niet vast gesoldeerd is, zodat je hem met een andere programmer kan programmeren.</simpara>
</section>
<section id="_opstartroutine_met_bios">
<title>Opstartroutine met BIOS</title>
<simpara>Bij het aanschakelen van de spanning wordt een reeks stappen doorlopen. De volgorde is afhankelijk van de fabrikant van de hardware (de hoofdkaart, BIOS, CMOS en andere componenten). Onderstaande stappen worden steeds uitgevoerd.</simpara>
<section id="_systeemstart">
<title>Systeemstart</title>
<simpara>Eerst start de interne voeding op. Het duurt even voor alle lijnen een stabiele spanning afgeven. Eens dit het geval is geeft de voeding een power good-signaal. De chipset, die gevoed werd door de 5V standby lijn, zal het reset-signaal pas wegnemen op het ogenblik dat het power good signaal komt. Zodra het reset signaal wegvalt, zal de computer beginnen opstarten. De processor begint op adres FFFFOh, waar de uitvoering van de BIOS opstartroutine begint.</simpara>
</section>
<section id="_power_on_self_test_post">
<title>Power On Self Test (POST)</title>
<simpara>De opstartroutine uit de BIOS voert de Power-on-self-test (POST) uit. Indien er fatale fouten ontdekt worden, geeft het een foutmelding, indien om de een of andere reden de grafische kaart niet bruikbaar is enkele BEEP-signalen, en stopt het startproces. Dit kan bijvoorbeeld het geval zijn indien er een probleem met de grafische kaart ontdekt wordt (de kaart is defect of is niet goed ingeplugd) of wanneer de kabel voor de harde schijf verkeerd aangesloten werd.</simpara>
</section>
<section id="_zoeken_naar_bios_uitbreidingen">
<title>Zoeken naar BIOS-uitbreidingen</title>
<simpara>De systeem-BIOS is niet het enige BIOS in een computer. Grafische kaarten, harde schijven, storage-adapters en andere hebben ook hun eigen BIOS. Het systeem-BIOS gaat daarom onmiddellijk op zoek naar de grafische kaart en laat het ingebouwde video-BIOS programma uitvoeren. Hierdoor verschijnt er informatie over de kaart op het scherm. Deze informatie is doorgaans slechts heel even op het scherm.</simpara>
<simpara>Daarna voert de computer enkele tests uit op het systeem (vervolg POST): onder andere het geheugen wordt onderzocht en de geheugenplaatsen geteld. Het BIOS zal bij een defect een foutmelding geven.<?asciidoc-br?></simpara>
<simpara>Vervolgens begint het de startroutine aan een inventarisatie waarbij de meeste klassieke randapparatuur (printerpoorten, seriële poorten, floppy- en harddisk controllers) gedetecteerd zal worden.<?asciidoc-br?></simpara>
<simpara>Een recente BIOS zal zelfs automatisch het soort geheugen herkennen en de juiste parameters voor de harde schijf instellen.<?asciidoc-br?>
Meestal wordt op het scherm getoond welke apparaten, harde schijf, DVD-ROM, … gevonden en herkend worden.</simpara>
<formalpara>
<title>Oefening</title>
<para>
<screen>Zoek voor het moederbord van jouw pc op welke auditieve foutcodes van toepassing zijn.</screen>
</para>
</formalpara>
</section>
</section>
<section id="_plug_and_play_configuratie">
<title>Plug and play configuratie</title>
<simpara>Indien een plug and play ondersteunend bussysteem (zoals PCI) aanwezig is, zal een plug and play configuratie fase doorlopen worden: Er wordt gezocht naar P&amp;P-devices op alle aanwezige I/O bussen (PCI, PCI Xpress, AGP). Dit wordt de enumeration genoemd. Voor elk gevonden device wordt gelezen welke resources (I/O-adressen, Interrupts, DMA-kanalen, geheugenruimte) er nodig zijn. De lijst met de vorige configuratie (inclusief de vroegere toekenning van de resources) wordt uit het ESCD geladen en vergeleken met de nieuwe informatie. Het ESCD (Extended System Configuration Data) is een deel van het CMOS-RAM geheugen. Hierin wordt de P&amp;P-configuratie opgeslagen.</simpara>
<simpara>Bij het opstarten controleert het BIOS deze gegevens op wijzigingen sinds de laatste start om te weten of bepaalde instellingen moeten aangepast worden. Indien er geen verandering is, gaat het opstartproces gewoon verder.<?asciidoc-br?>
In het andere geval begint er een herconfiguratie.</simpara>
<simpara>De BIOS-setup informatie wordt geraadpleegd voor eventuele gereserveerde systeembronnen door niet Plug and Play-kaarten. Overblijvende systeembronnen worden toegekend aan de PnP-kaarten. Het ESCD wordt bijgewerkt met de mededeling “Updating ESCD&#8230;&#8203; successfull”.</simpara>
<simpara>Het bootproces gaat verder. Wanneer het besturingssysteem opgestart is, heeft dat tenslotte nog de mogelijkheid om de Plug and Play-configuratie te controleren en eventueel te wijzigen.</simpara>
</section>
<section id="_extensible_firmware_interface">
<title>Extensible Firmware Interface</title>
<section id="_bios_op_pensioen">
<title>BIOS op pensioen</title>
<simpara>Het systeem van de BIOS is één van de laatste onderdelen die nog niet substantieel veranderd zijn sinds de introductie van de PC lang geleden. Hoewel er geprobeerd wordt om de technische details wat weg te stoppen voor de eindgebruiker, is het toch nog steeds een erg gebruiksonvriendelijke omgeving. Het gebrek aan ondersteuning van bijvoorbeeld muizen is daar een goed voorbeeld van.<?asciidoc-br?>
Aan de binnenkant van het BIOS-raderwerk was de situatie zo mogelijk nog een pak erger. Het programmeren ervan gebeurde voor een stuk in machinecode, en het toevoegen van functionaliteit was grotendeels patchwork. Slechts erg weinig mensen hebben de nodige ervaring om hieraan te programmeren. Sommige zaken zijn zelfs niet op te lossen. Een voorbeeld hiervan is de maximum grootte van de opstartpartitie, die is 2TB. Over enkele jaren zal dat ongetwijfeld te weinig zijn.<?asciidoc-br?>
Daarom zijn er in de loop der tijd enkele pogingen geweest om dit systeem te vervangen. Weinigen daarvan hadden veel succes. Veel had te maken met de licentie waaronder moest gecodeerd worden. Bedrijven waren immers niet bereid om de code van hun drivers vrij te geven.<?asciidoc-br?>
Ook Intel deed een poging om de BIOS overbodig te maken door een ander systeem. Om het project voldoende momentum te bezorgen, werd een organisatie opgebouwd rond deze technologie, met als doel ze te standaardiseren. Deze technologieën zijn verzameld in de EFI (Extensible Firmware Interface).</simpara>
<simpara>Deze technologie verschilt fundamenteel van de verouderde BIOS.</simpara>
<itemizedlist>
<listitem>
<simpara>Gecodeerd in een breed gekende taal (C++)</simpara>
</listitem>
<listitem>
<simpara>Volledig modulair</simpara>
</listitem>
<listitem>
<simpara>Compatibel met de oude BIOS om de overgang mogelijk te maken.</simpara>
</listitem>
<listitem>
<simpara>Drivers kunnen opgenomen worden in deze EFI</simpara>
</listitem>
<listitem>
<simpara>De 2TB-grens voor de opstartpartitie is hier niet bestaande</simpara>
</listitem>
</itemizedlist>
<simpara>Door dit vernieuwde opzet zullen ongetwijfeld een pak nieuwe mogelijkheden toegevoegd worden aan de PC zoals we hem nu kennen. EFI laat zich nog het best vergelijken met een micro-besturingssysteem.
Enkele voorbeelden van nieuwe toepassingen:</simpara>
<itemizedlist>
<listitem>
<simpara>Omdat drivers kunnen geïntegreerd worden, kan het veel makkelijker worden om een nieuw besturingssysteem te installeren. Rondzeulen met driverdisks voor eenvoudige devices zou dus moeten verleden tijd worden.</simpara>
</listitem>
<listitem>
<simpara>EFI kan makkelijk uitgebreid worden met kleine toepassingen. Denk bijvoorbeeld aan een mediaplayer. Zo zou je kunnen je laptop gebruiken als mediaspeler, zelfs zonder dat die ‘echt’ opgestart is.</simpara>
</listitem>
<listitem>
<simpara>EFI zou kunnen voorzien worden van een virtualisatielaag zodat je meerdere besturingssystemen tegelijkertijd kan gebruiken.</simpara>
</listitem>
<listitem>
<simpara>Hoewel de mogelijkheden nagenoeg eindeloos zijn, is te verwachten dat de eerste gebruikte EFI’s niet veel meer functionaliteit hebben dan de vroegere BIOS’en.</simpara>
</listitem>
</itemizedlist>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch05/images/UEFI_01.jpg" contentwidth="500" width="500%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>UEFI interface (voorbeeld)</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
<section id="__u_efi_verspreiding">
<title>(U)EFI verspreiding</title>
<simpara>Aan EFI wordt sedert 2002 gewerkt door enkele grote firma’s. Nagenoeg elke grote hardware bouwer heeft zich bij de organisatie aangesloten. Toch zal het nog een tijd duren vooraleer we het BIOS volledig kunnen naar de geschiedenis verwijzen. Een overzichtje van de ondersteuning tegenwoordig:</simpara>
<itemizedlist>
<listitem>
<simpara>Apple: standaard op alle recente computers (met BIOS-support)</simpara>
</listitem>
<listitem>
<simpara>Microsoft: standaard vanaf vista X64 sp1</simpara>
</listitem>
<listitem>
<simpara>Linux: reeds lange tijd standaard geïmplementeerd</simpara>
</listitem>
</itemizedlist>
<simpara>Ook moederborden bieden tegenwoordig meestal ondersteuning, al zullen ze vaak nog manueel moeten ingesteld worden om UEFI te selecteren, BIOS blijft voorlopig nog even default.</simpara>
</section>
</section>
<section id="_coreboot">
<title>Coreboot</title>
<simpara>Een tweede alternatief voor BIOS is Coreboot. Dit project is conceptueel verschillend van UEFI omdat coreboot zichzelf probeert overbodig te maken. Zo snel mogelijk na het opstarten wordt de controle doorgegeven aan het besturingssysteem.
Coreboot zal de meest elementaire hardware initialiseren (vb RAM-geheugeh) Het besturingssysteem krijgt dan alle verdere controle. Coreboot bevat zelfs geen GUI.
De coreboot-code is daardoor erg compact en snel.</simpara>
<simpara>Besturingssystemen die niet rechtstreeks kunnen booten via coreboot, kunnen gebruik maken van een alternatieve 'payload' die compatibiliteit met BIOS garandeert.</simpara>
<simpara>Deze technologie is momenteel (nog?) niet breed ondersteund, maar is bijvoorbeeld wel bij chromebooks in gebruik.</simpara>
</section>
</chapter>
<chapter id="_internal_i_o">
<title>Internal I/O</title>
<simpara>In dit hoofdstuk wordt een overzicht gegeven van de verschillende manieren waarop data uitgewisseld wordt op het moederbord, en met de systeemapparaten.</simpara>
<section id="_i_o_transfers">
<title>I/O transfers</title>
<simpara>Naast processor en geheugen vormt I/O het derde fundamenteel onderdeel van een computersysteem. Er zijn een aantal verschillende soorten manieren om data te versturen of te ontvangen van een I/O apparaat. Afhankelijk van het type I/O apparaat is een bepaald soort transfer beter geschikt dan de andere. Het is aan het besturingssysteem of aan de in het besturingssysteem geïntegreerde drivers om de I/O transfers af te handelen.</simpara>
<simpara>Drie types onderscheiden zich:</simpara>
<itemizedlist>
<listitem>
<simpara>pollen</simpara>
</listitem>
<listitem>
<simpara>interrupts</simpara>
</listitem>
<listitem>
<simpara>direct memory access</simpara>
</listitem>
</itemizedlist>
<section id="_pollen">
<title>Pollen</title>
<simpara>'Pollen' staat voor bevragen.
Dit is ook exact wat de processor zal doen: de processor zal voortdurend de I/O gaan bevragen om te kijken of er een actie van de CPU gewenst is.<?asciidoc-br?>
Het voordeel van pollen is dat een verandering bij het I/O apparaat onmiddellijk wordt opgemerkt en de processor dus ook ogenblikkelijk kan reageren. Het belangrijkste nadeel is dat de processor voortdurend de toestand van het I/O apparaat moet controleren.<?asciidoc-br?>
Wanneer de processor de toestand controleert, kan hij uiteraard geen andere (nuttige) taken uitvoeren.<?asciidoc-br?>
Pollen vraagt dus behoorlijk wat rekenkracht, ook al is die niet echt nodig om het trage I/O apparaat aan te sturen.<?asciidoc-br?>
Voor dit probleem kan eventueel gedeeltelijk een oplossing voor gevonden worden bij multitasking, waardoor het wachten kan afgewisseld worden met andere taken.</simpara>
<simpara>Voorgaande maakt waarschijnlijk wel duidelijk dat pollen niet echt bruikbaar is voor invoerapparaten, die moeten immers voortdurend gecontroleerd worden.</simpara>
<simpara>Polling wordt niet veel meer gebruikt voor gangbare PC I/O, maar is een zeer eenvoudige techniek en is dikwijls de eerste oplossing bij het schrijven van eigen interfaces voor bijvoorbeeld microcontroller-toepassingen.</simpara>
</section>
<section id="_interrupts">
<title>Interrupts</title>
<simpara>In het geval van interrupt driven I/O zal het I/O apparaat de processor onderbreken. Dit betekent dat het I/O apparaat zelf om aandacht zal vragen en niet voortdurend gecontroleerd moet worden door de processor. De werking van interrupts zal hier uitgelegd worden voor een 8086 processor. Op een modern systeem verandert de werking van het geheel een beetje omwille van de afscherming van I/O door een buscontroller (zie verder), maar de principiële afhandeling van een interrupt door een processor blijft gelijk.</simpara>
<section id="_interrupthardware">
<title>Interrupthardware</title>
<simpara>De processor beschikt over een aparte INT-ingang, langs waar I/O een interruptsignaal kan doorgeven. Om meerdere interrupts van verschillende I/O toe te laten zou de processor moeten beschikken over meerdere ingangen, waar liefst nog een prioriteit aan verbonden kan worden.<?asciidoc-br?>
Om dit mogelijk te maken wordt gebruik gemaakt van twee interrupt controllers (PIC - Programmable Interrupt Controller ), die elk beschikken over acht interrupt-ingangen. De uitgang van de eerste interrupt controller wordt verbonden met de INT-ingang van de processor, de uitgang van de tweede controller zit op ingang nummer 2 van de eerste controller. Aangezien de controllers intern prioriteit hebben van lage naar hoge cijfers, zijn er dus vijftien mogelijke interruptniveaus.</simpara>
</section>
<section id="_interrupt_transfer">
<title>Interrupt transfer</title>
<simpara>Een interrupt transfer verloopt als volgt:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Als een I/O apparaat data (of een toestand) wil doorgeven aan de CPU, geeft het 	zelf een interruptsignaal.</simpara>
</listitem>
<listitem>
<simpara>Dit interrupsignaal komt toe op de interrupt controller. Als er geen andere interrupts zijn met hogere prioriteit, dan geeft de controller het signaal onmiddellijk door naar de processor. In het andere geval wordt pas na de afhandeling van de hogere prioriteitsinterrupt het interruptsignaal doorgegeven.</simpara>
</listitem>
<listitem>
<simpara>Als de controller het INT signaal geeft aan de processor, zal deze eerst de huidige instructie afwerken en zijn context opslaan (onder andere inhoud instruction pointer en statusregister).</simpara>
</listitem>
<listitem>
<simpara>Nu de processor klaar is voor de verwerking van de interrupt geeft hij een INTA (interrupt acknowledge) signaal door aan de interruptcontroller.</simpara>
</listitem>
<listitem>
<simpara>De controller reageert hierop door over de databus een vectornummer door te geven naar de processor.</simpara>
</listitem>
<listitem>
<simpara>Op basis van het vectornummer kan de processor de juiste interrupthandler starten en de interrupt afwerken</simpara>
</listitem>
<listitem>
<simpara>Zodra de interrupt volledig is afgewerkt, kan de processor zijn werk hervatten op de plaats waar hij onderbroken werd. Hiervoor laadt hij de instruction pointer met het eerder opgeslagen adres van de eerstvolgende af te werken instructie</simpara>
</listitem>
</orderedlist>
<simpara>Deze uiteenzetting zou duidelijk moeten maken dat de reactie van de processor op de gebeurtenis bij de I/O trager is dan bij polling. Eerst moet nog een instructie afgehandeld worden, vervolgens moet de juiste handler geladen worden en vervolgens kunnen pas de nodige acties ondernomen worden. Daar staat tegenover dat de processor alleen maar tijd moet spenderen aan de I/O op het ogenblik dat dit echt nodig is. Hierdoor zal de processor minder tijd spenderen aan de I/O operatie. Het maakt interrupts dan ook uitermate geschikt voor invoerapparaten.</simpara>
</section>
<section id="_interrupts_op_bussystemen">
<title>Interrupts op bussystemen</title>
<simpara>Op de ISA bus (voorganger van PCI) waren interrupts vast gelinkt op een bepaalde IRQ. Dit moest ingesteld worden met jumpers en vroeg enige zorg, want een IRQ kon slechts door één apparaat gebruikt worden.<?asciidoc-br?>
Om het gebruiksgemak te verhogen werd bij de PCI bus gebruikt gemaakt van een buscontroller die de PCI bus afschermt van de processor. <?asciidoc-br?>
Een manier om op PCI een interrupt te genereren is het versturen van een speciaal interrupt bericht naar de bus controller. Dit bericht bevat de nodige informatie over het type en de bron van de interrupt. De bus controller vertaalt dit dan naar een IRQ voor de processor.<?asciidoc-br?>
Op de PCI bus kunnen ook een aantal interruptlijnen beschikbaar zijn, die gedeeld kunnen worden tussen verschillende apparaten. Een interrupt op deze lijnen wordt dan door de controller vertaald naar een signaal dat uiteindelijk doorgegeven wordt aan de processor. Op die manier kunnen apparaten ook hetzelfde IRQ nummer delen.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/interrupt-muis.png" contentwidth="500" width="75%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>IRQ verdeling in apparaatbeheer</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Aangezien de banen van de PCI slots wel vast op een bepaald PCI interruptkanaal zaten, waren (zeker in de begindagen van PCI) nog wel conflicten mogelijk tussen apparaten die toch niet met elkaar overweg konden. In zo’n geval kon het volstaan om een van de uitbreidingskaarten naar een ander slot te verplaatsen om het conflict op te lossen.</simpara>
</section>
</section>
<section id="_direct_memory_access_dma">
<title>Direct Memory Access (DMA)</title>
<simpara>Bij een Direct Memory Acces (DMA) toegang, zal het I/O apparaat rechtstreeks data uitwisselen zonder dat de processor hierbij moet tussenkomen. Hiervoor is er weer behoefte aan een DMA controller. Dit kan een aparte controller zijn, maar de functies kunnen ook geïntegreerd worden in de chipset of in de I/O controller zelf. Om het verloop van een DMA transfer duidelijk te maken, zullen we het lezen van een sector van een harde schijf bekijken als voorbeeld.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>De DMA transfer begint met de processor die de opdracht doorgeeft aan de DMA controller. Hierbij wordt onder meer het aantal bytes en het geheugenadres doorgegeven</simpara>
</listitem>
<listitem>
<simpara>De I/O controller krijgt de nodige instructies, in dit geval dat er gelezen moet worden en op welk adres dit moet gebeuren</simpara>
</listitem>
<listitem>
<simpara>Het I/O apparaat onderneemt de nodige acties (koppen verplaatsen, lezen) om de data beschikbaar te maken in het buffer</simpara>
</listitem>
<listitem>
<simpara>Zodra de data beschikbaar is, geeft de I/O controller een DRQ (DMA-request) signaal door aan de DMA controller.</simpara>
</listitem>
<listitem>
<simpara>De DMA controller probeert nu de controle te krijgen over de bus. Dit gebeurt door een HOLD signaal door te geven aan de processor.</simpara>
</listitem>
<listitem>
<simpara>De processor werkt eventuele lopende transfers op de bus af en geeft de bus dan vrij met een HOLDA signaal.</simpara>
</listitem>
<listitem>
<simpara>De DMA controller heeft nu controle over de databus en kan nu de transfer van schijf naar geheugen sturen. Dit gebeurt door het juiste geheugenadres op de bus te plaatsen en met een DACK-signaal aan de harde schijf aan te geven dat de data op de bus geplaatst mag worden.</simpara>
</listitem>
<listitem>
<simpara>Als de data verplaatst is, worden alle stuursignalen inactief gemaakt en wordt de DMA cyclus beëindigd.</simpara>
</listitem>
</orderedlist>
<figure>
<title>DMA request (bron:http://www.talktoanit.com/)</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/resources-dma.jpg" contentwidth="600" width="80%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>DMA</phrase></textobject>
</mediaobject>
</figure>
<simpara>Het belangrijkste voordeel van dit soort transfer is dat de processor niet betrokken is bij het eigenlijke verplaatsen van de gegevens. In dit voorbeeld moet de CPU enkel de nodige commando’s doorgeven aan de DMA controller. Het voordeel hiervan is uiteraard dat de processor ondertussen kan verder werken en dus niet moet wachten op de trage harde schijf. Bovendien worden de gegevens nu meteen in het geheugen geplaatst, anders zou de processor ze eerst moeten lezen van de schijf en dan naar het geheugen schrijven.Tijdens de eigenlijke overdracht van gegevens is de bus natuurlijk bezet en kan de processor daar geen gebruik van maken. Dit heet cycle stealing. De DMA controller steelt tijd van de processor op de bus. Hoewel de DMA controller toegang tot de bus aanvraagt, zal hij bijna altijd voorrang krijgen op de processor.</simpara>
<simpara>Eens een I/O apparaat zoals een schijf op gang komt, is het belangrijk om de gegevens zo snel mogelijk te kunnen verplaatsen. Meestal zal het ook zo zijn dat de DMA controller meerdere keren de bus moet overnemen om bytes te verplaatsen.<?asciidoc-br?>
Dit hangt natuurlijk ook af van de grootte van buffers en interface-snelheden.
Het opstarten van een DMA transfer kost wel wat extra processorcycli. Alle nodige gegevens doorgeven aan de DMA controller kost nu eenmaal tijd. DMA is dan ook een transfermethode die vooral voordeel biedt als er grote hoeveelheden data verplaatst moeten worden. Dan is slechts een opdracht naar de DMA controller nodig, die vervolgens autonoom de transfer kan regelen.</simpara>
</section>
</section>
<section id="_bussystemen">
<title>Bussystemen</title>
<section id="_in_den_beginne">
<title>In den beginne…</title>
<simpara>In de geschiedenis van de personal computer zijn reeds een heel aantal verschillende bussystemen de revue gepasseerd.<?asciidoc-br?>
De eerste IBM PC gebruikte als bus de zogenaamde PC-bus. In feite was dit in grote lijnen een gebufferde versie van de processor in- en uitgangen.<?asciidoc-br?>
Er waren 62 signaallijnen: 20 adreslijnen, 8 datalijnen, een paar controlelijnen (I/O read/write, memory read/write) en een aantal lijnen ten behoeve van interrupts en DMA transfers. Bij de lancering van de PC/AT met 80286 stond IBM voor een dilemma. Er moest een keuze gemaakt worden voor een bussysteem, dat ofwel toeliet om de kaarten voor de PC-bus te blijven gebruiken ofwel gebruik kon maken van de extra mogelijkheden van de 80286 (24 adreslijnen, 16 datalijnen).<?asciidoc-br?>
De oplossing was het uitbreiden van de slots op de PC bus met een extra connector. Nieuwe kaarten konden gebruik maken van dit extra deel en dus ook van de extra mogelijkheden in het nieuwe systeem.<?asciidoc-br?>
Oudere kaarten konden gewoon verder gebruikt worden langs het PC-bus gedeelte, uiteraard zonder de voordelen van de nieuwe processor. Toen IBM zijn PS/2-serie uitbracht, vonden ze de tijd gekomen om een nieuwe bus te ontwikkelen. Dit was de microchannel bus. Een deel van de reden was dat de PC-bus ondertussen echt wel verouderd was, een ander deel van de reden was dat IBM een obstakel wilde opwerpen voor de kloonbouwers. Microchannel werd dan ook afgeschermd met een muur van patenten met daarachter een legertje advocaten.<?asciidoc-br?></simpara>
<simpara>De reactie van de overige PC-bouwers was de ontwikkeling van een eigen bus, namelijk de ISA-bus (Industry Standard Architecture). Dit was in feite gewoon een AT-bus die op een hogere klokfrequentie werkte. Belangrijk voordeel was dat deze bus compatibel was met de oudere kaarten. Bovendien waren er een groot aantal fabrikanten van uitbreidingskaarten, die vrij van licentiezorgen, kaarten ontwikkeld hadden voor de AT-bus en dit konden blijven doen voor de ISA-bus.<?asciidoc-br?>
Gevolg was dat dit de de facto standaard werd en dat IBM in de vrij absurde situatie terecht kwam, waarin het als enige geen IBM-compatibele PC’s produceerde en het bijna volledig uit de PC-markt verdreven werd. Later werd de ISA-bus nog uitgebreid naar de 32 bit EISA (Extended ISA) versie.<?asciidoc-br?></simpara>
<simpara>Op moderne computersystemen zal je deze bussen niet meer aantreffen.</simpara>
</section>
<section id="_pci">
<title>PCI</title>
<simpara>Uit het voorgaande blijkt al dat de ISA-bus technologisch zeker niet superieur is. De belangrijkste kwaliteit was de backward compatibiliteit met oudere uitbreidingskaarten.<?asciidoc-br?>
Het gebrek aan bandbreedte werd echt een belangrijk tekort als grafische interfaces en toepassingen hun intrede deden.
Een rekenvoorbeeld om dit duidelijk te maken: om full screen bewegende kleurbeelden weer te geven op een computerscherm van 1024*768 pixels zijn dertig beelden per seconde nodig.<?asciidoc-br?></simpara>
<simpara>Als voor de kleurweergave per pixel drie bytes nodig zijn (RGB), dan is een transfersnelheid nodig van</simpara>
<simpara>3 Byte * 1024 * 768 * 30 = 70 MB //_sec</simpara>
<simpara>De EISA bus met 32 bit databus en 8,33MHz kloksnelheid, kon maximaal 33,3MB/s geven. Bovendien moet de bus nog gedeeld worden door andere apparaten, waaronder het geheugen, waarvoor deze snelheid ook onvoldoende zal blijken. De oplossing bestaat erin een nieuw bussysteem te ontwikkelen. Dit zal de PCI-bus (Peripheral Component Interconnect) worden.<?asciidoc-br?>
PCI werd ontwikkeld door Intel, dat verstandig genoeg was om de patenten in het publiek domein te plaatsen, zodat alle fabrikanten randapparatuur konden bouwen, zonder hiervoor rechten te moeten betalen. Intel richtte ook de PCI Special Interest Group op, een industrieconsortium dat dat de toekomst van de PCI-bus moest regelen.
Belangrijke eisen bij de ontwikkeling van PCI zijn onder andere:</simpara>
<itemizedlist>
<listitem>
<simpara>zorgen voor voldoende bandbreedte, ook naar het geheugen</simpara>
</listitem>
<listitem>
<simpara>backward compatibility verzekeren</simpara>
</listitem>
<listitem>
<simpara>kleinere connector dan ISA slots</simpara>
</listitem>
<listitem>
<simpara>ondersteuning voor plug-and-play, power management (laag stroomverbruik)</simpara>
</listitem>
<listitem>
<simpara>hiërarchie van bussen</simpara>
</listitem>
</itemizedlist>
<simpara>De twee eerste eisen zijn uiteraard de belangrijkste.
De eerste ligt voor de hand, de tweede heeft in de PC-geschiedenis zijn belang bewezen. De oplossing voor beide ligt in de ontwikkeling van een I/O systeem, waarin verschillende bussen aanwezig zijn. Er ontstaat op die manier een bushiërarchie van snellere naar tragere bussen, waarbij over de snelle bussen data uitgewisseld kan worden zonder rekening te moeten houden met de tragere onderdelen van het computersysteem (die op een tragere bus aangesloten zijn).</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/busHierarchie.png" contentwidth="400" width="60%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>bussysteem</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Bovenstaande afbeelding geeft de opbouw van het bussysteem bij de ontwikkeling van de PCI-bus. De processor was via de snelle back-side bus verbonden met het cachegeheugen, dat terwijl het nog niet (volledig) in de processor geïntegreerd was. Via de front-side bus was de processor verbonden met de PCI-bridge.</simpara>
<simpara>De PCI bridge kon dan enerzijds verbinding maken met het hoofdgeheugen en anderzijds met de PCI bus. Op de PCI bus kon dan de ISA bridge aangesloten worden, die verbinding kon maken met de IDE kanalen en uiteraard ook met de ISA-bus. De compatibiliteit werd verzekerd door naast PCI slots ook een aantal ISA slots te blijven voorzien. Op de PCI bus kon dan allerhande hardware aangesloten worden, waaronder ook adapters voor andere bussystemen zoals SCSI en USB. De IC’s die de verschillende bussystemen van elkaar scheiden, vormen de chipset. Het is dit onderdeel van het computersysteem dat de ontwikkeling voor Intel zo interessant maakte. Intel wou (en zou) immers de chipsets ontwikkelen en verkopen. De namen voor de verschillende bridge chips verandert in de loop der tijden wel een aantal keer (net zoals de functies die erin geïntegreerd zijn). Gangbare, maar verouderde terminologie hiervoor zijn North en South bridge, waarbij PCI gekoppeld was aan de south-bridge. Nieuwere versies verlaten de ‘north’ en ‘south’ terminologie. De micro-architectuur die momenteel gebruikt wordt, vind je hieronder:</simpara>
<figure>
<title>Oude en nieuwe microarchitectuur</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/oude_en_nieuwe_microarchitectuur_intel.png" contentwidth="600" width="100%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>oude en nieuwe microarchitectuur intel</phrase></textobject>
</mediaobject>
</figure>
<simpara>Het gebruik van de bridges heeft als bijkomend voordeel dat de PCI-bus eigenlijk processoronafhankelijk wordt. Hoe transfers op PCI verlopen is volledig van de processor afgeschermd door de bridge (die uiteraard wel processor-afhankelijk is).
Dit maakt PCI eigenlijk platformonafhankelijk, wat betekent dat het ook met andere processoren gebruikt werd (b.v. ultrasparc).</simpara>
<section id="_transfers">
<title>Transfers</title>
<simpara>PCI is een gedeeld bussysteem. Dit betekent dat de datalijnen gebruikt worden door alle aangesloten apparaten. Dit betekent dus ook dat er enerzijds nood is aan adressering (welk apparaat moet data accepteren) en anderzijds nood aan toegangscontrole (twee apparaten mogen niet tegelijkertijd toegang krijgen tot de bus).<?asciidoc-br?>
Adreslijnen en datalijnen worden op de PCI-bus gemultiplext. Dit zorgt ervoor dat er eerst een adrescyclus nodig is en dat pas daarna de data getransfereerd kan worden. Dit is iets trager, maar bespaart ruimte op de connector. Er zijn verschillende manieren om toegang tot een bus te controleren. Op PCI is het zo dat elk apparaat op elk ogenblik een transfer kan starten. Elk apparaat kan initiator zijn.</simpara>
<simpara>Om conflicten te vermijden is er op de PCI bus ook een arbitrator, deze functie is meestal geïntegreerd in de chipset. Een apparaat dat toegang wil tot de bus zal dit aanvragen bij de arbitrator. Indien meerdere apparaten tegelijk toegang vragen, zal de arbitrator een van de apparaten toegang verlenen via een grant-signaal. De andere moeten wachten. Het apparaat met het grant signaal wordt op dat ogenblik master op de PCI-bus. Het algoritme dat hierbij gebruikt wordt, ligt niet vast in de standaard, maar is bij voorkeur wel rechtvaardig, zodat elk apparaat aan bod komt.</simpara>
<simpara>Eens een apparaat toegang tot de bus krijgt kan het dan een data transfer starten. Deze kan in principe variëren in het aantal bits dat overgebracht wordt, zodat grote blokken getransfereerd kunnen worden en de bus dus lang aan haar maximale datasnelheid kan werken. Om te vermijden dat een apparaat met een lange transfer de bus gaat monopoliseren, moet het voortdurend zijn grant-signaal in de gaten houden. Zodra een ander apparaat toegang tot de bus wil, zal de arbitrator het grant-signaal wegnemen. De data die al op de bus staat, wordt afgeleverd, waarna de bus wordt vrijgegeven. De onderbroken transfer moet uiteraard later afgewerkt worden, daarvoor zal het apparaat weer toegang vragen.</simpara>
</section>
<section id="_snelheid">
<title>Snelheid</title>
<simpara>De originele PCI bus maakte gebruik van een 32 bits databus en 33MHz klokfrequentie. Dit geeft een maximale bandbreedte van 133MB/s. Belangrijke opmerking is dat deze snelheid niet voortdurend gehaald wordt. Op sommige ogenblikken moeten andere gegevens verstuurd worden over de bus(bijvoorbeeld adres). Bovendien moet deze bandbreedte verdeeld worden over alle aangesloten apparaten, zodat de gemiddelde beschikbare snelheid voor een bepaald apparaat lager zal liggen dat de vermelde 133MB/s.</simpara>
<simpara>Er bestaan varianten van PCI die hogere snelheden toelaten. Dit kan ofwel door de breedte van de databus te vergroten tot 64 bit ofwel door de kloksnelheid te verhogen tot 66MHz (in beide gevallen geeft dit een verdubbeling van de snelheid tot 266MB/s) ofwel door een combinatie van beiden (533MB/s). Deze laatste variant heet PCI-X (PCI eXtended) en is nog terug te vinden in oudere servers en workstations. In een gewone desktop PC vind je deze variant niet terug.</simpara>
<simpara>Ter illustratie staan in onderstaande figuur de bekende 32-bit connectoren.</simpara>
<figure>
<title>PCI slots</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/Pci-slots.jpg" contentwidth="350" width="40%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>PCI slots</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_agp_accelerated_graphics_port">
<title>AGP (Accelerated Graphics Port)</title>
<simpara>Uit de eerdere berekening voor de bandbreedte voor het bekijken van videobeelden en de bandbreedte van PCI kan je afleiden dat er al snel problemen ontstonden op het vlak van beschikbare bandbreedte. Een oppervlakkige vergelijking van de cijfers leidt tot de conclusie dat de 133MB/s voldoende is voor de benodigde 70MB/s. Als je de cijfers iets nauwkeuriger gaat bekijken, dan moet je vaststellen dat de 70MB/s echt nodig zijn en de 133MB/s enkel gehaald worden op het ogenblik dat een apparaat echt data verstuurd. Als we rekening houden met andere apparaten die data moeten uitwisselen (bijvoorbeeld de harde schijf of dvd waar de film op staat), dan blijkt al snel dat PCI onvoldoende bandbreedte biedt voor de huidige eisen aan video.
Dezelfde conclusie kan je ook trekken als je rekening houdt met hogere schermresoluties. Om dit probleem aan te pakken, werd het bussysteem uitgebreid met een extra interface (AGP). De functionaliteit voor het besturen van deze interface werd geïntegreerd in de chipset. Deze chipsets werden initieel de north bridge en south bridge genoemd.</simpara>
<simpara>Merk op dat de north en south bridge ondertussen omgedoopt zijn in memory controller hub (MCH) en I/O controller hub (ICH). In de nieuwste processoren is de North Bridge zelfs helemaal opgegaan in de processor.</simpara>
<simpara>De besturing van AGP bevindt zich in de MCH en de besturing van PCI in de ICH. AGP bood in zijn eerste versie (AGP 1x) een databus van 32 bit bij 66MHz, hetgeen een bandbreedte geeft van 266MB/s. Behalve de vergroting van de kloksnelheid heeft AGP nog een bijkomend voordeel dat tot een grotere datasnelheid leidt: de AGP verbinding is een punt-tot-punt verbinding en de beschikbare bandbreedte moet dus niet gedeeld worden en is ogenblikkelijk beschikbaar. Een ander voordeel van AGP is dat het voorziet in mogelijkheden om rechtstreeks uit het geheugen te lezen, door gebruik te maken van een Graphics Addressing Remapping Table.</simpara>
<simpara>Een grafische kaart op PCI moest eerst de data kopiëren naar het framebuffer op de kaart. AGP komt in een aantal varianten. Het voornaamste onderscheid is de snelheid.
Naast AGP 1x, bestaan ook 2x, 4x en 8x. Deze boden respectievelijk 533,1066 en 2133MB/s aan over een databus van 32 bit. Het verschil tussen elk van deze varianten is dat de kloksnelheid volgens het DDR principe wordt vergroot. De basisfrequentie was steeds 66MHz, maar deze werd op 2x verdubbeld naar 133MHz (net zoals bij DDR). Op 4x en 8x wordt ze respectievelijk verviervoudigd (zoals bij DDR2) en verachtvoudigd (zoals bij DDR3).</simpara>
<simpara>Daarnaast is er ook nog variatie in voedingsspanningen (eerst 3.3V, daarna 1.5V en tenslotte 0.8V). Hierbij moest wel opgelet worden met compatibilteit.</simpara>
<simpara>De pro-versies vormen een eerder zeldzame variant, waarbij er extra stroom geleverd kan worden.</simpara>
</section>
<section id="_pci_express">
<title>PCI-express</title>
<simpara>Er komt steeds meer hardware die een te grote bandbreedte vraagt voor PCI. Een voorbeeld zijn gigabit netwerkkaarten die een bandbreedte van 125MB/s vragen, zeer dicht bij de (gedeelde bovengrens van) 133MB/s die PCI kan bieden. Een oplossing zou kunnen zijn om voor die apparaten de functie van de chipset aan te passen en een aparte poort te voorzien (zoals voor AGP). Op deze manier wordt de flexibiliteit wel beperkt en daalt ook de overzichtelijkheid van het systeem. Het zou interessanter zijn om een bus te ontwikkelen die gewoon een hogere bandbreedte haalt en bijvoorbeeld ook voldoende bandbreedte kan bieden om grafische kaarten te ondersteunen. Er zijn een aantal oplossingen ontwikkeld, maar diegene die het uiteindelijk gehaald heeft is PCI-express (PCIe) (ook hier was Intel weer een van de drijvende krachten achter de ontwikkeling).</simpara>
<section id="_architectuur">
<title>Architectuur</title>
<simpara>Het ontwerp van PCIe breekt radicaal met dat van de traditionele bussystemen. In plaats van het traditionele concept van een bussysteem met een brede databus, die gedeeld wordt door meerdere apparaten, gebruikt PCIe een snelle seriële punt-tot-punt verbinding.</simpara>
<simpara>Seriële verbindingen hebben als belangrijk voordeel dat problemen met looptijdverschillen en overspraak vermeden kunnen worden, waardoor een veel hogere kloksnelheid gebruikt kan worden. De topologie lijkt dan ook geweldig op die van switched ethernet.</simpara>
<simpara>Centraal in het concept staat een PCIe switch, die met een aantal gepaarde seriële links verbonden is met de aanwezige hardware.</simpara>
</section>
<section id="_snelheid_2">
<title>Snelheid</title>
<figure>
<title>PCIe slots</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/pcie_slots.jpg" contentwidth="400" width="60%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>PCIe slots</phrase></textobject>
</mediaobject>
</figure>
<simpara>De verbinding tussen de PCIe-switch en de I/O bestaat uit een of meer paren van eenrichtingslinks. Een link bestaat dus uit een upstream en downstream-verbinding. Een dergelijke link noemt men een lane. In het eenvoudigste geval bestaat de verbinding uit een lane, maar het kunnen ook 2, 4, 8, 16 of 32 paren zijn.
Uiteraard nemen uitbreidingsslots met meerdere lanes meer plaats in op het moederbord (zie bovenstaande afbeelding).</simpara>
<simpara>Op elke lane wordt er snelheid gehaald van 2,5Gbps. Deze snelheid zal in de toekomst nog kunnen vergroten (PCIe2.0: 5Gbps, 3.0: 8Gbps, 4.0: 16Gbps). De vermelde snelheid is wel een brutosnelheid, dus zonder rekening te houden met extra informatie die verzonden moet worden. Vergeleken met de maximale transfer rate van PCI is de snelheid op per lane ongeveer 2,3 keer groter.</simpara>
</section>
<section id="_protocol_stack">
<title>Protocol stack</title>
<simpara>Gebruik maken van een snelle synchrone seriële verbinding vraagt wel dat er extra informatie verzonden wordt. Eerst en vooral moet ervoor gezorgd worden dat zender en ontvanger met elkaar gesynchroniseerd geraken. Aangezien er geen extra lijnen voorzien zijn voor een gemeenschappelijk kloksignaal of om te signaleren dat de transmissie start, moet de zender de start van een pakket aangeven en zorgen dat de bitstroom voldoende synchronisatie informatie bevat. Het eerste probleem wordt aangepakt door de te verzenden data in te pakken tussen twee gekende vlaggen, die start en einde van de data aangeven. Om twee partijen met elkaar te synchroniseren, zonder extra kloklijn, moeten er in het verzonden datapatroon regelmatig overgangen voorkomen.<?asciidoc-br?>
De oplossing die op PCIe gebruikt wordt (althans in versie1), is een 8b/10b codering. Dit betekent dat om acht bits te versturen er werkelijk tien verstuurd worden. De vertaling van acht bits naar tien bits is natuurlijk zodanig dat in elk mogelijk verzonden patroon voldoende overgangen zitten. Merk op hoe deze vertaling de brutosnelheid vermindert naar 2Gbps. Een nieuwigheid ten opzichte van PCI is de aanwezigheid van flow control en error control.<?asciidoc-br?>
Flow control moet zorgen dat de zender niet sneller data verstuurt dan de ontvanger ze kan verwerken. Het principe dat wordt toegepast is gelijkaardig aan het sliding window principe dat ook door TCP wordt toegepast: de zender krijgt een bepaald venster en kan binnen dit vensterdata versturen. Bij bevestiging van pakketten verschuift het venster en kan de zender weer pakketten versturen.
Error control wordt verwezenlijkt door een foutdetecterende code (CRC -Cyclic Redundancy Check) toe te voegen aan het pakket. De ontvanger controleert de data op fouten en vraagt in het geval van een fout een hertransmissie aan.
Het voordeel van deze foutcontrole is dat PCIe een stuk betrouwbaarder wordt, maar vooral dat hogere kloksnelheden mogelijk worden. Bij hogere kloksnelheden wordt de kans op bitfouten groter, maar door de aanwezigheid van foutcontrole is dit niet noodzakelijk een drama (te veel bitfouten gaan natuurlijk de netto snelheid nog meer laten afnemen).</simpara>
<figure>
<title>PCIe protocolstack</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/pcie_protocolstack.png" contentwidth="700" width="80%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>protocol stack PCIe</phrase></textobject>
</mediaobject>
</figure>
<simpara>Omdat er op de seriële verbinding geen plaats is voor controlelijnen, moet alle controle-informatie verzonden worden in een header. Deze laat onder andere toe om het soort transfer aan te geven (bijvoorbeeld gewone I/O, configuratie bericht voor PnP, interrupt, &#8230;&#8203;).</simpara>
</section>
<section id="_vergelijking_met_pci">
<title>Vergelijking met PCI</title>
<simpara>Ten opzichte van PCI zijn er een aantal fundamentele veranderingen, waarbij de overgang naar seriële transmissie waarschijnlijk de grootste is.</simpara>
<simpara>Deze verandering, gecombineerd met hogere kloksnelheden en de foutcorrectie laat veel grotere datasnelheden toe. Bovendien moet de beschikbare bandbreedte op de punt-tot-punt verbinding niet gedeeld worden. Het is wel mogelijk om een PCIe apparaat zelf te gebruiken als switch en op die manier grotere netwerken te bouwen. In dat geval wordt een deel van het pad richting centrale switch en dus ook de bandbreedte gedeeld.
De seriële verbinding met zijn zeer beperkt aantal geleiders laat ook veel kleinere connectoren toe, wat het geschikter maakt voor bijvoorbeeld laptops. Ook andere ontwerpen van computerbehuizing (bijvoorbeeld Apple-gewijs alles in het scherm steken) worden eenvoudiger. Een minder voor de hand liggend voordeel van de minder storingsgevoelige seriële verbinding is dat de afstand tussen communicerende apparaten groter kan worden.</simpara>
<simpara>Uit al deze verschillen zou duidelijk moeten blijken dat PCI Express bijzonder weinig te maken heeft met PCI. Behalve de naam (die om marketingredenen begint met PCI) hebben ze enkel gemeen dat dezelfde commando’s ondersteund worden.In tegenstelling tot wat de naam probeert te suggereren, zijn PCI en PCI express absoluut niet compatibel. Om te zorgen voor backwards compatibility worden op de moederborden (zeker de eerste jaren) nog een aantal PCI-slots voorzien. De PCI controller functionaliteit is natuurlijk terug te vinden in de ICH.</simpara>
</section>
</section>
</section>
<section id="_bussystemen_voor_harde_schijven">
<title>Bussystemen voor harde schijven</title>
<section id="_in_den_beginne_2">
<title>In den beginne…</title>
<simpara>De IDE, ATA en ATAPI benamingen worden zeer vlot door elkaar gebruikt om bussystemen voor harde schijven (origineel) en optische stations aan te duiden.+
Op de eerste IBM PC was er optioneel een harde schijf van 10MB. De schijfcontroller zat op het moederbord en er liepen analoge signalen naar de schijf om de motoren te sturen. Naarmate de technologie zich verder ontwikkelde, werd de controller geïntegreerd op de schijf en ontstond een IDE-schijf (Integrated Drive Electronics).
Een IDE interface had een 16-bit databus en voorzag origineel in de 20 bit CHS adressering. Transfers gebeurden volgens het polling principe (programmed I/O) en haalden snelheden van 3.3, 5.2 of 8.3 MB/s naargelang de gebruikte kloksnelheid.
Na IDE kwam er EIDE (Extended IDE) dat voorzag in LBA met 28 bit en dus grotere schijven kon aanspreken. Een andere belangrijke verbetering was een verhoging van de datasnelheid waardoor maximaal 16.6MB/s gehaald kon worden. Bovendien deed een nieuwe transfertechniek zijn intrede: multiword DMA.</simpara>
<simpara>Andere verbetering was dat een EIDE controller meerdere apparaten kon aansturen. Ze konden twee kanalen aan en op elk kanaal twee apparaten. Het ene apparaat werd master genoemd, het ander slave. Master en slave-instellingen moesten via jumpers op de schijf gedaan worden. Nadien kon de keuze ook gebeuren met de kabel (cable select). Het is een gangbaar misverstand om te denken dat de master ook effectief de transacties controleert en dus de slave aanstuurt. Het is steeds de EIDE-controller die de bus bestuurt.</simpara>
<simpara>Master en slave zijn eerder een soort van adressen (in moderne versies van de standaard spreekt men ook van device 0 en device 1 ).
Naarmate EIDE verder ontwikkelt werd en de controller aangesloten werd op de AT bus, duikt plotseling de naam ATA-3 op (AT attachment). De vorige twee standaarden krijgen als extra naam ATA-1 en ATA-2.<?asciidoc-br?>
ATA-3 voegt weinig extra toe, belangrijkste bijdrage is S.M.A.R.T.
De opvolger van ATA-3 zou logischerwijs ATA-4 zijn, maar plotseling spreekt men nu van ATA Packet Interface en dus ATAPI-4.<?asciidoc-br?>
Belangrijke aanpassingen zijn de ondersteuning voor optische stations en de hogere transfersnelheden(tot 33MB/s).<?asciidoc-br?>
Er wordt ook een nieuwe transfertechniek geïntroduceerd: ultra-DMA. Hierbij werden transfers op beide klokflanken mogelijk en werd CRC gebruikt om fouten op te sporen.ATAPI-5 ging tot 66MB/s en introduceerde hiervoor een kabel met 80 geleiders. ATA/ATAPI-6 verhoogde de snelheid tot 100MB/s en introduceerde 48 bit LBA adressering.
ATA/ATAPI-7 introduceerde enerzijds UDMA/133 (133MB/s) en anderzijds SATA.</simpara>
<simpara>Er zijn (waren?) twee soorten ATA-kabels.  Het aantal aansluitingen op de connectors is echter niet gewijzigd, de extra geleiders worden allemaal verbonden met de aarding. Ze komen tussen de signaalgeleiders te liggen, zodanig dat er steeds afwisselend een signaal geleider en een geaarde draad ligt. Op die manier wordt de capacitieve koppeling en de daarmee gepaard gaande overspraak tussen twee signaaldraden verminderd. Dit laat hogere datasnelheden toe. Voor transfers vanaf 66MB/s moet verplicht een 80-polige kabel gebruikt worden.</simpara>
<simpara>PATA kan ondertussen gecatalogeerd worden als geschiedenis.</simpara>
</section>
<section id="_sata">
<title>SATA</title>
<simpara>Het verhaal van de overgang van ATA (dat ondertussen ook PATA genoemd wordt) naar SATA is heel gelijkaardig aan het verhaal van PCI naar PCI-express. Ook in dit geval wordt er overgegaan van een parallelle interface naar een veel sneller geklokte seriële interface, die hogere datasnelheden toelaat.</simpara>
<figure>
<title>sata connector</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/satamobo.jpg" contentwidth="300" width="40%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>sata connector</phrase></textobject>
</mediaobject>
</figure>
<section id="_compatibiliteit_sata_vs_pata">
<title>Compatibiliteit sata vs pata</title>
<simpara>Zoals steeds in de PC wereld moet er opgelet worden voor backward compatibility. Uit het voorgaande zal wel duidelijk gebleken zijn dat PATA en SATA niet compatibel zijn met elkaar. Om die reden worden (voorlopig) nog extra PATA connectoren voorzien.
PATA en SATA zijn wel software compatibel, in die zin dat de commando’s die op PATA gebruikt worden ook begrepen worden op SATA. Dit maakte de stap naar SATA hardware eenvoudiger.</simpara>
</section>
<section id="_signalering_en_bandbreedte">
<title>Signalering en bandbreedte</title>
<simpara>De dataverbinding tussen schijf en moederbord bestaat uit zeven geleiders. Drie daarvan zijn ground, de andere vier vormen twee paren voor dataverkeer. Met deze kleine connector gaat uiteraard ook een veel kleinere kabel gepaard, wat de luchtstroming in de computerkast ten goede komt.</simpara>
<simpara>Door de overgang van parallel naar serieel zijn hogere kloksnelheden mogelijk om de eerder vermelde redenen. Bovendien werkt SATA differentieel, dit wil zeggen dat de data verzonden wordt over paren. De geleiders van deze paren liggen dicht bij elkaar, zodat ze ongeveer op dezelfde manier gestoord worden. Aangezien het verschil tussen de geleiders de data bepaalt, is het mogelijk om een groot deel van deze storingen weg te werken. De hogere kloksnelheid bedroeg in de eerste versie van SATA 1500MHz. Hierdoor was een bitrate mogelijk van 1500Mbps. Ook hier wordt omwille van de synchronisatie een 8b/10b codering gebruikt, zodat de werkelijke bandbreedte 120MB/s wordt. Dit is eigenlijk lager dan de maximale 133MB/s, maar hoger dan de maximale transfer rates van schijven.</simpara>
<example>
<title>oefening</title>
<simpara>Serial ATA 3 haalt een bitrate van 6Gbps, en toch maar een nuttige bandbreedte van 600MB/s. hoe verklaar je dat?</simpara>
</example>
<important>
<simpara>In tegenstelling tot PATA heeft SATA een verbinding in elke richting, zodat in principe full duplex mogelijk wordt (het is echter niet zo voor de hand liggend om tegelijk de schijf te schrijven en te lezen). Anderzijds beschikt SATA niet over controlelijnen om de commando’s door te sturen.
Deze moeten ook over de dataverbinding verzonden worden (wat de netto bandbreedte nog iets meer zal doen dalen), maar hier kan eventueel wel gebruik gemaakt worden van de full duplex eigenschap.</simpara>
</important>
<figure>
<title>sata multiplier</title>
<mediaobject>
<imageobject>
<imagedata fileref="ch06/images/satamultiplier.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>SATA multiplier</phrase></textobject>
</mediaobject>
</figure>
<simpara>In principe is SATA een punt-tot-punt verbinding tussen de SATA controller en de schijf. Het is echter ook mogelijk om met behulp van een expansor of multiplier meerdere SATA apparaten aan te sluiten op een connector van de controller (afbeelding 63). Dit betekent dus ook dat (tenzij met expansor) de bandbreedte niet gedeeld moet worden over verschillende apparaten. Voor de signalering op de dataparen gebruikt SATA LVDS (Low Voltage Differential Signaling). In plaats van de op PATA gangbare 5V, wordt een spanningszwaai van 0.5V gebruikt. Belangrijk voordeel hiervan is een veel lager stroomverbruik. Dit wordt zoals altijd op de mobiele markt gewaardeerd, maar ook aan het andere uiterste, in bijvoorbeeld data centers, waar deze besparing bij een grote hoeveelheid schijven een groot verschil maakt.</simpara>
<simpara>Een ander voordeel van SATA is dat het hot-pluggable is. Dit betekent dat de schijf vervangen kan worden terwijl het computersysteem in werking is. Dit kan bijzonder bruikbaar zijn in RAID configuraties.</simpara>
</section>
<section id="_ncq">
<title>NCQ</title>
<simpara>SATA ondersteunt ook Native Command Queueing (NCQ). Als een schijf verschillend lees- of schrijfcommando’s toegestuurd krijgt, zullen die meestal doorgaan op verschillende locaties op de schijf. NCQ kan rekening houden met de locatie van de gegevens op de schijf om de gegevens zo snel mogelijk beschikbaar te maken. NCQ vraagt natuurlijk wel enige tijd om te bekijken in welke volgorde de commando’s best verwerkt kunnen worden en er moeten natuurlijk ook meerdere commando’s beschikbaar zijn. NCQ is dan ook vooral handig bij zwaarder belaste schijven (bijvoorbeeld file server).</simpara>
</section>
</section>
<section id="_esata">
<title>eSATA</title>
<simpara>External SATA is een SATA-variant die de aansluiting van externe schijven mogelijk moet maken. Er zijn kleine verschillen met SATA, onder andere op het vlak van de signalering, zodat langere kabels gebruikt kunnen worden.<?asciidoc-br?>
eSATA treedt op het vlak van de externe opslag in concurrentie met USB, en zou dus eigenlijk even goed in het volgende hoofdstuk thuis horen, met de interfacebussen.
Ten opzichte van deze laatste twee heeft eSATA als voordeel dat het hogere bitsnelheden kan halen. Het belangrijkste nadeel is dat de andere twee veel beter ingeburgerd zijn. Een van de voordelen (of beter doelstellingen bij het ontwerp) van USB was het uniformiseren van de aansluitingen op een computer: een connector voor allerlei soorten apparaten. Ondertussen is de specificatie van USB 3 volledig af en wijd verspreid, wat het voor eSATA waarschijnlijk nog moeilijker zal maken om aan populariteit te winnen&#8230;&#8203;</simpara>
</section>
<section id="_serial_attached_scsi_sas">
<title>Serial Attached SCSI (SAS)</title>
<simpara>Ondertussen zal wel duidelijk zijn dat naarmate de datasnelheid echt groot moet zijn, seriële transfers de voorkeur krijgen op parallelle (toch als een zekere afstand overbrugd moet worden). Dit komt ook naar voor als je de geschiedenis van SAS bekijkt: deze komt voort uit de SCSI standaard, die parallelle communicatie gebruikte.</simpara>
<simpara>Vanzelfsprekend is er dus ook een seriële SCSI variant opgedoken, met name SAS (Serial Attached SCSI). SAS lijkt heel hard op SATA. Het is eveneens een seriële punt-tot-punt verbinding die gelijkaardige snelheden haalt. Het belangrijkste verschil is dat het zich net als het verouderde SCSI meer richt op de servermarkt, waarvoor het een iets grotere betrouwbaarheid biedt. Deze betrouwbaarheid uit zich vooral in een aantal foutcorrectie- en rapporteringmechanismen die in de loop der tijden binnen SCSI ontwikkeld zijn. Deze gaan een stuk verder dan wat met S.M.A.R.T. mogelijk is op ATA (en dus ook SATA).<?asciidoc-br?>
Daar staat dan weer tegenover dat SAS iets duurder is dan SATA.</simpara>
</section>
</section>
</chapter>
<chapter id="_externe_i_o">
<title>Externe I/O</title>
<simpara>In dit hoofdstuk komen een aantal veel voorkomende interfaces voor randapparatuur voor. Een aantal hiervan worden uitgebreider besproken in de cursus “interfacing &amp; microcontrollers”.</simpara>
<section id="_in_den_beginne_3">
<title>In den beginne</title>
<simpara>Dit hoofdstuk heeft niet de pretentie om alle mogelijke interfacebussen op te lijsten. Een aantal van die bussen worden niet meer gebruikt of raken stilaan in onbruik.
De klassieke printerpoort of Centronics poort is er zo eentje. Deze parallelle poort zoals ze ook genoemd werd, is primair ontworpen voor het aansturen van printers. Getuige daarvan zijn de specifieke controlelijnen om aan te geven als bijvoorbeeld het papier uitgeput is. Deze poort werd later ook nog veelvuldig gebruikt, omdat ze erg eenvoudig is van opbouw, en daardoor makkelijk te gebruiken voor kleinere elektronicaprojectjes. Tegenwoordig is deze poort slechts zelden nog te vinden op een pc.<?asciidoc-br?>
Ook de seriële poort is stilaan in z’n bestaan bedreigd. Enkel voor heel specifieke toepassingen (vb configuratie van apparatuur als routers) wordt ze nog gebruikt, maar ook daar moet ze stilaan plaats ruimen voor USB.</simpara>
<simpara>De COM poort (zoals de seriële poort ook genoemd werd) laat asynchrone seriële communicatie toe. Dit betekent relatief lage bitsnelheden (minimum 50bps, standaard 9600bps, maximum115kbps).
Deze vorm van communicatie wordt gebruikt voor tragere I/O, zoals barcodescanners, modems, &#8230;&#8203;<?asciidoc-br?>
Omwille van de eenvoud en de ondersteuning op tal van microcontrollers wordt ze dikwijls gebruikt bij embedded systemen.<?asciidoc-br?></simpara>
<simpara>Firewire is een andere I/O mogelijkheid die vooral door Apple gepromoot werd, maar die stilaan in onbruik geraakt is.</simpara>
</section>
<section id="_ps_2">
<title>PS/2</title>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/ps2port.jpg" align="center"/>
</imageobject>
<textobject><phrase>ps/2 connector</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>De PS/2 interface duikt in de PC wereld op met de introductie van de IBM PS/2 (Personal System 2), ondertussen enkele decennia geleden. Het is een interface die dient voor het aansluiten van toetsenborden en muizen. Er bestaan twee connectoren die identiek zijn, op hun kleur na. De paarse connector dient voor een toetsenbord, de groene voor een muis. Aangezien beiden gebruik maken van een ander protocol is het aangewezen om de kleurcode te respecteren. Met name het BIOS kan problemen maken van een toetsenbord dat op de verkeerde poort is aangesloten, zodat bij het opstarten geen opdrachten doorgegeven kunnen worden via het toetsenbord. Een tweede mogelijk verrassend feit, is dat PS/2 niet hot pluggable is.<?asciidoc-br?>
Dit komt door het elektronisch ontwerp. De pinnen van de connector zijn rechtstreeks verbonden met de pinnen van de microcontroller die beschadigd kan worden door hot swapping. Anderzijds is er ook geen ondersteuning voor het herkennen van een nieuw aangesloten apparaat. In moderne interfaces worden de contacten naar de microcontroller robuuster uitgevoerd, zodat er minder kans op beschadiging is. Bij het gebruik van standaardapparaten is de herkenning van het nieuw aangesloten apparaat ook geen probleem, zodat hot swapping soms wel succesvol kan aflopen, maar absoluut niet aan te raden is.<?asciidoc-br?></simpara>
<simpara>PS/2 is ondertussen technologisch al lang achterhaald, maar blijft desondanks (backward compatibility) toch aanwezig aan de achterkant van vele PC’s en servers. De opvolger van PS/2 is USB, dat tevens een aantal andere interfaces moet vervangen, met als belangrijke pluspunt een uniforme aansluiting voor alle soorten apparaten.</simpara>
</section>
<section id="_usb">
<title>USB</title>
<section id="_overzicht_3">
<title>Overzicht</title>
<simpara>Om een oplossing te vinden voor de problemen bij het gebruik en vooral de configuratie van de klassieke (legacy) I/O-interfaces zoals de Centronics Interface en RS232, werd onder andere onder impuls van Intel een werkgroep opgericht met als doel het ontwikkelen van een nieuwe interface standaard. Dit werd de Universal Serial Bus (USB). USB is een snelle en flexibele interface om randapparatuur te verbinden met een computer. Ze is ontworpen met als doel het gebruiksgemak en betrouwbaarheid te verhogen.</simpara>
<simpara>Doelstellingen:</simpara>
<itemizedlist>
<listitem>
<simpara>eenvoudige en betrouwbare aansluiting geschikt voor alle soorten randapparatuur</simpara>
</listitem>
<listitem>
<simpara>immuun voor problemen met systeemresources als interrupt- of DMA-conflict</simpara>
</listitem>
<listitem>
<simpara>automatische detectie en configuratie van aangesloten apparaten</simpara>
</listitem>
<listitem>
<simpara>goedkoop te realiseren</simpara>
</listitem>
<listitem>
<simpara>laag stroomverbruik</simpara>
</listitem>
<listitem>
<simpara>hot-pluggable</simpara>
</listitem>
</itemizedlist>
<simpara>In de originele specificatie (USB 1.1) is er sprake van twee mogelijke transmissiesnelheden:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Low Speed</emphasis>: 1,5 Mbps, bedoeld voor I/O met een beperkt datadebiet: muis, toetsenbord, joystick, &#8230;&#8203;</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Full Speed</emphasis>: 12 Mbps, bedoeld voor hogere debieten: audio, printers, scanners, processorcommunicatie&#8230;&#8203;
In een latere revisie (USB 2.0) is er een derde mogelijkheid bijgekomen:</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">High Speed</emphasis>: 480 Mbps, bedoeld voor video, externe harde schijven, DVD of CD-romspelers, &#8230;&#8203;
De nieuwste revisie (USB 3.0) krikt de snelheid verder op:</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Superspeed</emphasis>: 4,8 Gbps, bedoeld om extra hoge snelheden te halen, zoals voor SSD. 	De nieuwe mogelijkheden van deze versie van de standaard komen op het eind van 		dit hoofdstuk aan bod.
De USB-bus is gebaseerd op het master/slave principe: de host (de computer) is verantwoordelijk voor het beheer en de coördinatie van de activiteit op de bus. Er kan dus enkel communicatie gebeuren op initiatief van de host. Deze bevat hiervoor een zogenaamde USB Host-controller.</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_mechanische_en_elektrische_opbouw">
<title>Mechanische en elektrische opbouw</title>
<simpara>De USB-bus werkt met relatief korte kabels (maximum 5 m.) voor punt tot punt verbindingen: er wordt telkens een apparaat verbonden met een poort van een USB-hub. Ook de aansluitingen op een computer maken deel uit van één of (soms) meerdere hubs. Een USB2-kabel bevat vier geleiders:</simpara>
<itemizedlist>
<listitem>
<simpara>Rood: +5V</simpara>
</listitem>
<listitem>
<simpara>Zwart: Gnd</simpara>
</listitem>
<listitem>
<simpara>Wit: Data</simpara>
</listitem>
<listitem>
<simpara>Groen: Data+</simpara>
</listitem>
</itemizedlist>
<simpara>In het geval van Full- of High Speed USB heeft het datapaar een afzonderlijke afscherming. Om grotere afstanden te overbruggen of meer apparaten aan te sluiten kan de installatie uitgebreid worden door gebruik te maken van externe USB-Hubs. In totaal mogen er maximaal 4 externe hubs achter elkaar geschakeld worden (geeft een maximum afstand van 30 m) en mogen er maximaal 127 apparaten aangesloten worden op een USB-bus. Er zijn twee types connectoren. Type A wordt gebruikt voor de aansluiting aan de hub (of op de computer). Type B wordt gebruikt voor de aansluiting.<?asciidoc-br?>
Er bestaan ook mini en micro varianten van de connectoren. Volgende figuur toont een aantal voorbeelden.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/2000px-Types-usb_th1.svg.png" contentwidth="500" align="center"/>
</imageobject>
<textobject><phrase>USB connectoren (bron: wikipedia)</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Als een randapparaat geen al te groot stroomverbruik heeft, kan het gevoed worden vanuit de USB-kabel: stromen tot 500 mA zijn toegestaan bij een spanning van 5V (vanwege spanningsverlies over de kabel kan deze spanning zakken tot minimaal 4 V bij het randapparaat). Voor grotere vermogens moet het randapparaat een eigen voeding voorzien.</simpara>
<simpara>De USB-bus verstuurt de data serieel met NRZI-codering (Non Return on Zero Inverted) via een differentieel signaal (D+, D-). Een overgang in het datasignaal stelt een 0 voor, terwijl een ongewijzigd signaal een 1 voorstelt.<?asciidoc-br?>
Opdat de ontvanger synchroon zou blijven lopen met de zender (er is geen afzonderlijk kloksignaal), is het nodig dat er regelmatig een overgang in het signaal optreedt. In het geval dat er meer dan 6 opeenvolgende bits op 1 staan, wordt na het 6e bit automatisch een 0 ingevoegd (bit-stuffing) door de zender. Dat extra 0-bit moet door de ontvanger uiteraard weer verwijderd worden. Op deze manier wordt een betrouwbare gegevensoverdracht verzorgd, die nog aangevuld wordt met een CRC-foutcontrole per pakket.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/nrzi.png" contentwidth="500" width="70%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>voorbeeld NRZI-codering met bitstuffing</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>De communicatie in de twee richtingen (host&lt;&#8594;device) gebeurt over hetzelfde draadpaar. Dit is dus vergelijkbaar met half-duplex.</simpara>
</section>
<section id="_communicatie_over_usb">
<title>Communicatie over USB</title>
<simpara>Zoals de naam al aangeeft, wordt het medium bij de Universal Serial Bus gedeeld over alle aangesloten apparaten (shared bandwidth). Daarnaast wordt er gebruik gemaakt van het master/slave principe zodat de host-controller(de master) de volledige controle heeft over de communicatie via de USB-bus.</simpara>
<section id="_frames_pakketten">
<title>Frames, pakketten</title>
<simpara>De host verdeelt de tijd in frames met een vaste lengte (1 msec voor Low- en Full-speed, 125 µsec voor High-speed). Elk frame wordt op zijn beurt opgedeeld in een aantal pakketten (lengte kan variëren) waarvan het eerste een SOF (Start-Of-Frame) pakket is, bedoeld voor frame synchronisatie tussen de verschillende apparaten. Elk pakket is gekoppeld aan een apparaat en daarbinnen aan een endpoint (vergelijkbaar met een TCP-poortnummer).</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/USB_frames.png" contentwidth="500" align="center"/>
</imageobject>
<textobject><phrase>USB frames (bron onbekend)</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Binnen een pakket vind je enkele belangrijke velden:</simpara>
<variablelist>
<varlistentry>
<term>De Sync-vlag (00000001)</term>
<listitem>
<simpara>is bedoeld voor bit- en byte-synchronisatie.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>De Packet-ID (of PID)</term>
<listitem>
<simpara>geeft het type van het pakket weer (Token, Data, Handshake, Special, &#8230;&#8203;).</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Het Data-veld</term>
<listitem>
<simpara>bevat naast eventuele gegevens ook het adres van het apparaat waaraan het pakket gekoppeld is en het endpoint.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Gedurende het EOP-gedeelte worden de twee datalijnen beide laag gehouden gedurende een bittijd. Hierdoor detecteren alle aangesloten apparaten het einde van het pakket.
Een volledige transfer tussen de host en een apparaat zal opgebouwd worden door verschillende pakketten die eventueel in verschillende frames kunnen zitten.</simpara>
<simpara>Er onderscheiden zich vier types van pakketten.</simpara>
<itemizedlist>
<listitem>
<simpara>Start-of-frame: geeft het begin aan van een nieuw frame inclusief een 11 bit frame nummer.</simpara>
</listitem>
<listitem>
<simpara>Token: het token geeft de richting aan van de pakketten.</simpara>
<itemizedlist>
<listitem>
<simpara>IN:: informeert het toestel dat de host iets wil ontvangen</simpara>
</listitem>
<listitem>
<simpara>OUT:: informeert het toestel dat de host iets wil versturen</simpara>
</listitem>
<listitem>
<simpara>SETUP:: wordt gebruikt om een transfer te starten.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Handshake</simpara>
<itemizedlist>
<listitem>
<simpara>ACK:: geeft een bevestiging dat de info correct werd ontvangen</simpara>
</listitem>
<listitem>
<simpara>NAK:: geeft aan dat het toestel eventjes geen data kan zenden of ontvangen, of dat er geen data beschikbaar is op dit moment.</simpara>
</listitem>
<listitem>
<simpara>STALL:: het toestel bevindt zich in een staat waarin de host actie moet ondernemen.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Data: bevat maximum 1024 bytes aan data. Er zijn ook verschillende subtypes:</simpara>
<itemizedlist>
<listitem>
<simpara>Data0</simpara>
</listitem>
<listitem>
<simpara>Data1</simpara>
</listitem>
<listitem>
<simpara>Data2 (enkel bij high-speed)</simpara>
</listitem>
<listitem>
<simpara>MDATA (enkel bij high-speed)</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>Aanvullende uitleg en verdere verduidelijking vind je op <ulink url="http://www.beyondlogic.org/usbnutshell/usb3.shtml#USBPacketTypes">http://www.beyondlogic.org/usbnutshell/usb3.shtml#USBPacketTypes</ulink></simpara>
</section>
</section>
<section id="_endpoints">
<title>Endpoints</title>
<simpara>Voor de communicatie met de host, beschikt elk USB-device over een aantal endpoints (maximaal 16): dit zijn meestal kleine databuffers in het geheugen van de microcontroller van het randapparaat. Die buffers worden gebruikt om de informatie uit een pakket op te slaan.<?asciidoc-br?>
Om gegevens uit te wisselen tussen de host en een USB-apparaat wordt een verbinding opgezet (pipe genaamd) tussen een endpoint en de host. De richting wordt gespecificeerd vanuit het standpunt van de host: Een IN-endpoint stuurt data van het apparaat naar de computer. Bij een OUT-endpoint ontvangt het apparaat data van de computer.<?asciidoc-br?>
Een uitzondering op die regel: endpoint 0 is bedoeld voor controle van de verbinding en laat communicatie in de twee richtingen toe (is eigenlijk een combinatie van een IN- en een OUT-endpoint, beide met hetzelfde nummer).</simpara>
<simpara>images:endpoint.gif[align="center", scaledwitdth="40", alt="USB endpoints (bron: beyondlogic.org",width="500"]</simpara>
</section>
<section id="_types_van_transfers">
<title>Types van transfers</title>
<simpara>USB is ontworpen om verschillende soorten apparaten te bedienen, elk met zijn eigen specificaties (gegevensdebiet, reactietijd, foutcorrectie,&#8230;&#8203;). Om aan alle mogelijke situaties tegemoet te komen zijn er vier soorten transfers voorzien:</simpara>
<variablelist>
<varlistentry>
<term>CONTROL transfers</term>
<listitem>
<simpara>worden gebruikt voor het beheer van de USB. Via control transfers over de control-pipe (naar endpoint 0) leest de host informatie over een apparaat en ontvangt het apparaat configuratie-informatie (zoals een device-adres). Elk USB-apparaat moet controltransfers ondersteunen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>BULK transfers</term>
<listitem>
<simpara>zijn bedoeld voor situaties waar veel gegevens moeten doorgestuurd worden, maar waarbij de snelheid niet kritisch is: disk, printers, scanners,&#8230;&#8203; Als de USB bezet is met verkeer dat een gegarandeerde bandbreedte vereist (isochrone transfers), dan zal een bulktransfer moeten wachten. Wanneer er daarbuiten weinig verkeer is, zal een bulk-transfer zeer snel verlopen.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>INTERRUPT transfers</term>
<listitem>
<simpara>worden gebruikt wanneer een apparaat op regelmatige tijdstippen de gelegenheid moet krijgen om gegevens te verzenden of ontvangen. Voorbeelden hiervan zijn een toetsenbord, een joystick, een muis: hierbij wordt een limiet vereist op de reactietijd van de computer. In tegenstelling tot wat je uit de naam zou verwachten, is een interrupttransfer gebaseerd op regelmatige polling door de host-controller. Vermits USB een puur master/slave systeem is, zijn er geen interrupt-mogelijkheden voor de USB-apparaten.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>ISOCHRONE transfers</term>
<listitem>
<simpara>garanderen een gevraagde bandbreedte, maar voorzien geen foutcorrectie. Wanneer geluid of video over USB wordt doorgestuurd, zal men gebruik maken van isochrone transfers. Hierbij zorgt de host-controller ervoor dat alle toegestane transfers goed verlopen. Wanneer software een aanvraag doet om bijvoorbeeld een isochrone transfer op te zetten met een bepaald apparaat, wordt eerst nagegaan of er nog voldoende bandbreedte over is op de bus (of er in elk frame nog voldoende plaats vrij is). Voldoende plaats betekent dat steeds voldoende ruimte moet overblijven voor noodzakelijke controle transfers.
In een frame komen eerst de isochrone transfers aan bod. Vervolgens worden de interrupt apparaten gepold (en wordt eventueel de nodige interrupt data getransfereerd). Op deze manier komen alle apparaten die een bepaalde bandbreedte of een bepaalde korte reactietijd nodig hebben steeds aan bod. Wat overblijft van de tijd in een frame, kan ingenomen worden door bulktransfers. Dit is minimaal de nog niet toegekende tijd, maar kan ook niet gebruikte tijd voor controle of interrupt transfers zijn.</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="_verloop_van_een_transfer">
<title>Verloop van een transfer.</title>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/transint.png" contentwidth="400" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>voorbeeld van een interrupt transfer (bron: beyondlogic.org)</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>De transfer begint met de host controller die aangeeft in welke richting de data zal gaan: in-token voor data van apparaat naar host controller, out-token voor de omgekeerde inrichting. Vervolgens wordt de data verzonden (afhankelijk van de richting gebeurt dit door het apparaat of de host controller). In het geval van een transfer richting host controller, kan het apparaat ook reageren met een NAK. Dit betekent dat er geen data te versturen is. Geen reactie op het token bericht betekent dat dit token een fout bevatte. Na de data volgt nog een bevestiging, die aangeeft dat de data correct ontvangen is. In het geval van een transfer richting apparaat kan dit ook bevestigen met een NAK. Dit betekent dat het apparaat de inkomende data op dat ogenblik niet kan verwerken. Andere transfers verlopen op gelijkaardige manier.<?asciidoc-br?>
Bij isochrone transfers zullen er geen bevestigingen zijn, terwijl na een controle transfer nog een extra statusfase zal volgen waarbij de verwerking van een commando wordt bevestigd.</simpara>
</section>
</section>
<section id="_enumeratie_en_p_p">
<title>Enumeratie en P&amp;P</title>
<simpara>Zoals bij de inleiding al vermeld, is USB ontworpen met het oog op een volledige integratie met het Plug&amp;Play gebeuren. De bedoeling is dan ook dat een gebruiker een USB-apparaat aansluit, dat het automatisch herkend wordt door het besturingssysteem, dat de juiste drivers geladen worden waarna het apparaat gebruikt kan worden, zonder dat die gebruiker iets moet configureren. Om dit mogelijk te maken zijn er wel een aantal stappen nodig: detectie van nieuwe apparatuur en snelheid daarvan.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/USBpullup.png" contentwidth="800" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>pull-up weerstand voor detectie nieuw apparaat</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Langs de kant van de host (of hub) zijn de twee datalijnen via 2 pull-down weerstanden (15 k) verbonden met de massa. Daardoor ziet de host een laag niveau op beide datalijnen (D+ en D-).<?asciidoc-br?>
Een Low-speed device heeft van zijn kant een pull-up weerstand van 1,5k tussen de voedingsspanning en D- (bij de full- en high-speed apparaten is dat naar de D+ lijn).<?asciidoc-br?>
Wanneer een apparaat aangesloten wordt, zal langs de kant van de host (hub)een van beide D-lijnen naar een hoog niveau getrokken worden. Hierdoor detecteert deze dat er een nieuw apparaat op de bus aanwezig is en ook of dit al dan niet een low-speed device is. Elke hub heeft een interrupt IN-pipe waardoor de nieuwe aansluiting doorgegeven wordt naar de host.</simpara>
<section id="_enumeratie">
<title>Enumeratie</title>
<simpara>Bij het opstarten van de computer en telkens er een nieuw apparaat gedetecteerd wordt, zal er een procedure doorlopen worden: de zogenaamde enumeratie. Hierbij is het de bedoeling dat het apparaat een uniek adres toegewezen krijgt, dat het besturingssysteem informatie opvraagt over het apparaat en dat het weet welke drivers er eventueel geladen moeten worden.<?asciidoc-br?>
Wanneer een nieuw device gedetecteerd wordt (Windows XP/Vista geeft hiervan een melding in de system-tray), zal de host een aanvraag voor informatie sturen naar endpoint 0 (de controle-endpoint) van device-adres 0 (geen enkel actief apparaat heeft adres 0). Die informatie bestaat uit een aantal descriptors: records met vooraf bepaalde velden die alle nodige informatie bevatten die de host-controller nodig heeft. In een volgende stap kent de host een USB-adres toe aan het nieuwe apparaat (verschillend van 0), waarna nog wat informatie uitgewisseld wordt tussen host en apparaat.<?asciidoc-br?>
In de ontvangen device-descriptor staat onder andere een veld dat de fabrikant van het apparaat identificeert (zoals bij een netwerkkaart, aan te vragen bij het USB-consortium) en een veld dat door die fabrikant toegekend wordt om het model van het apparaat te identificeren. Bij die configuratie worden ook andere configuratieparameters (configuration-descriptor) uitgewisseld waarin onder meer bepaald wordt hoeveel stroom het apparaat nodig zal hebben.<?asciidoc-br?>
Daarna zullen ook nog interface descriptors uitgewisseld worden. Deze bevatten informatie over het aantal endpoints dat het device nodig heeft, en welke device classes ondersteund worden.<?asciidoc-br?>
Tot slot worden ook nog endpoint descriptors doorgestuurd. Daarin staat per endpoint beschreven hoe het verkeer zal georganiseerd worden (bulk, interrupt, …), hoe vaak er moet gepold worden in het geval van interrupt transfer, de richting van de endpoint (IN/OUT), …<?asciidoc-br?>
Op basis van die Vendor-en Product- ID’s  en de informatie die in de descriptors gevonden wordt, zal het besturingssysteem in de beschikbare INF-bestanden zoeken naar een geschikte driver. Als die niet gevonden wordt zal bijvoorbeeld Windows 8 online op zoek gaan. De pas geladen driver zal bij zijn initialisatie zelf het USB-apparaat (of beter de controller daarin) verder configureren, waarna het toestel gebruikt kan worden.</simpara>
</section>
</section>
<section id="_device_classes_drivers">
<title>Device Classes, Drivers</title>
<simpara>Bij het overlopen van alle mogelijke randapparaten voor een computer kunnen die in een aantal grote groepen ingedeeld worden. Bij het ontwerp van de USB-standaard zijn een aantal device-classes en subclasses gedefinieerd. Elk toestel moet bij de enumeratie in de device-descriptor ook meegeven tot welke groep het behoort. Voor elke vastgelegde class en subclass is ook de structuur van de driver vastgelegd samen met de vereisten voor de firmware van het apparaat zelf (een soort API).</simpara>
<simpara>Enkele voorbeelden van classes:</simpara>
<itemizedlist>
<listitem>
<simpara>Audio devices</simpara>
</listitem>
<listitem>
<simpara>Mass Storage devices</simpara>
</listitem>
<listitem>
<simpara>Monitors</simpara>
</listitem>
<listitem>
<simpara>Communication devices (modems)</simpara>
</listitem>
<listitem>
<simpara>Printers Still image capture devices (scanner, camera,&#8230;&#8203;)</simpara>
</listitem>
<listitem>
<simpara>HID (Human interface devices)</simpara>
</listitem>
</itemizedlist>
<simpara>Een mordern besturingssysteem bevat drivers voor een aantal veel voorkomende classes. Voor apparaten uit die groepen hoeft de fabrikant geen eigen drivers meer te schrijven (tenzij er extra functionaliteit gevraagd wordt).<?asciidoc-br?>
Een belangrijke groep is de HID-class: deze is origineel bedoeld voor I/O apparatuur als toetsenbord, muis en dergelijke. De vereisten voor deze toestellen zijn zeer beperkt, zodat het vrij gemakkelijk is om een toestel (en de bijhorende firmware) te ontwerpen dat binnen deze groep past, met als voordeel dat daarvoor geen drivers geschreven hoeven te worden (ze zijn immers al binnen het besturingssysteem aanwezig).</simpara>
</section>
<section id="_usb_3_0">
<title>USB 3.0</title>
<simpara>De USB standaard versie 3 verzekert de toekomst van deze technologie. Om deze hoge snelheden te kunnen halen, waren wel enkele compromissen nodig.
Zo was dezelfde connector niet langer bruikbaar. Alles is gelukkig backwards compatibel, maar een USB3 connector zal je makkelijk kunnen herkennen aan de blauwe kleur van de binnenkant van de connector.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/USB3connector.jpg" contentwidth="300" align="center"/>
</imageobject>
<textobject><phrase>USB3-connector</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Ondanks de fysieke compatibiliteit zijn er een flink aantal verschillen te bespeuren in de nieuwe versie. Kijk je bijvoorbeeld naar een dwarsdoorsnede van een USB3.0-kabel, dan merk je een groot verschil. Het data-paar van USB2.0 is nog steeds aanwezig, maar is enkel daar om compatibiliteit te garanderen.
De snelle data zal verplaatst worden over twee Shielded Differential Pairs.<?asciidoc-br?>
Deze geïsoleerde geleiders  zorgen er uiteraard voor dat deze kabels een stuk minder soepel zullen zijn dan hun voorgangers.<?asciidoc-br?>
Een ander interessant detail is dat deze standaard voorziet in een grotere stroomlevering aan apparaten: 900mA ten opzichte van 500mA bij de huidige (2.0) standaard.<?asciidoc-br?>
De encoding gebeurt ook niet langer met NRZI, maar met 8b/10b, de methode die ook gebruikt wordt bij SATA, SAS, PCI Express.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/usb3-kabeldoorsnede.png" contentwidth="500" width="35%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Dwarsdoorsnede USB3-kabel (bron onbekend)</phrase></textobject>
</mediaobject>
</informalfigure>
<section id="_signalering">
<title>Signalering</title>
<simpara>Ook de signalering is bij USB 3.0 op de schop genomen. Het typerende polling-concept is niet meer zo sterk aanwezig. Dat geeft voordelen naar zuinigheid van de apparaten. Ze moeten immers niet constant actief zijn.<?asciidoc-br?></simpara>
<simpara>Andere significante wijzigingen:</simpara>
<itemizedlist>
<listitem>
<simpara>verkeer is nu full duplex ten opzichte van half-duplex in USB 1 en 2.</simpara>
</listitem>
<listitem>
<simpara>de protocolstack is een stuk complexer</simpara>
</listitem>
<listitem>
<simpara>bulk streams is een nieuwe, vijfde transfermethode</simpara>
</listitem>
<listitem>
<simpara>toevoegen van een link layer</simpara>
</listitem>
<listitem>
<simpara>fel verbeterd power management</simpara>
</listitem>
<listitem>
<simpara>door complexiteit is de maximale kabellengte beperkt tot ongeveer 3 meter.</simpara>
</listitem>
</itemizedlist>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/usb3.0_architecture.jpg" width="50%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>USB3 protocol stack (bron:onbekend</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
</section>
</section>
<section id="_thunderbolt">
<title>Thunderbolt</title>
<simpara>De Thunderbolt interface is te vinden op alle nieuwe MAC-hardware, en heeft z’n reden.  De standaard werd ontwikkeld door Intel in samenwerking met Apple.<?asciidoc-br?>
De eerste apparaten die hiermee werden uitgerust, werden uitgebracht in februari 2011 (Macbook Pro). Mondjesmaat wordt extra randapparatuur uitgebracht die dit ondersteunt. De standaard probeert nog universeler te zijn dan USB door de kracht van displayport (zie verder) en PCIx te combineren in één enkele poort.</simpara>
<section id="_architectuur_2">
<title>Architectuur</title>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ch07/images/Thunderbolt_Technology_model_1_E.png" contentwidth="500" width="40%" scalefit="1" align="center"/>
</imageobject>
<textobject><phrase>Thunderbolt architectuur (bron: Intel)</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Thunderbolt is in staat om 10Gpbs te transfereren over een koperverbinding. Initieel had Intel de bedoeling om  de bekabeling met glasvezels te produceren, maar voorlopig is dat niet het geval. De bouw ervan was te duur, en een bijkomend probleem was dat op die manier geen stroomvoorziening kan gebeuren voor de randapparaten. Er wordt echter nog steeds ontwikkeld, dus misschien duikt dit alsnog op in een volgende versie.<?asciidoc-br?>
De architectuur van Thunderbolt  zet alles in op performantie. Daarvoor wordt de PCH  via een PCIe 4x poort verbonden met de Thunderbolt controller, en is die laatste ook verbonden met het interne grafisch systeem van de computer. Het resultaat is dat over deze verbinding een PCIx verbinding en een Displayport gebundeld zijn. Daarnaast ondersteunt Thunderbolt ook daisy chaining tot maximaal zeven apparaten. Dat betekent dat je Thunderbolt-compatibele apparaten kan doorlussen.<?asciidoc-br?>
Een goed voorbeeld van hoe dit gebruikt wordt, vind je bijvoorbeeld in het Apple Thunderbolt Display. Dat is een scherm dat bedoeld is voor de apple macbook pro’s als tweede scherm. Met een enkele Thunderbolt kabel naar dat schem wordt echter veel mogelijk:</simpara>
<itemizedlist>
<listitem>
<simpara>een 27” scherm met 2560-by-1440 resolutie krijgt z’n beelden door deze kabel</simpara>
</listitem>
<listitem>
<simpara>er is een camera ingebouwd</simpara>
</listitem>
<listitem>
<simpara>er is HD audio voorzien</simpara>
</listitem>
<listitem>
<simpara>er is een connector voor Gigabit Ethernet voorzien</simpara>
</listitem>
<listitem>
<simpara>er is een Firewire 800 connector voorzien.</simpara>
</listitem>
</itemizedlist>
<simpara>Dat alles gebeurt met deze enkele Thunderbolt kabel.</simpara>
<warning>
<simpara>Criticasters hekelen de veiligheid van Thunderbolt, net omdat je rechtstreeks verbonden bent als een PCIx poort, en je dus ook toegang hebt tot het geheugen van het host-apparaat. Bedenk zelf de risico’s die daarmee gepaard gaan…</simpara>
</warning>
</section>
</section>
</chapter>
<chapter id="_literatuurlijst">
<title>Literatuurlijst</title>
<simpara>Onderstaande werken bevatten een stuk diepgaandere informatie over deze materie. Ze kunnen dan ook een ideaal vertrekpunt vormen voor een verdere studie van de computerarchitectuur.</simpara>
<bibliodiv>
<bibliomixed>
<bibliomisc><anchor id="STALLINGS" xreflabel="[STALLINGS]"/>[STALLINGS] Andy Hunt &amp; Dave Thomas. 'Computer Organization and architecture, Ninth edition'. Pearson education. 2012.</bibliomisc>
</bibliomixed>
<bibliomixed>
<bibliomisc><anchor id="RAMA" xreflabel="[RAMA]"/>[RAMA] Umakishura Ramachandran. 'Computer Systems: An Integrated Approach to Architecture and Operating Systems'. Manning Publications.
2010.</bibliomisc>
</bibliomixed>
</bibliodiv>
</chapter>
</book>
